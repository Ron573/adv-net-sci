
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Exercise &#8212; Advanced Topics in Network Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tmp/all';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../home.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.jpg" class="logo__image only-light" alt="Advanced Topics in Network Science - Home"/>
    <script>document.write(`<img src="../_static/logo.jpg" class="logo__image only-dark" alt="Advanced Topics in Network Science - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../home.html">
                    Welcome to SSIE 641 Advanced Topics on Network Science
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Intro</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../intro/why-networks.html">Why should we care networks?</a></li>

<li class="toctree-l1"><a class="reference internal" href="../intro/zoo-of-networks.html">Zoo of networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/setup.html">Trouble shooting</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M01: Euler Tour</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m01-euler_tour/what-to-learn.html">Module 1: Euler Tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-euler_tour/puzzle.html">A puzzle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-euler_tour/euler-path.html">Euler’s solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-euler_tour/how-to-code-network.html">Compute with networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-euler_tour/coding-exercise.html">Exercise</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M02: Small World</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/what-to-learn.html">Module 2: Small-world</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/small-world-experiment.html">Small-world experiment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/wikirace.html">Wikirace</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/pen-and-paper.html">Why is our social network small world?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/connectedness.html">Walks, Trails, Paths, and Connectedness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/which-tools.html">Toolbox for network analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/compressed-sparse-row.html">Efficient representation for large sparse networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/connectedness-hands-on.html">Computing the Shortest Paths and Connected Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/assignment.html">Assignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/appendix.html">Appendix</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M03: Robustness</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/what-to-learn.html">Module 3: Robustness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/exercise-power-grid.html">Building a cost-effective power grid network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/minimum-spanning-tree.html">Minimum spanning tree</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/robustness.html">Network Robustness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/robustness-hands-on.html">Hands-on: Robustness (Random attack)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/percolation.html">Percolation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/appendix.html">Appendix</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M04: Friendship Paradox</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m04-friendship-paradox/what-to-learn.html">Module 4: Friendship Paradox</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-friendship-paradox/experiment.html">In-class experiment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-friendship-paradox/friendship-paradox.html">Friendship Paradox</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-friendship-paradox/vaccination-game.html">Vaccination Game</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-friendship-paradox/degree-distribution.html">Degree distribution</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M05: Clustering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/what-to-learn.html">Module 5: Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/what-is-community.html">What is community?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/pen-and-paper.html">Pen and Paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/pattern-matching.html">Community detection (pattern matching)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/graph-cut.html">Graph cut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/ratio-normalized-cut.html">Balanced cut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/modularity.html">Modularity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/modularity-02.html">Modularity (Cont.)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/stochastic-block-model.html">Stochastic Block Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/exercise-clustering.html">Hands-on: Clustering</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M06: Centrality</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m06-centrality/what-to-learn.html">Module 6: Centrality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m06-centrality/pen-and-paper.html">Pen and paper exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m06-centrality/degree-distance-based-centrality.html">What is centrality?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m06-centrality/eigencentrality.html">Centralities based on centralities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m06-centrality/hands-on.html">Computing centrality with Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m06-centrality/assignment.html">Assignment</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M07: Random Walks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/what-to-learn.html">Module 7: Random Walks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/amida-kuji.html">Ladder Lottery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/random-walks.html">Random Walks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/pen-and-paper.html">Pen and paper exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/random-walks-code.html">Random Walks in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/random-walks-math.html">Characteristics of Random Walks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/unifying-centrality-and-communities.html">Random walks unify centrality and communities</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M08: Embedding</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/what-to-learn.html">Module 8: Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/pen-and-paper.html">Pen and paper exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/spectral-embedding.html">Spectral Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/word2vec.html">word2vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/graph-embedding-w-word2vec.html">Graph embedding with word2vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/spectral-vs-neural-embedding.html">Spectral vs Neural Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/software.html">Software for Network Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/appendix.html">Appendix</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M09: Graph Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/what-to-learn.html">Module 9: Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/pen-and-paper.html">Pen and paper exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/image-processing.html">Preliminaries: Image Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/from-image-to-graph.html">From Image to Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/graph-convolutional-network.html">Graph Convolutional Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/popular-gnn.html">Popular Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/appendix.html">Appendix</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/skojaku/adv-net-sci/gh-pages?urlpath=tree/docs/lecture-note/tmp/all.md" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/skojaku/adv-net-sci" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/skojaku/adv-net-sci/issues/new?title=Issue%20on%20page%20%2Ftmp/all.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/tmp/all.ipynb" target="_blank"
   class="btn btn-sm btn-download-notebook-button dropdown-item"
   title="Download notebook file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li><a href="../_sources/tmp/all.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Exercise</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Exercise</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-01">Exercise 01</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-02">Exercise 02</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#edge-counting">Edge counting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pen-and-paper-worksheet">Pen-and-paper worksheet</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-generate-csr-format-from-an-adjacency-matrix">How to generate CSR format from an adjacency matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-use-csr-format-for-efficient-computations">How to use CSR format for efficient computations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#assignment">Assignment</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where-src-trg-and-values-are-lists-of-the-source-nodes-target-nodes-and-edge-weights-respectively">where <code class="docutils literal notranslate"><span class="pre">src</span></code>, <code class="docutils literal notranslate"><span class="pre">trg</span></code>, and <code class="docutils literal notranslate"><span class="pre">values</span></code> are lists of the source nodes, target nodes, and edge weights, respectively.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jupytext-cell-metadata-filter-all-formats-md-myst-text-representation-extension-rmd-format-name-myst-format-version-0-13-jupytext-version-1-16-3-kernelspec-display-name-python-3-ipykernel-language-python-name-python3">jupytext:
cell_metadata_filter: -all
formats: md:myst
text_representation:
extension: .Rmd
format_name: myst
format_version: 0.13
jupytext_version: 1.16.3
kernelspec:
display_name: Python 3 (ipykernel)
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-the-shortest-paths-and-connected-components">Computing the Shortest Paths and Connected Components</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#igraph">igraph</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#create-a-graph">Create a graph</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shortest-paths">Shortest Paths</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#connected-components">Connected Components</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id59">Exercise 01 🏋️‍♀️💪🧠</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#directed-networks">Directed networks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scipy">Scipy</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id60">Create a graph</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id61">Shortest Paths</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id62">Connected Components</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id63">Exercise 02 🏋️‍♀️💪🧠</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hint-finding-all-shortest-paths-is-a-qubic-time-operation-with-respect-to-the-number-of-nodes-or-simply-put-it-takes-a-long-time-to-compute-so-compute-the-estimate-by-sampling-many-pairs-of-nodes-uniformly-at-random-and-computing-the-average-path-length-jupytext-cell-metadata-filter-all-formats-md-myst-text-representation-extension-rmd-format-name-myst-format-version-0-13-jupytext-version-1-16-3-kernelspec-display-name-python-3-ipykernel-language-python-name-python3"><strong>Hint:</strong> Finding all shortest paths is a qubic time operation with respect to the number of nodes, or simply put, it takes a long time to compute. So compute the “estimate” by sampling many pairs of nodes uniformly at random and computing the average path length.—
jupytext:
cell_metadata_filter: -all
formats: md:myst
text_representation:
extension: .Rmd
format_name: myst
format_version: 0.13
jupytext_version: 1.16.3
kernelspec:
display_name: Python 3 (ipykernel)
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#walks-trails-paths-and-connectedness">Walks, Trails, Paths, and Connectedness</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#walks-trails-paths">Walks, Trails, Paths</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#connectedness">Connectedness</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#connectedness-in-directed-networks">Connectedness in directed networks</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#why-is-our-social-network-small-world">Why is our social network small world?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id67">jupytext:
cell_metadata_filter: -all
formats: md:myst
text_representation:
extension: .Rmd
format_name: myst
format_version: 0.13
jupytext_version: 1.16.3
kernelspec:
display_name: Python 3 (ipykernel)
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#small-world-experiment">Small-world experiment</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-criterion-for-the-giant-component">A criterion for the giant component</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-many-nodes-are-needed-to-break-a-network">How many nodes are needed to break a network?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-study-airport-network">Case study: Airport network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#targeted-attacks">Targeted attacks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-design-a-robust-network">How to design a robust network?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#hands-on-robustness-random-attack">Hands-on: Robustness (Random attack)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#robustness-against-random-failures">Robustness against random failures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#targeted-attack">Targeted attack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#while-the-network-is-robust-against-the-random-attacks-it-is-vulnerable-to-the-degree-based-targeted-attack-jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">While the network is robust against the random attacks, it is vulnerable to the degree-based targeted attack.—
jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#network-robustness">Network Robustness</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-node-failures">Random node failures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id74">Targeted attack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#whats-next">What’s next?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#module-3-robustness">Module 3: Robustness</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-to-learn-in-this-module">What to learn in this module</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#degree-distribution">Degree distribution</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization-basics">Visualization basics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coding-exercise">Coding exercise</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plotting-degree-distribution">Plotting degree distribution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#degree-distribution-of-a-friend">Degree distribution of a friend</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plotting-degree-distribution-of-a-friend">Plotting degree distribution of a friend</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modularity-maximization">Modularity maximization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id85">Exercise 01 🏋️‍♀️💪🧠</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stochstic-block-model">Stochstic Block Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id88">Exercise 02 🏋️‍♀️💪🧠</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modularity-demo">Modularity Demo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitation-of-modularity">Limitation of Modularity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#resolution-limit">Resolution limit</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spurious-communities">Spurious communities</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#so-should-we-avoid-modularity">So should we avoid modularity?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-full-modularity-formula-is-on-the-next-page-jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">The full modularity formula is on the next page 😉.—
jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#community-detection-pattern-matching">Community detection (pattern matching)</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pen-and-paper">Pen and Paper</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pen-and-paper-exercise">✍️ <span class="xref myst">Pen and Paper Exercise</span> 🚢</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#balanced-cut">Balanced cut</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ratio-cut">Ratio Cut</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normalized-cut">Normalized cut</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cut-into-more-than-two-communities">Cut into more than two communities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithms-to-find-the-best-cut">Algorithms to find the best cut</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#issue-of-ratio-cut-and-normalized-cut">Issue of Ratio cut and Normalized cut</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#characterizing-network-structures-with-the-sbm">Characterizing network structures with the SBM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-networks-with-sbm">Generating networks with SBM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#detecting-communities-with-sbm">Detecting communities with SBM</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#module-5-clustering">Module 5: Clustering</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id109">What to learn in this module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#harmonic-centrality">Harmonic centrality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eccentricity-centrality">Eccentricity centrality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id111">Eccentricity centrality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#betweenness-centrality">Betweenness centrality</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#katz-centrality">Katz centrality</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pagerank">PageRank</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-katz-centrality">Computing Katz centrality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-optional">Exercise (Optional)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#network-of-ancient-roman-roads">Network of ancient Roman roads</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-data-construct-the-network">Load the data &amp; construct the network</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id113">Exercise 🏛️</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id114">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pen-and-paper-exercises">Pen and paper exercises</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#module-6-centrality">Module 6: Centrality</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id115">What to learn in this module</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ladder-lottery">Ladder Lottery</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id116">Exercise 01</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expected-behavior-of-random-walks">Expected behavior of random walks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id117">Exercise 02</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-03">Exercise 03</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-structure">Community structure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-04">Exercise 04</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id118">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#characteristics-of-random-walks">Characteristics of Random Walks</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stationary-state">Stationary State</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment">Experiment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-to-reach-the-stationary-state">Time to reach the stationary state</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-the-mixing-time">Compute the mixing time</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#normalized-adjacency-matrix">Normalized Adjacency Matrix</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-step-transition-probability">Multi-step Transition Probability</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#relaxation-time-and-mixing-time">Relaxation Time and Mixing Time</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id119">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#random-walks-unify-centrality-and-communities">Random walks unify centrality and communities</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modularity-interpretation-from-random-walk-perspective">Modularity: Interpretation from random walk perspective</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pagerank-interpretation-from-random-walk-perspective">PageRank: Interpretation from random walk perspective</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-generate-random-walks">Step 2: Generate random walks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-train-the-word2vec-model">Step 3: Train the word2vec model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-clustering">Step 4: Clustering</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#node2vec">node2vec</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-02-implement-node2vec">Exercise 02: Implement node2vec</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#line">LINE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modularity-embedding">Modularity embedding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laplacian-eigenmap">Laplacian Eigenmap</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#an-example-for-the-laplacian-eigenmap">An example for the Laplacian Eigenmap</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id130">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-vs-neural-embedding">Spectral vs Neural Embedding</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#module-8-embedding">Module 8: Embedding</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id136">What to learn in this module</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#word2vec">word2vec</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-it-works">How it works</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#whats-special-about-word2vec">What’s special about word2vec?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id139">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">Appendix</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#brunas-spectral-gcn">Bruna’s Spectral GCN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chebnet">ChebNet</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id140">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#from-image-to-graph">From Image to Graph</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analogy-between-image-and-graph-data">Analogy between image and graph data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-filter-on-graphs">Spectral filter on graphs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-filtering">Spectral Filtering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-high-pass-filter-increases-the-contrast-of-the-eigenvector-centrality-emphasizing-the-differences-between-nodes-on-the-other-hand-the-low-pass-filter-smooths-out-the-eigenvector-centrality">The high-pass filter increases the contrast of the eigenvector centrality, emphasizing the differences between nodes. On the other hand, the low-pass filter smooths out the eigenvector centrality.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id141">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-convolutional-networks">Graph Convolutional Networks</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-graph-convolutional-networks">Spectral Graph Convolutional Networks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-spectral-to-spatial">From Spectral to Spatial</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id143">ChebNet</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-convolutional-networks-by-kipf-and-welling">Graph Convolutional Networks by Kipf and Welling</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#first-order-approximation">First-order Approximation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-gcns-can-suffer-from-over-smoothing">Deep GCNs can suffer from over-smoothing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fourier-transform">Fourier Transform</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#an-example-for-the-fourier-transform">An example for the Fourier transform</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fourier-transform-of-images">Fourier Transform of Images</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#an-example-of-fourier-transform">An example of Fourier transform</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-key-lesson-from-image-processing">A key lesson from image processing</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id147">Pen and paper exercises</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id148">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#popular-graph-neural-networks">Popular Graph Neural Networks</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graphsage-sample-and-aggregate">GraphSAGE: Sample and Aggregate</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-ideas">Key Ideas</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#neighborhood-sampling">Neighborhood Sampling</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#aggregation">Aggregation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-attention-networks-gat-differentiate-individual-neighbors">Graph Attention Networks (GAT): Differentiate Individual Neighbors</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#attention-mechanism">Attention Mechanism</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-isomorphism-network-gin-differentiate-the-aggregation">Graph Isomorphism Network (GIN): Differentiate the Aggregation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weisfeiler-lehman-test">Weisfeiler-Lehman Test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gin">GIN</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#module-9-graph-neural-networks">Module 9: Graph Neural Networks</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id152">What to learn in this module</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <a target="_blank" href="https://colab.research.google.com/github/skojaku/adv-net-sci/blob/main/notebooks/exercise-m01-euler-tour.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>
<section class="tex2jax_ignore mathjax_ignore" id="exercise">
<h1>Exercise<a class="headerlink" href="#exercise" title="Link to this heading">#</a></h1>
<section id="exercise-01">
<h2>Exercise 01<a class="headerlink" href="#exercise-01" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Create a network of landmasses and bridges of Binghamton, NY.</p></li>
<li><p>Find an Euler path that crosses all the bridges of Binghamton, NY exactly once.</p></li>
</ol>
<p><img alt="Binghamton Map" src="https://github.com/skojaku/adv-net-sci/raw/main/docs/lecture-note/figs/binghamton-map.jpg" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># If you are using colab, uncomment the following line</span>
<span class="c1"># !sudo apt install libcairo2-dev pkg-config python3-dev</span>
<span class="c1"># !pip install pycairo cairocffi</span>
<span class="c1"># !pip install igraph</span>
</pre></div>
</div>
</div>
</div>
<p>Define the edges</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This is a placeholder for your code for the exercise</span>
<span class="n">edges</span> <span class="o">=</span> <span class="o">...</span>
</pre></div>
</div>
</div>
</div>
<p>Define the adjacnecy matrix (without for loops!)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="o">...</span>
</pre></div>
</div>
</div>
</div>
<p>Visualize the graph</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">igraph</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">visualize_graph</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
  <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
  <span class="n">src</span><span class="p">,</span> <span class="n">trg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
  <span class="n">g</span> <span class="o">=</span> <span class="n">igraph</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">g</span><span class="o">.</span><span class="n">add_vertices</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">t</span><span class="p">]):</span>
      <span class="n">g</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>

<span class="n">visualize_graph</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ValueError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">line</span> <span class="mi">15</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span>       <span class="n">g</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span>   <span class="k">return</span> <span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">15</span> <span class="n">visualize_graph</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="nn">Cell In[4], line 7,</span> in <span class="ni">visualize_graph</span><span class="nt">(A, **params)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="k">def</span> <span class="nf">visualize_graph</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span>   <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">7</span>   <span class="n">src</span><span class="p">,</span> <span class="n">trg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>   <span class="n">g</span> <span class="o">=</span> <span class="n">igraph</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span>   <span class="n">g</span><span class="o">.</span><span class="n">add_vertices</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="ne">ValueError</span>: not enough values to unpack (expected 2, got 1)
</pre></div>
</div>
</div>
</div>
<p>Check if the graph has an Euler path</p>
</section>
<section id="exercise-02">
<h2>Exercise 02<a class="headerlink" href="#exercise-02" title="Link to this heading">#</a></h2>
<p>Let’s create a network from pre-existing data and check if it has an Euler path.</p>
<ol class="arabic simple">
<li><p>Select a network of your choice from <a class="reference external" href="https://networks.skewed.de/">Netzschleuder</a>. For convenience, choose a network of nodes less than 5000.</p></li>
<li><p>Download the csv version of the data by clicking something like “3KiB” under <code class="docutils literal notranslate"><span class="pre">csv</span></code> column.</p></li>
<li><p>Unzip the file and find “edges.csv”, open it with a text editor to familiarize yourself with the format.</p></li>
<li><p>Load the data using <code class="docutils literal notranslate"><span class="pre">pandas</span></code>.</p></li>
<li><p>Get the source and target nodes from the data to create an edge list.</p></li>
<li><p>Construct the adjacency matrix from the edge list.</p></li>
<li><p>Draw the graph using <code class="docutils literal notranslate"><span class="pre">igraph</span></code>.</p></li>
<li><p>Check if the graph has an Euler path.</p></li>
</ol>
<p>Load the data by</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;edges.csv&#39;</span><span class="p">)</span> <span class="c1"># load the data</span>
<span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then, get the srce and target nodes to compose an edge list</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">src</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">trg</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">edges</span> <span class="o">=</span> <span class="o">...</span>
</pre></div>
</div>
</div>
</div>
<p>Create the adjacency matrix from the edge list</p>
<p>Get the degree of each node</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deg</span> <span class="o">=</span> <span class="o">...</span>
</pre></div>
</div>
</div>
</div>
<p>Visualize the graph</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">visualize_graph</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Check if the graph has an Euler path</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="err">```</span><span class="o">---</span>
<span class="n">jupytext</span><span class="p">:</span>
  <span class="n">formats</span><span class="p">:</span> <span class="n">md</span><span class="p">:</span><span class="n">myst</span>
  <span class="n">text_representation</span><span class="p">:</span>
    <span class="n">extension</span><span class="p">:</span> <span class="o">.</span><span class="n">md</span>
    <span class="n">format_name</span><span class="p">:</span> <span class="n">myst</span>
<span class="n">kernelspec</span><span class="p">:</span>
  <span class="n">display_name</span><span class="p">:</span> <span class="n">Python</span> <span class="mi">3</span>
  <span class="n">language</span><span class="p">:</span> <span class="n">python</span>
  <span class="n">name</span><span class="p">:</span> <span class="n">python3</span>
<span class="n">launch_buttons</span><span class="p">:</span>
  <span class="n">notebook_interface</span><span class="p">:</span> <span class="s2">&quot;classic&quot;</span>
  <span class="n">colab_url</span><span class="p">:</span> <span class="s2">&quot;https://colab.research.google.com&quot;</span>
  <span class="n">thebe</span><span class="p">:</span> <span class="n">true</span>
  <span class="n">binderhub_url</span><span class="p">:</span> <span class="s2">&quot;https://mybinder.org&quot;</span>  <span class="c1"># The URL for your BinderHub (e.g., https://mybinder.org)</span>
<span class="o">---</span>


<span class="c1"># Euler&#39;s solution</span>

<span class="n">Euler</span> <span class="n">consider</span> <span class="n">two</span> <span class="n">cases</span><span class="p">:</span>
<span class="o">-</span> <span class="n">a</span> <span class="n">node</span> <span class="n">has</span> <span class="n">an</span> <span class="n">even</span> <span class="n">number</span> <span class="n">of</span> <span class="n">edges</span><span class="p">,</span> <span class="ow">or</span>
<span class="o">-</span> <span class="n">a</span> <span class="n">node</span> <span class="n">has</span> <span class="n">an</span> <span class="n">odd</span> <span class="n">number</span> <span class="n">of</span> <span class="n">edges</span><span class="o">.</span>

<span class="n">When</span> <span class="n">a</span> <span class="n">node</span> <span class="n">has</span> <span class="n">an</span> <span class="n">even</span> <span class="n">number</span> <span class="err">$</span><span class="mi">2</span><span class="n">k</span><span class="err">$</span> <span class="n">of</span> <span class="n">edges</span><span class="p">,</span> <span class="n">one</span> <span class="n">can</span> <span class="n">enter</span> <span class="ow">and</span> <span class="n">leave</span> <span class="n">the</span> <span class="n">node</span> <span class="err">$</span><span class="n">k</span><span class="err">$</span> <span class="n">times</span> <span class="n">by</span> <span class="n">crossing</span> <span class="n">different</span> <span class="n">edges</span><span class="o">.</span>

<span class="n">When</span> <span class="n">a</span> <span class="n">node</span> <span class="n">has</span> <span class="n">an</span> <span class="n">odd</span> <span class="n">number</span> <span class="err">$</span><span class="mi">2</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="err">$</span> <span class="n">of</span> <span class="n">edges</span><span class="p">,</span> <span class="n">one</span> <span class="n">can</span> <span class="n">enter</span> <span class="ow">and</span> <span class="n">leave</span> <span class="n">the</span> <span class="n">node</span> <span class="err">$</span><span class="n">k</span><span class="err">$</span> <span class="n">times</span> <span class="n">by</span> <span class="n">crossing</span> <span class="n">different</span> <span class="n">edges</span> <span class="n">but</span> <span class="n">leave</span> <span class="n">one</span> <span class="n">last</span> <span class="n">edge</span> <span class="n">to</span> <span class="n">cross</span><span class="o">.</span> <span class="n">The</span> <span class="n">only</span> <span class="n">way</span> <span class="n">to</span> <span class="n">cross</span> <span class="n">this</span> <span class="n">last</span> <span class="n">edge</span> <span class="ow">is</span> <span class="n">that</span> <span class="n">one</span> <span class="n">starts</span> <span class="ow">or</span> <span class="n">ends</span> <span class="n">at</span> <span class="n">the</span> <span class="n">node</span><span class="o">.</span>

<span class="n">Based</span> <span class="n">up</span> <span class="n">on</span> <span class="n">the</span> <span class="n">above</span> <span class="n">reasoning</span><span class="p">,</span> <span class="n">Euler</span> <span class="n">leads</span> <span class="n">to</span> <span class="n">the</span> <span class="n">following</span> <span class="n">necessary</span> <span class="p">(</span><span class="ow">and</span> <span class="n">later</span> <span class="n">shown</span> <span class="k">as</span> <span class="n">sufficient</span><span class="p">)</span> <span class="n">conditions</span><span class="p">:</span>

<span class="p">:::{</span><span class="n">admonition</span><span class="p">}</span> <span class="n">Euler</span><span class="s1">&#39;s path</span>

<span class="n">There</span> <span class="n">exists</span> <span class="n">a</span> <span class="n">walk</span> <span class="n">that</span> <span class="n">crosses</span> <span class="nb">all</span> <span class="n">edges</span> <span class="n">exactly</span> <span class="n">once</span> <span class="k">if</span> <span class="ow">and</span> <span class="n">only</span> <span class="k">if</span> <span class="nb">all</span> <span class="n">nodes</span> <span class="n">have</span> <span class="n">even</span> <span class="n">number</span> <span class="n">of</span> <span class="n">edges</span><span class="p">,</span> <span class="ow">or</span> <span class="n">exactly</span> <span class="n">two</span> <span class="n">nodes</span> <span class="n">have</span> <span class="n">an</span> <span class="n">odd</span> <span class="n">number</span> <span class="n">of</span> <span class="n">edges</span><span class="o">.</span>
<span class="p">:::</span>

<span class="o">![</span>alt<span class="w"> </span>text<span class="o">](</span>https://lh3.googleusercontent.com/-CYxppcJBwe4/W2ndkci9bVI/AAAAAAABX-U/K6SNM8gAhg0oNsnWNgQbH3uKNd5Ba10wwCHMYCw/euler-graph-bridges2?imgmax<span class="o">=</span><span class="m">1600</span><span class="o">)</span>

<span class="n">Back</span> <span class="n">to</span> <span class="n">the</span> <span class="n">Konigsberg</span> <span class="n">bridge</span> <span class="n">problem</span><span class="p">,</span> <span class="n">every</span> <span class="n">node</span> <span class="n">has</span> <span class="n">an</span> <span class="n">odd</span> <span class="n">number</span> <span class="n">of</span> <span class="n">edges</span><span class="p">,</span> <span class="n">meaning</span> <span class="n">that</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">no</span> <span class="n">way</span> <span class="n">to</span> <span class="n">cross</span> <span class="nb">all</span> <span class="n">edges</span> <span class="n">exactly</span> <span class="n">once</span><span class="o">.</span> <span class="n">What</span> <span class="n">a</span> <span class="n">sad</span> <span class="n">story</span> <span class="k">for</span> <span class="n">the</span> <span class="n">citizens</span> <span class="n">of</span> <span class="n">Konigsberg</span><span class="o">.</span> <span class="n">But</span> <span class="n">the</span> <span class="n">problem</span> <span class="n">was</span> <span class="n">solved</span> <span class="n">during</span> <span class="n">World</span> <span class="n">War</span> <span class="n">II</span><span class="p">,</span> <span class="n">where</span> <span class="n">Koingberg</span> <span class="n">was</span> <span class="n">bombarded</span> <span class="n">by</span> <span class="n">Soviet</span> <span class="n">Union</span><span class="p">,</span> <span class="n">losing</span> <span class="n">two</span> <span class="n">of</span> <span class="n">the</span> <span class="n">seven</span> <span class="n">bridges</span> <span class="err">🫠</span><span class="o">.</span>

<span class="p">:::{</span><span class="n">figure</span><span class="o">-</span><span class="n">md</span><span class="p">}</span> <span class="n">markdown</span><span class="o">-</span><span class="n">fig</span>
<span class="o">&lt;</span><span class="n">img</span> <span class="n">src</span><span class="o">=</span><span class="s2">&quot;../figs/seven-bridge-bombared.png&quot;</span> <span class="n">alt</span><span class="o">=</span><span class="s2">&quot;fishy&quot;</span> <span class="n">width</span><span class="o">=</span><span class="s2">&quot;50%&quot;</span><span class="o">&gt;</span>

<span class="n">Two</span> <span class="n">bridges</span> <span class="n">were</span> <span class="n">bombed</span> <span class="n">by</span> <span class="n">Soviet</span> <span class="n">Union</span><span class="p">,</span> <span class="n">which</span> <span class="n">allows</span> <span class="n">the</span> <span class="n">Euler</span> <span class="n">path</span> <span class="n">to</span> <span class="n">exist</span><span class="o">.</span>
<span class="p">:::</span>

<span class="o">---</span>
<span class="n">kernelspec</span><span class="p">:</span>
  <span class="n">display_name</span><span class="p">:</span> <span class="n">Python</span> <span class="mi">3</span> <span class="p">(</span><span class="n">ipykernel</span><span class="p">)</span>
  <span class="n">language</span><span class="p">:</span> <span class="n">python</span>
  <span class="n">name</span><span class="p">:</span> <span class="n">python3</span>
<span class="o">---</span>

<span class="o">&lt;</span><span class="n">a</span> <span class="n">target</span><span class="o">=</span><span class="s2">&quot;_blank&quot;</span> <span class="n">href</span><span class="o">=</span><span class="s2">&quot;https://colab.research.google.com/github/skojaku/adv-net-sci/blob/main/docs/lecture-note/m01-euler_tour/how-to-code-network.ipynb&quot;</span><span class="o">&gt;</span>
  <span class="o">&lt;</span><span class="n">img</span> <span class="n">src</span><span class="o">=</span><span class="s2">&quot;https://colab.research.google.com/assets/colab-badge.svg&quot;</span> <span class="n">alt</span><span class="o">=</span><span class="s2">&quot;Open In Colab&quot;</span><span class="o">/&gt;</span>
<span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>

<span class="c1"># Compute with networks</span>

<span class="n">So</span> <span class="n">far</span> <span class="n">we</span> <span class="n">worked</span> <span class="n">out</span> <span class="n">the</span> <span class="n">network</span> <span class="n">of</span> <span class="n">bridges</span> <span class="n">of</span> <span class="n">Konigsberg</span> <span class="n">by</span> <span class="n">illustrating</span> <span class="n">the</span> <span class="n">network</span> <span class="k">with</span> <span class="n">points</span> <span class="ow">and</span> <span class="n">lines</span><span class="o">.</span>
<span class="n">From</span> <span class="n">now</span><span class="p">,</span> <span class="n">we</span> <span class="n">will</span> <span class="n">work</span> <span class="k">with</span> <span class="n">a</span> <span class="n">representation</span> <span class="n">of</span> <span class="n">the</span> <span class="n">network</span> <span class="n">that</span> <span class="n">can</span> <span class="n">be</span> <span class="n">easily</span> <span class="n">computed</span> <span class="k">with</span> <span class="n">code</span><span class="o">.</span>

<span class="c1">## Network representation</span>

<span class="n">An</span> <span class="n">atomic</span> <span class="n">element</span> <span class="n">of</span> <span class="n">a</span> <span class="n">network</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">node</span><span class="p">,</span> <span class="n">i</span><span class="o">.</span><span class="n">e</span><span class="o">.</span><span class="p">,</span> <span class="n">a</span> <span class="n">network</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">collection</span> <span class="n">of</span> <span class="n">edges</span> <span class="n">which</span> <span class="n">are</span> <span class="n">pairs</span> <span class="n">of</span> <span class="n">nodes</span><span class="o">.</span>
<span class="n">We</span> <span class="o">*</span><span class="n">label</span><span class="o">*</span> <span class="n">a</span> <span class="n">unique</span> <span class="n">integer</span> <span class="k">as</span> <span class="n">an</span> <span class="n">identifier</span> <span class="k">for</span> <span class="n">each</span> <span class="n">node</span><span class="o">.</span> <span class="n">For</span> <span class="n">instance</span><span class="p">,</span> <span class="n">the</span> <span class="n">bridges</span> <span class="n">of</span> <span class="n">Konigsberg</span> <span class="n">has</span> <span class="mi">4</span> <span class="n">nodes</span><span class="p">,</span> <span class="ow">and</span> <span class="n">we</span> <span class="n">assign</span> <span class="n">the</span> <span class="n">number</span> <span class="mi">0</span> <span class="n">to</span> <span class="mi">3</span> <span class="n">to</span> <span class="n">the</span> <span class="n">nodes</span><span class="o">.</span> <span class="n">An</span> <span class="n">edge</span> <span class="n">can</span> <span class="n">be</span> <span class="n">represented</span> <span class="n">by</span> <span class="n">a</span> <span class="n">pair</span> <span class="n">of</span> <span class="n">nodes</span><span class="o">.</span> <span class="n">For</span> <span class="n">instance</span><span class="p">,</span> <span class="n">the</span> <span class="n">edge</span> <span class="n">between</span> <span class="n">node</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">node</span> <span class="mi">1</span> <span class="n">can</span> <span class="n">be</span> <span class="n">represented</span> <span class="n">by</span> <span class="n">the</span> <span class="n">pair</span> <span class="err">`</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="err">`</span><span class="o">.</span>


<span class="err">```</span><span class="p">{</span><span class="n">figure</span><span class="o">-</span><span class="n">md</span><span class="p">}</span> <span class="n">numbered</span><span class="o">-</span><span class="n">koningsberg</span><span class="o">-</span><span class="n">graph</span>

<span class="o">![</span>file<span class="o">](</span>https://github.com/skojaku/adv-net-sci/blob/gh-pages/_images/labeled-koningsberg.jpg?raw<span class="o">=</span><span class="nb">true</span><span class="o">)</span>

<span class="n">Labeled</span> <span class="n">Knigsberg</span> <span class="n">graph</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note" id="node-labeling">
<p class="admonition-title">Note</p>
<p>We label nodes starting from 0 with consecutive numbers, which is convenient for Python. However, this is <em>not the only way</em> to label nodes.</p>
</div>
<p>The Konigsberg graph can be represented by a list of edges.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">edges</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<p>Another, more convenient format is the <em>adjacency matrix</em>.
In this form, one regard the node index as a coordinate in the matrix. For instance, edge <span class="math notranslate nohighlight">\((1,3)\)</span> is represented by the entry in the second row and fourth column. The entry of the matrix represents the number of edges between two nodes. Thus, the zeros in the matrix represent the absence of edges.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<p>or equivalently, using for loops:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>
    <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the Konigsberg graph, the edges are <em>undirected</em>, meaning edge (i,j) is the same as edge (j,i), which is why we increment both entries <span class="math notranslate nohighlight">\((i,j)\)</span> and <span class="math notranslate nohighlight">\((j,i)\)</span> in the for loop. If the edges are <em>directed</em>, we treat (i,j) and (j,i) as two different edges, and increment only (i,j).</p>
</div>
</section>
<section id="edge-counting">
<h2>Edge counting<a class="headerlink" href="#edge-counting" title="Link to this heading">#</a></h2>
<p>Let us showcase the convenience of the adjacency matrix by counting the number of edges in the network.</p>
<p>The total number of edges in the network is the sum of the entities in the</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<p>We divide by 2 because an edge corresponds to two entries in the matrix. Now, let us consider</p>
<p>It is also easy to compute the number of edges pertained to individual nodes by taking the row or column sum of the matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The result is an array of length 4, where the i-th entry is the number of edges connected to node i.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The number of edges connected to a node is called the <em><strong>degree</strong></em> of the node.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The <code class="docutils literal notranslate"><span class="pre">np.sum(A,</span> <span class="pre">axis</span> <span class="pre">=</span> <span class="pre">1)</span></code> is the column sum of <code class="docutils literal notranslate"><span class="pre">A</span></code>. Alternatively, <code class="docutils literal notranslate"><span class="pre">np.sum(A,</span> <span class="pre">axis</span> <span class="pre">=</span> <span class="pre">0)</span></code> is the row sum of <code class="docutils literal notranslate"><span class="pre">A</span></code>.
Check out the numpy <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.sum.html">documentation</a> for more details.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If the adjacency matrix is <code class="docutils literal notranslate"><span class="pre">scipy</span></code> CSR format (or CSC format), you can instead use <code class="docutils literal notranslate"><span class="pre">A_csr.sum(axis=1)</span></code>, <code class="docutils literal notranslate"><span class="pre">A_csr.sum(axis=0)</span></code>, and <code class="docutils literal notranslate"><span class="pre">A_csr.sum()</span></code>.
Check out the <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix">scipy documentation</a> for more details.</p>
</div>
<p>We can check the number of nodes with odd degree by taking the modulus of the degree by 2.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">is_odd</span> <span class="o">=</span> <span class="n">deg</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span>
<span class="n">is_odd</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">is_odd</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">is_odd</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The graph has a Euler path.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The graph does not have a Euler path.&quot;</span><span class="p">)</span>
<span class="err">```</span><span class="o">---</span>
<span class="n">jupytext</span><span class="p">:</span>
  <span class="n">formats</span><span class="p">:</span> <span class="n">md</span><span class="p">:</span><span class="n">myst</span>
  <span class="n">text_representation</span><span class="p">:</span>
    <span class="n">extension</span><span class="p">:</span> <span class="o">.</span><span class="n">md</span>
    <span class="n">format_name</span><span class="p">:</span> <span class="n">myst</span>
<span class="n">kernelspec</span><span class="p">:</span>
  <span class="n">display_name</span><span class="p">:</span> <span class="n">Python</span> <span class="mi">3</span>
  <span class="n">language</span><span class="p">:</span> <span class="n">python</span>
  <span class="n">name</span><span class="p">:</span> <span class="n">python3</span>
<span class="o">---</span>

<span class="c1"># A puzzle</span>

<span class="n">Back</span> <span class="ow">in</span> <span class="mi">18</span><span class="n">th</span> <span class="n">century</span><span class="p">,</span> <span class="n">there</span> <span class="n">was</span> <span class="n">a</span> <span class="n">city</span> <span class="n">called</span> <span class="o">*</span><span class="n">Königsberg</span><span class="o">*</span> <span class="n">situated</span> <span class="n">on</span> <span class="n">the</span> <span class="n">Pregel</span> <span class="n">River</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">historical</span> <span class="n">region</span> <span class="n">of</span> <span class="n">Germany</span><span class="o">.</span> <span class="n">The</span> <span class="n">city</span> <span class="n">had</span> <span class="n">two</span> <span class="n">large</span> <span class="n">islands</span> <span class="n">connected</span> <span class="n">to</span> <span class="n">each</span> <span class="n">other</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">mainland</span> <span class="n">by</span> <span class="n">seven</span> <span class="n">bridges</span><span class="o">.</span>
<span class="n">The</span> <span class="n">citizens</span> <span class="n">of</span> <span class="n">Königsberg</span> <span class="n">pondered</span> <span class="n">a</span> <span class="n">puzzle</span> <span class="n">during</span> <span class="n">their</span> <span class="n">Sunday</span> <span class="n">walks</span><span class="p">:</span>

<span class="err">```</span><span class="p">{</span><span class="n">admonition</span><span class="p">}</span> <span class="n">Problem</span>
<span class="n">How</span> <span class="n">could</span> <span class="n">one</span> <span class="n">walk</span> <span class="n">through</span> <span class="n">the</span> <span class="n">city</span> <span class="ow">and</span> <span class="n">cross</span> <span class="n">each</span> <span class="n">bridge</span> <span class="n">exactly</span> once<span class="o">?</span>
</pre></div>
</div>
</div>
</div>
<figure class="align-default" id="seven-bridges">
<img alt="alt text" src="https://99percentinvisible.org/wp-content/uploads/2022/02/bridges-with-water-600x418.png" />
<figcaption>
<p><span class="caption-text">The seven bridges of Königsberg</span><a class="headerlink" href="#seven-bridges" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Leonard Euler worked out the solution to this puzzle in 1736. He first simplified the city into <em>a network of landmasses connected by bridges</em>, by noting that the landareas, the positions of the islands and the bridges are nothing to do with the puzzle, and that the only thing that matters is the connections between the landmasses.</p>
<figure class="align-default" id="euler-graph">
<img alt="https://lh3.googleusercontent.com/-CYxppcJBwe4/W2ndkci9bVI/AAAAAAABX-U/K6SNM8gAhg0oNsnWNgQbH3uKNd5Ba10wwCHMYCw/euler-graph-bridges2?imgmax=1600" src="https://lh3.googleusercontent.com/-CYxppcJBwe4/W2ndkci9bVI/AAAAAAABX-U/K6SNM8gAhg0oNsnWNgQbH3uKNd5Ba10wwCHMYCw/euler-graph-bridges2?imgmax=1600" />
<figcaption>
<p><span class="caption-text">Euler’s graph of the bridges of Knigsberg</span><a class="headerlink" href="#euler-graph" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="pen-and-paper-worksheet">
<h2>Pen-and-paper worksheet<a class="headerlink" href="#pen-and-paper-worksheet" title="Link to this heading">#</a></h2>
<p>Let’s follow the worksheet to solve the puzzle step by step.</p>
<ul class="simple">
<li><p><a class="reference external" href="http://estebanmoro.org/pdf/netsci_for_kids/the_konisberg_bridges.pdf">Worksheet</a> <span id="id1">[<a class="reference internal" href="m01.html#id3" title="Esteban Moro. Network science for kids! Mar 2017. URL: http://estebanmoro.org/2017/03/network-science-for-kids.">1</a>]</span></p></li>
</ul>
<div class="docutils container" id="id2">
<div role="list" class="citation-list">
<div class="citation" id="id3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Esteban Moro. Network science for kids! Mar 2017. URL: <a class="reference external" href="http://estebanmoro.org/2017/03/network-science-for-kids">http://estebanmoro.org/2017/03/network-science-for-kids</a>.</p>
</div>
</div>
</div>
<p>We will walk you through what these arrays mean, how they are generated, and how we can leverage them for efficient computations.</p>
<section id="how-to-generate-csr-format-from-an-adjacency-matrix">
<h3>How to generate CSR format from an adjacency matrix<a class="headerlink" href="#how-to-generate-csr-format-from-an-adjacency-matrix" title="Link to this heading">#</a></h3>
<p>Let’s walk you through how to store an example adjacency matrix in Compressed Sparse Row (CSR) format. Our example adjacency matrix is as follows.</p>
<div align="center">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-right"><p></p></th>
<th class="head text-right"><p>0</p></th>
<th class="head text-right"><p>1</p></th>
<th class="head text-right"><p>2</p></th>
<th class="head text-right"><p>3</p></th>
<th class="head text-right"><p>4</p></th>
<th class="head text-right"><p>5</p></th>
<th class="head text-right"><p>6</p></th>
<th class="head text-right"><p>7</p></th>
<th class="head text-right"><p>8</p></th>
<th class="head text-right"><p>9</p></th>
<th class="head text-right"><p>10</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-right"><p>0</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>2</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>3</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>4</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>5</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>6</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>7</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>8</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>9</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>10</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p></p></td>
</tr>
</tbody>
</table>
</div>
</div>
<p>We will first create <strong>adjacency list</strong>, which is a dictionary consisting of the row IDs and column IDs for the non-zero entries in the adjacency matrix.</p>
<div class="container" align="center">
<div class="col" style="margin-top:0%">
<p><span class="math notranslate nohighlight">\(\{\text{Row ID}: (\text{Column ID}, \text{Value})\}\)</span></p>
</div>
</div>
<p>Concretely, in Python,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adj_list</span> <span class="o">=</span> <span class="p">{</span>
  <span class="mi">0</span><span class="p">:[(</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">)],</span>
  <span class="mi">1</span><span class="p">:[(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>
  <span class="mi">2</span><span class="p">:[(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>
  <span class="mi">3</span><span class="p">:[(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">1</span><span class="p">)],</span>
  <span class="c1">#...</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>CSR format is a <em>concatenation</em> of the keys and values of the adjacency list, respectively. The CSR format has a concatenated array of the values, one for column IDs and one for the values, called <code class="docutils literal notranslate"><span class="pre">indices</span></code> and <code class="docutils literal notranslate"><span class="pre">data</span></code>, respectively.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">vv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">adj_list</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">for</span> <span class="n">vv</span> <span class="ow">in</span> <span class="n">v</span><span class="p">])</span>
<span class="n">indices</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">vv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">adj_list</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">for</span> <span class="n">vv</span> <span class="ow">in</span> <span class="n">v</span><span class="p">])</span>
<span class="n">data</span>
</pre></div>
</div>
</div>
</div>
<p>Additionally, the CSR format has another array called <code class="docutils literal notranslate"><span class="pre">indptr</span></code>, which stores the Row IDs of the non-zero entries in the adjacency matrix. This <code class="docutils literal notranslate"><span class="pre">indptr</span></code> array has a value such that <code class="docutils literal notranslate"><span class="pre">indptr[i]</span></code> is the first index of <code class="docutils literal notranslate"><span class="pre">indices</span></code> that corresponds to the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th row of the adjacency matrix. This can be generated by</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">indptr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">adj_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">adj_list</span><span class="p">))])</span>
<span class="n">indptr</span>
</pre></div>
</div>
</div>
</div>
<p>where we added <code class="docutils literal notranslate"><span class="pre">0</span></code> at the beginning of the array to represent the first non-zero entry in the first row.
The first row ends at index <code class="docutils literal notranslate"><span class="pre">len(adj_list[0])-1</span></code>, and the second row starts at index <code class="docutils literal notranslate"><span class="pre">len(adj_list[0])</span></code> and ends at index <code class="docutils literal notranslate"><span class="pre">len(adj_list[0])+len(adj_list[1])-1</span></code>, and so on.</p>
<p>Now we have three compressed vectors <code class="docutils literal notranslate"><span class="pre">indptr</span></code>, <code class="docutils literal notranslate"><span class="pre">indices</span></code>, and <code class="docutils literal notranslate"><span class="pre">data</span></code>, that together form the CSR format for the adjacency matrix.</p>
</section>
<section id="how-to-use-csr-format-for-efficient-computations">
<h3>How to use CSR format for efficient computations<a class="headerlink" href="#how-to-use-csr-format-for-efficient-computations" title="Link to this heading">#</a></h3>
<p>The key advantage of the CSR representation is the memory efficiency. But you can leverage the CSR format for more efficient computations, if you know the semantics of <code class="docutils literal notranslate"><span class="pre">indptr</span></code>, <code class="docutils literal notranslate"><span class="pre">indices</span></code>, and <code class="docutils literal notranslate"><span class="pre">data</span></code> arrays.</p>
<p>For instance, one can compute the degree of a node by using</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">degree</span> <span class="o">=</span> <span class="n">indptr</span><span class="p">[</span><span class="n">node</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">indptr</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
<span class="n">degree</span>
</pre></div>
</div>
</div>
</div>
<p>Let us break down the above code.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">indptr[node]</span></code> is the first index of the <code class="docutils literal notranslate"><span class="pre">indices</span></code> array that corresponds to the <code class="docutils literal notranslate"><span class="pre">node</span></code>-th row of the adjacency matrix.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">indptr[node+1]</span></code> is the first index of the <code class="docutils literal notranslate"><span class="pre">indices</span></code> array that corresponds to the <code class="docutils literal notranslate"><span class="pre">(node+1)</span></code>-th row of the adjacency matrix.</p></li>
<li><p>Thus, <code class="docutils literal notranslate"><span class="pre">indptr[node+1]</span> <span class="pre">-</span> <span class="pre">indptr[node]</span></code> is the number of non-zero entries in the <code class="docutils literal notranslate"><span class="pre">node</span></code>-th row of the adjacency matrix, which is the degree of the <code class="docutils literal notranslate"><span class="pre">node</span></code>-th node.</p></li>
</ul>
<p>Using <code class="docutils literal notranslate"><span class="pre">indices</span></code>, it is easy to identify the neighbors of a given node by using</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">neighbors</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">indptr</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span><span class="n">indptr</span><span class="p">[</span><span class="n">node</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">neighbors</span>
</pre></div>
</div>
</div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">indices[indptr[node]:indptr[node+1]]</span></code> is the corresponding column IDs of the non-zero entries in the <code class="docutils literal notranslate"><span class="pre">node</span></code>-th row of the adjacency matrix, which corresponds to the node IDs connected to the <code class="docutils literal notranslate"><span class="pre">node</span></code>-th node.</p>
<p>The edge weights to the neighbors can be obtained by using</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">edge_weights</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">indptr</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span><span class="n">indptr</span><span class="p">[</span><span class="n">node</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">edge_weights</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="assignment">
<h1>Assignment<a class="headerlink" href="#assignment" title="Link to this heading">#</a></h1>
<p>We will compute the average path length of a network of scientists. The network is constructed from <a class="footnote-reference brackets" href="#footcite-sinatra2016quantifying" id="id57" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>, where each node represents a scientist and two scientists are connected if they have co-authored a paper in Physical Review Journals from American Physical Society.</p>
<ul class="simple">
<li><p><strong>For students enrolled in SSIE 641</strong></p>
<ul>
<li><p>You will receive a dedicated link to the assignment repository from the instructor.</p></li>
</ul>
</li>
<li><p><em>For those who are not enrolled in SSIE 641</em></p>
<ul>
<li><p>You can access the assignment repository at <a class="reference external" href="https://github.com/sk-classroom/adv-net-sci-small-world">Github</a>.</p></li>
<li><p>This repository does not offer auto-grading. But you can grade the assignment by yourself by</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">grading-toolkit/grade_notebook.sh</span> <span class="pre">tests/test_01.py</span> <span class="pre">assignment/assignment.ipynb</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">grading-toolkit/grade_notebook.sh</span> <span class="pre">tests/test_02.py</span> <span class="pre">assignment/assignment.ipynb</span></code></p></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="docutils container" id="id58">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-sinatra2016quantifying" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id57">1</a><span class="fn-bracket">]</span></span>
<p>Roberta Sinatra, Dashun Wang, Pierre Deville, Chaoming Song, and Albert-László Barabási. Quantifying the evolution of individual scientific impact. <em>Science</em>, 354(6312):aaf5239, 2016.</p>
</aside>
</aside>
</div>
<p>If you have an <em>edge list</em>, you can directly generate the CSR matrix without creating the dense matrix first.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>

<span class="n">edges</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)]</span>

<span class="n">src</span> <span class="o">=</span> <span class="p">[</span><span class="n">edge</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">]</span>
<span class="n">trg</span> <span class="o">=</span> <span class="p">[</span><span class="n">edge</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">]</span>
<span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">]</span>
<span class="n">A_csr</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">((</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">)),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">A_csr</span>
</pre></div>
</div>
</div>
</div>
<section id="where-src-trg-and-values-are-lists-of-the-source-nodes-target-nodes-and-edge-weights-respectively">
<h2>where <code class="docutils literal notranslate"><span class="pre">src</span></code>, <code class="docutils literal notranslate"><span class="pre">trg</span></code>, and <code class="docutils literal notranslate"><span class="pre">values</span></code> are lists of the source nodes, target nodes, and edge weights, respectively.<a class="headerlink" href="#where-src-trg-and-values-are-lists-of-the-source-nodes-target-nodes-and-edge-weights-respectively" title="Link to this heading">#</a></h2>
</section>
<section id="jupytext-cell-metadata-filter-all-formats-md-myst-text-representation-extension-rmd-format-name-myst-format-version-0-13-jupytext-version-1-16-3-kernelspec-display-name-python-3-ipykernel-language-python-name-python3">
<h2>jupytext:
cell_metadata_filter: -all
formats: md:myst
text_representation:
extension: .Rmd
format_name: myst
format_version: 0.13
jupytext_version: 1.16.3
kernelspec:
display_name: Python 3 (ipykernel)
language: python
name: python3<a class="headerlink" href="#jupytext-cell-metadata-filter-all-formats-md-myst-text-representation-extension-rmd-format-name-myst-format-version-0-13-jupytext-version-1-16-3-kernelspec-display-name-python-3-ipykernel-language-python-name-python3" title="Link to this heading">#</a></h2>
<a target="_blank" href="https://colab.research.google.com/github/skojaku/adv-net-sci/blob/main/notebooks/exercise-m02-small-world.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="computing-the-shortest-paths-and-connected-components">
<h1>Computing the Shortest Paths and Connected Components<a class="headerlink" href="#computing-the-shortest-paths-and-connected-components" title="Link to this heading">#</a></h1>
<p>Let’s use <code class="docutils literal notranslate"><span class="pre">igraph</span></code> to compute the shortest paths and connected components. We will then use <code class="docutils literal notranslate"><span class="pre">scipy</span></code> to compute them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># If you are using Google Colab, uncomment the following line to install igraph</span>
<span class="c1"># !sudo apt install libcairo2-dev pkg-config python3-dev</span>
<span class="c1"># !pip install pycairo cairocffi</span>
<span class="c1"># !pip install igraph</span>
</pre></div>
</div>
</div>
</div>
<section id="igraph">
<h2>igraph<a class="headerlink" href="#igraph" title="Link to this heading">#</a></h2>
<section id="create-a-graph">
<h3>Create a graph<a class="headerlink" href="#create-a-graph" title="Link to this heading">#</a></h3>
<p>Let us create a graph of 4 nodes and 4 edges. Our edge list is given by</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">edge_list</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">igraph</span></code> has an object <code class="docutils literal notranslate"><span class="pre">Graph</span></code> that stores a graph and provides methods to manipulate and analyze the graph. To create a graph from an edge list, we can use the <code class="docutils literal notranslate"><span class="pre">add_edges</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">igraph</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">igraph</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span> <span class="c1"># Create an empty graph</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_vertices</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="c1"># Add 4 vertices</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_edges</span><span class="p">(</span><span class="n">edge_list</span><span class="p">)</span> <span class="c1"># Add edges to the graph</span>

<span class="c1"># Plot the graph</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">bbox</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">),</span> <span class="n">vertex_label</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="shortest-paths">
<h3>Shortest Paths<a class="headerlink" href="#shortest-paths" title="Link to this heading">#</a></h3>
<p>Let’s compute the paths between nodes 2 and 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span><span class="o">.</span><span class="n">get_all_simple_paths</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This method enumerates all possible simple paths between two nodes. This is OK for small networks but quickly becomes impractical for larger networks, as the number of paths increases exponentially with the size of the network.</p>
<p>Often, we are interested in the shortest path, which is the path with the smallest number of edges. The shortest path can be computed by using the <code class="docutils literal notranslate"><span class="pre">get_shortest_paths</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span><span class="o">.</span><span class="n">get_shortest_paths</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Note that there can be multiple shortest paths between two nodes. If we are interested in the “length” instead of the path itself, there is a more efficient function <code class="docutils literal notranslate"><span class="pre">distances</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span><span class="o">.</span><span class="n">distances</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="connected-components">
<h3>Connected Components<a class="headerlink" href="#connected-components" title="Link to this heading">#</a></h3>
<p>In the simple network above, we can see that for every pair of nodes, we can find a path connecting them. This is the definition of a connected graph. We can check this property for a given graph:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">components</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">connected_components</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">components</span></code> is a special object called <a class="reference external" href="https://python.igraph.org/en/0.11.6/api/igraph.VertexClustering.html">VertexClustering</a> in <code class="docutils literal notranslate"><span class="pre">igraph</span></code>.
It has the following useful functions and attributes:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;membership: &quot;</span><span class="p">,</span> <span class="n">components</span><span class="o">.</span><span class="n">membership</span><span class="p">)</span>  <span class="c1"># the IDs of the component each node belongs to.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sizes: &quot;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">components</span><span class="o">.</span><span class="n">sizes</span><span class="p">()))</span>  <span class="c1"># the number of nodes in each component.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;giant: &quot;</span><span class="p">,</span> <span class="n">components</span><span class="o">.</span><span class="n">giant</span><span class="p">())</span>  <span class="c1"># a subgraph of the largest connected component.</span>
</pre></div>
</div>
</div>
</div>
<section id="id59">
<h4>Exercise 01 🏋️‍♀️💪🧠<a class="headerlink" href="#id59" title="Link to this heading">#</a></h4>
<ol class="arabic simple">
<li><p>Now, let us add two nodes that are not connected to the existing graph, and call <code class="docutils literal notranslate"><span class="pre">connected_components</span></code> again. 🔗➕</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">get_shortest_paths</span></code> between the two new nodes in different connected components. 🛣️🔍</p></li>
<li><p>Get the largest connected component. 🌐🏆</p></li>
</ol>
</section>
</section>
<section id="directed-networks">
<h3>Directed networks<a class="headerlink" href="#directed-networks" title="Link to this heading">#</a></h3>
<p>Let’s extend these ideas about paths and connected components to directed graphs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">edge_list</span> <span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)]</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">igraph</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="n">directed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_vertices</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_edges</span><span class="p">(</span><span class="n">edge_list</span><span class="p">)</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">bbox</span><span class="o">=</span><span class="p">(</span><span class="mi">250</span><span class="p">,</span> <span class="mi">250</span><span class="p">),</span> <span class="n">vertex_label</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p>In directed graphs, edges and paths can be one-way. For instance, in our graph, you can go from node 0 to node 3, but not from 3 to 0.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;From 0 to 3&quot;</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_all_simple_paths</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;From 3 to 0&quot;</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_all_simple_paths</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>The shortest path from 4 to 1 must take a longer route due to edge directions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span><span class="o">.</span><span class="n">get_shortest_paths</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Directed networks have two kinds of connected components.</p>
<ul class="simple">
<li><p><strong>Strongly connected components:</strong> Strongly connected means that there exists a direct path between every pair of nodes, i.e., that from any node to any other nodes while respecting the edge directionality.</p></li>
<li><p><strong>Weakly connected components:</strong> Weakly connected means that there exists a path between every pair of nodes when ignoring the edge directionality.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">connected_components</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;strong&quot;</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">connected_components</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;weak&quot;</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="scipy">
<h2>Scipy<a class="headerlink" href="#scipy" title="Link to this heading">#</a></h2>
<p>We can create a graph, compute the shortest paths, and connected components using <code class="docutils literal notranslate"><span class="pre">scipy</span></code>.</p>
<section id="id60">
<h3>Create a graph<a class="headerlink" href="#id60" title="Link to this heading">#</a></h3>
<p>With scipy, we represent a network by an adjacency matrix using something called a <em>Compressed Sparse Row (CSR) matrix</em>. CSR matrices are efficient format for storing and manipulating <em>sparse</em> matrices. Why <em>sparse</em> is highlighed here? Because in many networks, the adjacency matrix is sparse, i.e., most of the entries are zero. For example, here is the adjacency matrix of a real-world network:</p>
<p><img alt="" src="https://www.researchgate.net/publication/263506932/figure/fig1/AS:392539896074252&#64;1470600212952/Scale-free-Network-left-its-adjacency-matrix-upper-right-and-degree-distribution.png" /></p>
<p>Most of the entries in this adjacency matrix are white, and white means that the value of the entry is zero. And the adjacency matrix looks very white! This is pretty common in real-world networks. We call these matrices “sparse” because they are mostly empty. And CSR matrices are a way to store these sparse matrices efficiently. Don’t worry too much about the technical details for now. If you’re curious to learn more, you can check out the <a class="reference internal" href="#appendix.md"><span class="xref myst">Appendix</span></a>.</p>
<p>The great thing is, <code class="docutils literal notranslate"><span class="pre">scipy</span></code> (especially the <code class="docutils literal notranslate"><span class="pre">scipy.sparse</span></code> module) provides efficient tools for working with these sparse matrices. This comes in really handy when we’re working with large networks.</p>
<p>Let create a graph using scipy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">sparse</span> <span class="c1"># We will use sparse module in scipy</span>

<span class="n">edge_list</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)]</span>

<span class="n">src</span> <span class="o">=</span> <span class="p">[</span><span class="n">src</span> <span class="k">for</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="ow">in</span> <span class="n">edge_list</span><span class="p">]</span>
<span class="n">trg</span> <span class="o">=</span> <span class="p">[</span><span class="n">dst</span> <span class="k">for</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="ow">in</span> <span class="n">edge_list</span><span class="p">]</span>
<span class="n">weight</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="ow">in</span> <span class="n">edge_list</span><span class="p">]</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">((</span><span class="n">weight</span><span class="p">,</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">)),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">A</span> <span class="o">+</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span> <span class="c1"># Make the adjacency matrix symmetric</span>
<span class="n">A</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s break down the code.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">src</span></code> and <code class="docutils literal notranslate"><span class="pre">trg</span></code> are the source and target nodes of the edges.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weight</span></code> is the weight of the edges.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sparse.csr_matrix((weight,</span> <span class="pre">(src,</span> <span class="pre">trg)))</span></code> creates a sparse matrix, filling <code class="docutils literal notranslate"><span class="pre">weight</span></code> into the positions specified by <code class="docutils literal notranslate"><span class="pre">(src,</span> <span class="pre">trg)</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">A.T</span></code> is the transpose of <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">+</span> <span class="pre">A.T</span></code> makes the adjacency matrix symmetric.</p></li>
</ul>
<p>The CSR matrix does not print nicely. But you can see it by converting to a numpy array and printing it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id61">
<h2>Shortest Paths<a class="headerlink" href="#id61" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">sparse</span></code> module has a submodule <code class="docutils literal notranslate"><span class="pre">csgraph</span></code> that provides APIs for network analysis.</p>
<p>For example, <code class="docutils literal notranslate"><span class="pre">csgraph.shortest_path</span></code> computes the shortest path length from a specific node to all other nodes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csgraph</span>

<span class="c1"># `indices` is the node to compute the shortest path from.</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">csgraph</span><span class="o">.</span><span class="n">shortest_path</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">D</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Advanced:</strong> If you want to get the actual paths (i.e., list of nodes in the path), you can pass <code class="docutils literal notranslate"><span class="pre">return_predecessors=True</span></code> to <code class="docutils literal notranslate"><span class="pre">csgraph.shortest_path</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">D</span><span class="p">,</span> <span class="n">predecessors</span> <span class="o">=</span> <span class="n">csgraph</span><span class="o">.</span><span class="n">shortest_path</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_predecessors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id62">
<h2>Connected Components<a class="headerlink" href="#id62" title="Link to this heading">#</a></h2>
<p>Connected components can be computed by <code class="docutils literal notranslate"><span class="pre">csgraph.connected_components</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_components</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">csgraph</span><span class="o">.</span><span class="n">connected_components</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of connected components:&quot;</span><span class="p">,</span> <span class="n">n_components</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Labels:&quot;</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_components</span></code> is the number of connected components.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">labels</span></code> is an array of length <code class="docutils literal notranslate"><span class="pre">n_nodes</span></code> where each element is the ID of the connected component the node belongs to.</p></li>
</ul>
</section>
<section id="id63">
<h2>Exercise 02 🏋️‍♀️💪🧠<a class="headerlink" href="#id63" title="Link to this heading">#</a></h2>
<p>Let’s compute the average path length of a network from pre-existing data and check if how long on average it takes to go from any node to any other node.</p>
<ol class="arabic simple">
<li><p>Select a network of your choice from <a class="reference external" href="https://networks.skewed.de/">Netzschleuder</a>. For convenience, choose a network of nodes less than 5000.</p></li>
<li><p>Download the csv version of the data by clicking something like “3KiB” under <code class="docutils literal notranslate"><span class="pre">csv</span></code> column.</p></li>
<li><p>Unzip the file and find “edges.csv”, open it with a text editor to familiarize yourself with the format.</p></li>
<li><p>Load the data using <code class="docutils literal notranslate"><span class="pre">pandas</span></code>.</p></li>
<li><p>Get the source and target nodes from the data to create an edge list.</p></li>
<li><p>Construct a graph from the edge list, either using <code class="docutils literal notranslate"><span class="pre">igraph</span></code> or <code class="docutils literal notranslate"><span class="pre">scipy</span></code>.</p></li>
<li><p>Compute the average path length</p></li>
</ol>
</section>
<section id="hint-finding-all-shortest-paths-is-a-qubic-time-operation-with-respect-to-the-number-of-nodes-or-simply-put-it-takes-a-long-time-to-compute-so-compute-the-estimate-by-sampling-many-pairs-of-nodes-uniformly-at-random-and-computing-the-average-path-length-jupytext-cell-metadata-filter-all-formats-md-myst-text-representation-extension-rmd-format-name-myst-format-version-0-13-jupytext-version-1-16-3-kernelspec-display-name-python-3-ipykernel-language-python-name-python3">
<h2><strong>Hint:</strong> Finding all shortest paths is a qubic time operation with respect to the number of nodes, or simply put, it takes a long time to compute. So compute the “estimate” by sampling many pairs of nodes uniformly at random and computing the average path length.—
jupytext:
cell_metadata_filter: -all
formats: md:myst
text_representation:
extension: .Rmd
format_name: myst
format_version: 0.13
jupytext_version: 1.16.3
kernelspec:
display_name: Python 3 (ipykernel)
language: python
name: python3<a class="headerlink" href="#hint-finding-all-shortest-paths-is-a-qubic-time-operation-with-respect-to-the-number-of-nodes-or-simply-put-it-takes-a-long-time-to-compute-so-compute-the-estimate-by-sampling-many-pairs-of-nodes-uniformly-at-random-and-computing-the-average-path-length-jupytext-cell-metadata-filter-all-formats-md-myst-text-representation-extension-rmd-format-name-myst-format-version-0-13-jupytext-version-1-16-3-kernelspec-display-name-python-3-ipykernel-language-python-name-python3" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="walks-trails-paths-and-connectedness">
<h1>Walks, Trails, Paths, and Connectedness<a class="headerlink" href="#walks-trails-paths-and-connectedness" title="Link to this heading">#</a></h1>
<section id="walks-trails-paths">
<h2>Walks, Trails, Paths<a class="headerlink" href="#walks-trails-paths" title="Link to this heading">#</a></h2>
<p>While we have already used the term <strong>path</strong>, let us make clear its definition, together with other related terms.</p>
<ul class="simple">
<li><p>A <strong>walk</strong> is a sequence of nodes that are connected to form a continous route in a network. For instance, walk (0, 1, 2, 3) is a walk in the graph of the bridges of Konigsberg. But the sequence (0,2,3,1) is not a walk, because the node 0 is not directly connected to node 2.</p></li>
<li><p>A <strong>trail</strong> is a walk with no repeated edge. For instance, walk (0, 1, 2, 3) is also a trail as it does not cross the same edge twice. But walk (0,2,3,1,3) is not a trail due to the repeated edge (1,3).</p></li>
<li><p>A <strong>path</strong> is a walk without repeated node. For instance, walk (0,1,2,3) is a path. But walk (0, 1, 2, 1, 2, 3) is not a path due to the repeated node 1 and 2.</p></li>
<li><p>When a walk starts and ends at the same node, it is called a *<em>loop</em>. If the loop is a trail, it is called a <strong>circuit</strong>. If the loop is a path, it is called a <strong>cycle</strong>.</p></li>
</ul>
<p><em><strong>Question</strong></em>: Is a path always a trail, and is a trail always a path?</p>
<figure class="align-default" id="numbered-koningsberg-graph2">
<a class="reference internal image-reference" href="../_images/labeled-koningsberg.jpg"><img alt="../_images/labeled-koningsberg.jpg" src="../_images/labeled-koningsberg.jpg" style="width: 30%;" /></a>
<figcaption>
<p><span class="caption-text">Labeled Knigsberg graph</span><a class="headerlink" href="#numbered-koningsberg-graph2" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><strong>Shortest Path</strong> is the path with the smallest number of edges (or nodes) between two nodes.
A shortest path from node 0 to 2 is (0, 1, 2). Two nodes can have multiple shortest paths e.g., (0, 3, 2).</p></li>
<li><p><strong>The shortest path length</strong> is the number of edges in the shortest path, <em>not the number of nodes!</em> 👈👈</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Are there <strong>shortest trails</strong> and <strong>shortest walks</strong>?
Shortest trails and shortest walks are fundamentally equivalent to shortest paths. A shortest trail must visit each node only once (otherwise it would not be the shortest), and similarly, a shortest walk does not repeat nodes (otherwise it would not be the shortest), both forming a shortest path.</p>
</div>
</section>
<section id="connectedness">
<h2>Connectedness<a class="headerlink" href="#connectedness" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>A network is <strong>connected</strong> if there is a path between every pair of nodes.</p></li>
<li><p>A network is <strong>disconnected</strong> if there is no path between some pairs of nodes.</p></li>
<li><p><strong>A connected component</strong> of a network is a set of nodes that are connected to each other.</p></li>
<li><p><strong>The giant component</strong> of a network is the largest connected component that contains a significant fraction of nodes in the network (in order of the number of nodes).</p></li>
</ul>
<figure class="align-default" id="id64">
<a class="reference internal image-reference" href="../_images/connected-component.jpg"><img alt="../_images/connected-component.jpg" src="../_images/connected-component.jpg" style="width: 50%;" /></a>
<figcaption>
<p><span class="caption-text">connected components of a network. the nodes with the same color form a connected component.</span><a class="headerlink" href="#id64" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="connectedness-in-directed-networks">
<h2>Connectedness in directed networks<a class="headerlink" href="#connectedness-in-directed-networks" title="Link to this heading">#</a></h2>
<p>We call a network is <em>directed</em> if the edges have a direction. Example directed networks include the network of Web pages, the network of friendships on X, the network of citations on academic papers.</p>
<p>In a directed network, a walk must follow the edge directions. Paths, trails, and loops extend similarly to directed networks. But one thing to keep in mind: a walk may not be reversible, meaning there can be a walk from one node to another but not vice versa.</p>
<p>This leads to two different types of <code class="docutils literal notranslate"><span class="pre">connectedness</span></code> as follows:</p>
<ul class="simple">
<li><p><strong>Strong connectedness</strong>: A directed network is said to be strongly connected if there is a path from every node to every other node.</p></li>
<li><p><strong>Weak connectedness</strong>: A directed network is said to be weakly connected if there is a path from every node to every other node on its <em>undirected</em> counterpart.</p></li>
</ul>
<figure class="align-default" id="connected-components-directed">
<a class="reference internal image-reference" href="../_images/connected-component-directed.jpg"><img alt="../_images/connected-component-directed.jpg" src="../_images/connected-component-directed.jpg" style="width: 50%;" /></a>
<figcaption>
<p><span class="caption-text">connected components of a network. the nodes with the same color form a connected component.</span><a class="headerlink" href="#connected-components-directed" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Question</strong>: Is a strongly-connected component always a weakly-connected component?</p>
<p>In the next section, we will learn how to compute the shortest paths and connected components of a network using a library <a class="reference external" href="https://python.igraph.org/en/stable/">igraph</a>.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="why-is-our-social-network-small-world">
<h1>Why is our social network small world?<a class="headerlink" href="#why-is-our-social-network-small-world" title="Link to this heading">#</a></h1>
<ul class="simple">
<li><p>✍️ <a class="reference external" href="http://estebanmoro.org/pdf/netsci_for_kids/6_degrees_of_separation.pdf">It’s a small world!! 6 degrees of separation</a> <a class="footnote-reference brackets" href="#footcite-esteban-moro-worksheet" id="id65" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></p></li>
</ul>
<div class="docutils container" id="id66">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-esteban-moro-worksheet" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id65">2</a><span class="fn-bracket">]</span></span>
<p>Esteban Moro. Network science for kids! Mar 2017. URL: <a class="reference external" href="http://estebanmoro.org/2017/03/network-science-for-kids">http://estebanmoro.org/2017/03/network-science-for-kids</a>.</p>
</aside>
</aside>
</div>
<hr class="docutils" />
<section id="id67">
<h2>jupytext:
cell_metadata_filter: -all
formats: md:myst
text_representation:
extension: .Rmd
format_name: myst
format_version: 0.13
jupytext_version: 1.16.3
kernelspec:
display_name: Python 3 (ipykernel)
language: python
name: python3<a class="headerlink" href="#id67" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="small-world-experiment">
<h1>Small-world experiment<a class="headerlink" href="#small-world-experiment" title="Link to this heading">#</a></h1>
<p>How far are two people in a social network? Milgram and his colleagues conducted a series of expriment to find out in the 1960s.</p>
<figure class="align-default" id="milgram-small-world-experiment">
<a class="reference internal image-reference" href="../_images/milgram-small-world-experiment.png"><img alt="../_images/milgram-small-world-experiment.png" src="../_images/milgram-small-world-experiment.png" style="width: 70%;" /></a>
<figcaption>
<p><span class="caption-text">Milgram’s small world experiment.</span><a class="headerlink" href="#milgram-small-world-experiment" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The experiment went as follows:</p>
<ol class="arabic simple">
<li><p>Milgram first sent out packets to randomly selected people in Omaha, Nebraska, and Wichita, Kansas.</p></li>
<li><p>The recipient was asked to send the packet to the target person in Boston if they knew them. If not, they were to forward it to someone they knew on a first-name basis who might know the target.</p></li>
<li><p>The recipient continued to forward the packet to their acquaintances until it reached the target.</p></li>
</ol>
<p>The results were surprising: out of the 160 letters sent, 64 successfully reached the target person by the chain of nearly six people, which was later called <strong>six degrees of separation</strong>.
The results imply that, despite the fact that there were hundreds of millions of people in the United States, their social network was significantly compact, with two random people being connected to each other in only a few steps.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The term “Six degrees of separation” is commonly associated with Milgram’s experiment, but Milgram never used it. John Guare coined the term for his 1991 play and movie <a class="reference external" href="https://en.wikipedia.org/wiki/Six_Degrees_of_Separation_(film)">“Six Degrees of Separation.”</a></p>
</div>
<p>The results were later confirmed independently.</p>
<ul class="simple">
<li><p>Yahoo research replicate the Milgram’s experiment by using emails. Started from more than 24,000 people, only 384 people reached the one of the 18 target person in 13 countries. Among the successful ones, the average length of the chain was about 4. When taken into account the broken chain, the average length was estimated between 5 and 7.<a class="footnote-reference brackets" href="#footcite-goel2009social" id="id68" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a></p></li>
<li><p>Researchers in Facebook and University of Milan analyzed the social network n Facebook, which consisted of 721 million active users and 69 billion friendships. The average length of the shortest chain was found to be 4.74. <a class="footnote-reference brackets" href="#footcite-backstrom2012four" id="id69" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a></p></li>
</ul>
<div class="docutils container" id="id70">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-goel2009social" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id68">3</a><span class="fn-bracket">]</span></span>
<p>Sharad Goel, Roby Muhamad, and Duncan Watts. Social search in” small-world” experiments. In <em>Proceedings of the 18th international conference on World wide web</em>, 701–710. 2009.</p>
</aside>
<aside class="footnote brackets" id="footcite-backstrom2012four" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id69">4</a><span class="fn-bracket">]</span></span>
<p>Lars Backstrom, Paolo Boldi, Marco Rosa, Johan Ugander, and Sebastiano Vigna. Four degrees of separation. In <em>Proceedings of the 4th annual ACM Web science conference</em>, 33–42. 2012.</p>
</aside>
</aside>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Zachary%27s_karate_club">Zachary’s karate club</a> is a famous network of 34 members of a karate club and documents of their links between friends.
The network is undirected and unweighted.</p>
</div>
<p>The minimum spanning tree of the network can be found by the following code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gmst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">spanning_tree</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">es</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">])</span> <span class="c1"># If not `weights` are not specified, the edges are assumed to be unweighted</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gmst</span><span class="p">,</span> <span class="n">edge_width</span> <span class="o">=</span> <span class="n">gmst</span><span class="o">.</span><span class="n">es</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">])</span>
<span class="err">```</span><span class="o">---</span>
<span class="n">jupytext</span><span class="p">:</span>
  <span class="n">formats</span><span class="p">:</span> <span class="n">md</span><span class="p">:</span><span class="n">myst</span>
  <span class="n">text_representation</span><span class="p">:</span>
    <span class="n">extension</span><span class="p">:</span> <span class="o">.</span><span class="n">md</span>
    <span class="n">format_name</span><span class="p">:</span> <span class="n">myst</span>
<span class="n">kernelspec</span><span class="p">:</span>
  <span class="n">display_name</span><span class="p">:</span> <span class="n">Python</span> <span class="mi">3</span>
  <span class="n">language</span><span class="p">:</span> <span class="n">python</span>
  <span class="n">name</span><span class="p">:</span> <span class="n">python3</span>
<span class="o">---</span>

<span class="c1"># Percolation</span>

<span class="n">Network</span> <span class="n">robustness</span> <span class="n">can</span> <span class="n">be</span> <span class="n">viewed</span> <span class="k">as</span> <span class="n">a</span> <span class="n">inverse</span> <span class="n">process</span> <span class="n">of</span> <span class="o">**</span><span class="n">percolation</span><span class="o">**</span> <span class="n">on</span> <span class="n">a</span> <span class="n">network</span><span class="o">.</span> <span class="n">What</span> <span class="ow">is</span> percolation<span class="o">?</span>
<span class="n">Imagine</span> <span class="n">a</span> <span class="n">grid</span> <span class="n">where</span> <span class="n">each</span> <span class="n">square</span> <span class="n">has</span> <span class="n">a</span> <span class="n">chance</span> <span class="n">to</span> <span class="n">become</span> <span class="n">a</span> <span class="n">little</span> <span class="n">puddle</span><span class="o">.</span> <span class="n">Two</span> <span class="n">puddles</span> <span class="n">are</span> <span class="n">connected</span> <span class="k">if</span> <span class="n">they</span> <span class="n">are</span> <span class="nb">next</span> <span class="n">to</span> <span class="n">each</span> <span class="n">other</span><span class="o">.</span> <span class="n">As</span> <span class="n">more</span> <span class="n">puddles</span> <span class="n">appear</span><span class="p">,</span> <span class="n">they</span> <span class="n">start</span> <span class="n">connecting</span> <span class="k">with</span> <span class="n">their</span> <span class="n">neighbors</span> <span class="n">to</span> <span class="n">form</span> <span class="n">bigger</span> <span class="n">puddles</span><span class="o">.</span> <span class="n">This</span> <span class="ow">is</span> <span class="n">basically</span> <span class="n">what</span> <span class="n">percolation</span> <span class="ow">is</span> <span class="nb">all</span> <span class="n">about</span><span class="err">!</span>
<span class="n">Random</span> <span class="n">failure</span> <span class="n">can</span> <span class="n">be</span> <span class="n">viewed</span> <span class="k">as</span> <span class="n">an</span> <span class="n">inverse</span> <span class="n">process</span> <span class="n">of</span> <span class="n">percolation</span><span class="p">,</span> <span class="n">where</span> <span class="n">a</span> <span class="n">puddle</span> <span class="ow">is</span> <span class="n">dried</span> <span class="n">up</span> <span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">e</span><span class="o">.</span><span class="p">,</span> <span class="n">removed</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">network</span><span class="p">),</span>

<span class="err">```</span><span class="p">{</span><span class="n">figure</span><span class="o">-</span><span class="n">md</span><span class="p">}</span> <span class="n">percolation</span>

<span class="o">![](</span>https://jamesmccaffrey.wordpress.com/wp-content/uploads/2021/07/percolation.jpg?w<span class="o">=</span><span class="m">584</span><span class="p">&amp;</span><span class="nv">h</span><span class="o">=</span><span class="m">389</span><span class="o">)</span>

<span class="n">Image</span> <span class="n">taken</span> <span class="kn">from</span> <span class="nn">https</span><span class="p">:</span><span class="o">//</span><span class="n">jamesmccaffrey</span><span class="o">.</span><span class="n">wordpress</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="mi">2021</span><span class="o">/</span><span class="mi">07</span><span class="o">/</span><span class="mi">12</span><span class="o">/</span><span class="n">whatever</span><span class="o">-</span><span class="n">happened</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">percolation</span><span class="o">-</span><span class="n">theory</span><span class="o">/</span>
</pre></div>
</div>
</div>
</div>
<p>Now, the big question is: When the probability of a node being puddle is <span class="math notranslate nohighlight">\(p\)</span>, how big can our largest puddle get? 🌊
As we increase the chance of puddles appearing (that’s our <span class="math notranslate nohighlight">\(p\)</span>), the biggest puddle does not grow slowly but explodes in size when <span class="math notranslate nohighlight">\(p\)</span> reaches a critical value <span class="math notranslate nohighlight">\(p_c\)</span>. This sudden change is what we call a <em>phase transition</em>! From the percolation perspective, we approach to the critical point from disconnected phase, whereas from the network robustness perspective, we approach to the critical point from connected phase.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">igraph</span> <span class="k">as</span> <span class="nn">ig</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="k">def</span> <span class="nf">percolate</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">subgraph</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">largest_cluster_size</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">connected_components</span><span class="p">()</span><span class="o">.</span><span class="n">giant</span><span class="p">()</span><span class="o">.</span><span class="n">vcount</span><span class="p">()</span>


<span class="n">n</span><span class="p">,</span> <span class="n">nei</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">Graph</span><span class="o">.</span><span class="n">Lattice</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">],</span> <span class="n">nei</span><span class="o">=</span><span class="n">nei</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mutual</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">circular</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">p_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">largest_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">largest_cluster_size</span><span class="p">(</span><span class="n">percolate</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span> <span class="o">/</span> <span class="n">n</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">p_values</span><span class="p">]</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;ticks&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">p_values</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">largest_sizes</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Probability (p)&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Fractional Largest Cluster Size&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Percolation on a 500x500 Lattice&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>

<span class="n">critical_p</span> <span class="o">=</span> <span class="mf">0.592746</span>  <span class="c1"># Critical probability for 2D square lattice</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;colorblind&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">critical_p</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_betweenx</span><span class="p">(</span>
    <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">x1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">x2</span><span class="o">=</span><span class="n">critical_p</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Disconnected&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_betweenx</span><span class="p">(</span>
    <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">x1</span><span class="o">=</span><span class="n">critical_p</span><span class="p">,</span> <span class="n">x2</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Connected&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
    <span class="s2">&quot;Disconnected&quot;</span><span class="p">,</span>
    <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
    <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
    <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
    <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
    <span class="n">verticalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span>
    <span class="n">fontweight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
    <span class="s2">&quot;Connected&quot;</span><span class="p">,</span>
    <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
    <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
    <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
    <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
    <span class="n">verticalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span>
    <span class="n">fontweight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Want to see this in action? 🌟 Check out this interactive simulation.
Play around with it and watch how the puddles grow and connect. 🌊</p>
<p><a class="reference external" href="https://visualize-it.github.io/bernoulli_percolation/simulation.html">Bernoulli Percolation Simulation 🌐</a> 🔗</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The transition at <span class="math notranslate nohighlight">\(p_c\)</span> is discontinuous in the limit of large <span class="math notranslate nohighlight">\(N\)</span>, called <em>first-order phase transition</em>.
In practice, it is often a continuous transition because of the finite size of the network.</p>
</div>
<section id="a-criterion-for-the-giant-component">
<h2>A criterion for the giant component<a class="headerlink" href="#a-criterion-for-the-giant-component" title="Link to this heading">#</a></h2>
<p>Percolation theory focuses on lattice, a regular structure that is rare in real-world networks. What happens if the network has a complex structure?
The Molloy-Reed criterion <a class="footnote-reference brackets" href="#footcite-molloy1995critical" id="id71" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a> provides a simple condition for the existence of a giant component in a rewired network. It states that a giant component is likely to exist if:</p>
<div class="math notranslate nohighlight">
\[
\kappa_0 := \frac{\langle k^2 \rangle}{\langle k \rangle} &gt; 2
\]</div>
<p>where <span class="math notranslate nohighlight">\(k\)</span> is the degree of a node, and <span class="math notranslate nohighlight">\(\langle k \rangle\)</span> and <span class="math notranslate nohighlight">\(\langle k^2 \rangle\)</span> are the average degree and the average of the square of the degree, respectively. The variable <span class="math notranslate nohighlight">\(\kappa_0\)</span> is a shorthand for the ratio. See the <a class="reference internal" href="#./appendix.md"><span class="xref myst">Appendix</span></a> for the derivation of this criterion.</p>
<p>What does <span class="math notranslate nohighlight">\(\kappa_0\)</span> represent? It represents the heterogeneity of the degree distribution. For example, a high <span class="math notranslate nohighlight">\(\kappa_0\)</span> indicates that there are a few nodes with very high degrees and many nodes with low degrees. When <span class="math notranslate nohighlight">\(\kappa_0\)</span> is small, the nodes have similar degree. And Molloy-Reed criterion tells us an important fact about the role of degree distributions on the robustness of networks:
the more heterogeneous the degree distribution is, the more likely the network is to have a giant component.</p>
<div class="cell tag_remove-input docutils container">
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The rewired network considered here is <strong>the configuration model</strong>, where the edges are rewired randomly while keeping the degree distribution fixed. We will discuss more about the configuration model later.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Exercise</p>
<p>Consider a random network of <span class="math notranslate nohighlight">\(N\)</span> nodes, where every pair of nodes are connected by an edge with a certain probability.
Then, the degree <span class="math notranslate nohighlight">\(k\)</span> of a node is a binomial random variable, which we approximate by a Poisson random variable with mean <span class="math notranslate nohighlight">\(\langle k \rangle\)</span>. The variance of the Poisson random variable is also <span class="math notranslate nohighlight">\(\langle k \rangle\)</span>.</p>
<ol class="arabic simple">
<li><p>Derive <span class="math notranslate nohighlight">\(\langle k^2 \rangle\)</span> using <span class="math notranslate nohighlight">\(\langle k \rangle\)</span>.</p></li>
</ol>
<ul class="simple">
<li><p>Hint: Variance is defined as <span class="math notranslate nohighlight">\(\text{Var}(k) = \langle (k-\langle k \rangle)^2 \rangle\)</span>.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Compute the ratio <span class="math notranslate nohighlight">\(\frac{\langle k^2 \rangle}{\langle k \rangle}\)</span>.</p></li>
<li><p>Check when the network satisfies the Molloy-Reed criterion.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Solution<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Solution for Q1</strong>:
To derive <span class="math notranslate nohighlight">\(\langle k^2 \rangle\)</span>, we start with the definition of variance</p>
<div class="math notranslate nohighlight">
\[\text{Var}(k) = \langle (k - \langle k \rangle)^2 \rangle\]</div>
<p class="sd-card-text">Expanding the square, we get</p>
<div class="math notranslate nohighlight">
\[\text{Var}(k) = \langle k^2 \rangle - 2\langle k \rangle \langle k \rangle + \langle k \rangle^2\]</div>
<p class="sd-card-text">Since <span class="math notranslate nohighlight">\(\text{Var}(k) = \langle k \rangle\)</span> for a Poisson distribution, we can substitute and rearrange</p>
<div class="math notranslate nohighlight">
\[\langle k \rangle = \langle k^2 \rangle - \langle k \rangle^2\]</div>
<p class="sd-card-text">Solving for <span class="math notranslate nohighlight">\(\langle k^2 \rangle\)</span>, we obtain</p>
<div class="math notranslate nohighlight">
\[\langle k^2 \rangle = \langle k \rangle + \langle k \rangle^2\]</div>
<p class="sd-card-text"><strong>Solution for Q2</strong>:
<span class="math notranslate nohighlight">\(\frac{\langle k^2 \rangle}{\langle k \rangle} = 1 + \langle k \rangle\)</span></p>
<p class="sd-card-text"><strong>Solution for Q3</strong>:
<span class="math notranslate nohighlight">\(\langle k \rangle &gt;1\)</span>. In other words, if a node has on average more than one neighbor, the random network is likely to have a giant component.</p>
</div>
</details></div>
</section>
<section id="how-many-nodes-are-needed-to-break-a-network">
<h2>How many nodes are needed to break a network?<a class="headerlink" href="#how-many-nodes-are-needed-to-break-a-network" title="Link to this heading">#</a></h2>
<p>When does a network become disconnected? Based on the Molloy-Reed criterion, we can identify the critical fraction of nodes <span class="math notranslate nohighlight">\(f_c\)</span> that need to be removed for the giant component to disappear in a network with an arbitrary degree distribution. This critical point is given by <a class="footnote-reference brackets" href="#footcite-cohen2000resilience" id="id72" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a>:</p>
<div class="math notranslate nohighlight">
\[
f_c = 1 - \frac{1}{\frac{\langle k^2 \rangle}{\langle k \rangle} - 1}
\]</div>
<p>See the <a class="reference internal" href="#./appendix.md"><span class="xref myst">Appendix</span></a> for the derivation of this criterion.</p>
<p>Let us illustrate this by considering two kinds of networks:</p>
<p><strong>Degree homogeneous network</strong>:</p>
<p>In case of a degree homogeneous network like a random network considered in the exercise above,</p>
<div class="math notranslate nohighlight">
\[
f_c = 1 - \frac{1}{\langle k \rangle}
\]</div>
<p>This suggests that the threshold is determined by the average degree <span class="math notranslate nohighlight">\(\langle k \rangle\)</span>. A large <span class="math notranslate nohighlight">\(\langle k \rangle\)</span> results in a larger <span class="math notranslate nohighlight">\(f_c\)</span>, meaning that the network is more robust against random failures.</p>
<p><strong>Degree heterogeneous network</strong>:</p>
<p>Most real-world networks are degree heterogeneous, i.e., the degree distribution <span class="math notranslate nohighlight">\(P(k) \sim k^{-\gamma}\)</span> follows a power law (called <em>scale-free</em> network).
In this case, <span class="math notranslate nohighlight">\(f_c\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
f_c =
\begin{cases}
1 - \dfrac{1}{\frac{\gamma-2}{3-\gamma} k_{\text{min}} ^{\gamma-2} k_{\text{max}}^{3-\gamma} -1} &amp; \text{if } 2 &lt; \gamma &lt; 3 \\
1 - \dfrac{1}{\frac{\gamma-2}{3-\gamma} k_{\text{min}} - 1} &amp; \text{if } \gamma &gt; 3 \\
\end{cases}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(k_{\text{min}}\)</span> and <span class="math notranslate nohighlight">\(k_{\text{max}}\)</span> are the minimum and maximum degree, respectively.
The variable <span class="math notranslate nohighlight">\(\gamma\)</span> is the exponent of the power law degree distribution, controlling the degree heterogeneity, where a lower <span class="math notranslate nohighlight">\(\gamma\)</span> results in a more degree heterogeneous network.</p>
<ul class="simple">
<li><p>For regime <span class="math notranslate nohighlight">\(2 &lt; \gamma &lt; 3\)</span>, the critical threshold <span class="math notranslate nohighlight">\(f_c\)</span> is determined by the extreme values of the degree distribution, <span class="math notranslate nohighlight">\(k_{\text{min}}\)</span> and <span class="math notranslate nohighlight">\(k_{\text{max}}\)</span>.
And <span class="math notranslate nohighlight">\(f_c \rightarrow 1\)</span> when the maximum degree <span class="math notranslate nohighlight">\(k_{\text{max}} \in [k_{\text{min}}, N-1]\)</span> increases.
Notably, in this regime, the maximum degree <span class="math notranslate nohighlight">\(k_{\text{max}}\)</span> increases as the network size <span class="math notranslate nohighlight">\(N\)</span> increases, and this makes <span class="math notranslate nohighlight">\(f_c \rightarrow 1\)</span>.</p></li>
<li><p>For regime <span class="math notranslate nohighlight">\(\gamma &gt; 3\)</span>, the critical threshold <span class="math notranslate nohighlight">\(f_c\)</span> is influenced by the minimum degree <span class="math notranslate nohighlight">\(k_{\text{min}}\)</span>. In contrast to <span class="math notranslate nohighlight">\(k_{\text{max}}\)</span>, <span class="math notranslate nohighlight">\(k_{\text{min}}\)</span> remains constant as the network size <span class="math notranslate nohighlight">\(N\)</span> grows. Consequently, the network disintegrates when a finite fraction of its nodes are removed.</p></li>
</ul>
</section>
<section id="case-study-airport-network">
<h2>Case study: Airport network<a class="headerlink" href="#case-study-airport-network" title="Link to this heading">#</a></h2>
<p>Let’s consider an empirical network of international airports, where nodes are airports and edges denote a regular commercial flight between two airports.</p>
<p>Data loading:</p>
<div class="cell tag_hide-input tag_hide-output docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import necessary libraries</span>
<span class="kn">import</span> <span class="nn">igraph</span> <span class="k">as</span> <span class="nn">ig</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Load the airport network data from a CSV file</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/skojaku/core-periphery-detection/master/data/edge-table-airport.csv&quot;</span><span class="p">)</span>

<span class="c1"># Process the edge data</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;source&quot;</span><span class="p">,</span> <span class="s2">&quot;target&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">edges</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">edges</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># Create the original graph</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_vertices</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_edges</span><span class="p">([</span><span class="nb">tuple</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span> <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">])</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Based on the argument above, we can predict the critical point <span class="math notranslate nohighlight">\(f_c\)</span> for the airport network as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">g</span> <span class="c1"># igraph object of the airport network</span>

<span class="c1"># Compute the degree distribution</span>
<span class="n">deg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">degree</span><span class="p">())</span>

<span class="n">k_ave</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">deg</span><span class="p">)</span>
<span class="n">k_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">deg</span> <span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Compute the critical fraction of nodes that need to be removed (prediction)</span>
<span class="n">f_c</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">k_2</span> <span class="o">/</span> <span class="n">k_ave</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The critical fraction of nodes that need to be removed is predicted to be </span><span class="si">{</span><span class="n">f_c</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The <span class="math notranslate nohighlight">\(f_c\)</span> is very close to 1, meaning that the network is highly robust to random failures that it keeps the giant component until when almost all nodes are removed.
Let us confirm this by simulating the random failures.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a copy of the original graph for manipulation</span>
<span class="n">g_damaged</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">n_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">()</span>  <span class="c1"># Number of nodes in the graph</span>

<span class="c1"># Initialize list to store results</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Simulate random node removal and measure network connectivity</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>  <span class="c1"># Loop until only one node remains</span>

    <span class="c1"># Randomly select and remove a node</span>
    <span class="n">node_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">g_damaged</span><span class="o">.</span><span class="n">vs</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
    <span class="n">g_damaged</span><span class="o">.</span><span class="n">delete_vertices</span><span class="p">(</span><span class="n">node_idx</span><span class="p">)</span>

    <span class="c1"># Evaluate the connectivity of the remaining network</span>
    <span class="n">components</span> <span class="o">=</span> <span class="n">g_damaged</span><span class="o">.</span><span class="n">connected_components</span><span class="p">()</span>
    <span class="n">connectivity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">components</span><span class="o">.</span><span class="n">sizes</span><span class="p">())</span> <span class="o">/</span> <span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">()</span>

    <span class="c1"># Save the results</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;connectivity&quot;</span><span class="p">:</span> <span class="n">connectivity</span><span class="p">,</span>
            <span class="s2">&quot;frac_nodes_removed&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_nodes</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>

<span class="c1"># Convert results to a DataFrame</span>
<span class="n">df_robustness_profile</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="c1"># Set up the plot style</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;ticks&#39;</span><span class="p">)</span>

<span class="c1"># Create the plot</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">df_robustness_profile</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;frac_nodes_removed&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;connectivity&quot;</span><span class="p">,</span>
    <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;line&quot;</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random attack&quot;</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">color</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Set labels for x and y axes</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Proportion of nodes removed&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Fractional size of largest component&quot;</span><span class="p">)</span>

<span class="c1"># Remove the legend</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>

<span class="c1"># Add a diagonal line from top left to bottom right</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="c1"># Adjust the plot limits to ensure the diagonal line is visible</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Add a vertical line at the critical fraction</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">f_c</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Critical fraction&quot;</span><span class="p">)</span>

<span class="c1"># Remove top and right spines of the plot</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>The robustness profile of the airport network shows a very robust nature of the network, i.e., the airport network keeps the giant component until almost all nodes are removed.</p>
</section>
<section id="targeted-attacks">
<h2>Targeted attacks<a class="headerlink" href="#targeted-attacks" title="Link to this heading">#</a></h2>
<p>A key implication of the random failures is that a hub plays a critical role in holding the network together. This also implies a vulnerability of the network to targeted attacks. Namely, if we remove the hub preferentially, the network can be quickly disconnected into small components.</p>
<p>One can consider a targeted attack as a process of reducing the degree of nodes in a network. The degree-based attack, for example, reduces the maximum degree of the network, together with the degrees of neighboring nodes.
An effective attack is one that quickly breaks the Molloy-Reed criterion, and from this perspective, the degree-based attack is not effective because it reduces the maximum degree of the network, a major contributor to the degree heterogeneity, <span class="math notranslate nohighlight">\(\kappa_0\)</span>.</p>
</section>
<section id="how-to-design-a-robust-network">
<h2>How to design a robust network?<a class="headerlink" href="#how-to-design-a-robust-network" title="Link to this heading">#</a></h2>
<p>Based on the percolation theory, how we do we design a network that is robust against random failures and targeted attacks? Two key ingredients are:</p>
<ol class="arabic simple">
<li><p><strong>Degree heterogeneity</strong>: As we have seen in the percolation theory, the more heterogeneous the degree distribution is, the more likely the network is to have a giant component.</p></li>
<li><p><strong>Resilience to hub removal</strong>: A network is vulnerable to targeted attacks if the removal of a single node significantly decreases the heterogeneity of the degree distribution. The most susceptible structure is a star graph, where a central node connects to all other nodes, as removing this central node will disconnect the network.</p></li>
</ol>
<div class="tip admonition">
<p class="admonition-title">Exercise</p>
<p>What is the design strategy to make a network robust against targeted attacks?
Design a network that is robust against both random failures and targeted attacks.</p>
<p><a class="reference external" href="https://skojaku.github.io/adv-net-sci/vis/network-robustness.html">🚀 Interactive Demo</a></p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
An answer<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">A bimodal degree distribution can enhance network robustness against both random failures and targeted attacks.
In this setup, <span class="math notranslate nohighlight">\((1-r)\)</span> portion of nodes have a degree of 1, while <span class="math notranslate nohighlight">\(r\)</span> portion of nodes have a high degree, <span class="math notranslate nohighlight">\(k_{\text{max}}\)</span>.
This structure ensures that the network remains connected even if a hub is removed, as other hubs maintain the connectivity. It also withstands random failures due to its heterogeneous degree distribution.</p>
</div>
</details></div>
<div class="docutils container" id="id73">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-molloy1995critical" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id71">5</a><span class="fn-bracket">]</span></span>
<p>Michael Molloy and Bruce Reed. A critical point for random graphs with a given degree sequence. <em>Random structures &amp; algorithms</em>, 6(2-3):161–180, 1995.</p>
</aside>
<aside class="footnote brackets" id="footcite-cohen2000resilience" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id72">6</a><span class="fn-bracket">]</span></span>
<p>Reuven Cohen, Keren Erez, Daniel Ben-Avraham, and Shlomo Havlin. Resilience of the internet to random breakdowns. <em>Physical review letters</em>, 85(21):4626, 2000.</p>
</aside>
</aside>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="hands-on-robustness-random-attack">
<h1>Hands-on: Robustness (Random attack)<a class="headerlink" href="#hands-on-robustness-random-attack" title="Link to this heading">#</a></h1>
<p>We consider a small social network of 34 members in a university karate club, called Zachary’s karate club network.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">igraph</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">igraph</span><span class="o">.</span><span class="n">Graph</span><span class="o">.</span><span class="n">Famous</span><span class="p">(</span><span class="s2">&quot;Zachary&quot;</span><span class="p">)</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vertex_size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s break the network 😈!
We will remove nodes one by one and see how the connectivity of the network changes at each step.
It is useful to create a copy of the network to keep the original network unchanged.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g_original</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="robustness-against-random-failures">
<h2>Robustness against random failures<a class="headerlink" href="#robustness-against-random-failures" title="Link to this heading">#</a></h2>
<p>Let us remove a single node from the network. To this end, we need to first identify which nodes are in the network. With <code class="docutils literal notranslate"><span class="pre">igraph</span></code>, the IDs of the nodes in a graph are accessible through <code class="docutils literal notranslate"><span class="pre">Graph.vs.indices</span></code> as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">vs</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We randomly choose a node and remove it from the network by using <code class="docutils literal notranslate"><span class="pre">Graph.delete_vertices</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">node_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">vs</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">delete_vertices</span><span class="p">(</span><span class="n">node_idx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Node removed:&quot;</span><span class="p">,</span> <span class="n">node_idx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Nodes remaining:&quot;</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">vs</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">np.random.choice(array)</span></code> takes an array <code class="docutils literal notranslate"><span class="pre">array</span></code> and returns a single element from the array.
For example, <code class="docutils literal notranslate"><span class="pre">np.random.choice(np.array([1,</span> <span class="pre">2,</span> <span class="pre">3]))</span></code> returns either 1, 2, or 3 with equal probability.
See <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html">the documentation</a> for more details.</p>
</div>
<p>The connectivity of the network is the fraction of nodes in the largest connected component of the network after node removal.
We can get the connected components of the network by using <code class="docutils literal notranslate"><span class="pre">Graph.connected_components</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">components</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">connected_components</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The sizes of the connected components are accessible via <code class="docutils literal notranslate"><span class="pre">Graph.connected_components.sizes</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">components</span><span class="o">.</span><span class="n">sizes</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Thus, the connectivity of the network can be computed by</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">components</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">connected_components</span><span class="p">()</span>
<span class="n">connectivity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">components</span><span class="o">.</span><span class="n">sizes</span><span class="p">())</span> <span class="o">/</span> <span class="n">g_original</span><span class="o">.</span><span class="n">vcount</span><span class="p">()</span>
<span class="n">connectivity</span>
</pre></div>
</div>
</div>
</div>
<p>Putting together the above code, let us compute the robustness profile of the network.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">g_original</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># restore the network</span>
<span class="n">n_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">()</span>  <span class="c1"># Number of nodes</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>  <span class="c1"># Loop if the network has at least one node</span>

    <span class="c1"># Remove a randomly selected node</span>
    <span class="n">node_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">vs</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
    <span class="n">g</span><span class="o">.</span><span class="n">delete_vertices</span><span class="p">(</span><span class="n">node_idx</span><span class="p">)</span>

    <span class="c1"># Evaluate the connectivity</span>
    <span class="n">components</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">connected_components</span><span class="p">()</span>
    <span class="n">connectivity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">components</span><span class="o">.</span><span class="n">sizes</span><span class="p">())</span> <span class="o">/</span> <span class="n">g_original</span><span class="o">.</span><span class="n">vcount</span><span class="p">()</span>

    <span class="c1"># Save the results</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;connectivity&quot;</span><span class="p">:</span> <span class="n">connectivity</span><span class="p">,</span>
            <span class="s2">&quot;frac_nodes_removed&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_nodes</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>

<span class="n">df_robustness_profile</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us plot the robustness profile.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;ticks&#39;</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">df_robustness_profile</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;frac_nodes_removed&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;connectivity&quot;</span><span class="p">,</span>
    <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;line&quot;</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random attack&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Proportion of nodes removed&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Connectivity&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="targeted-attack">
<h2>Targeted attack<a class="headerlink" href="#targeted-attack" title="Link to this heading">#</a></h2>
<p>In a targeted attack, nodes are removed based on specific criteria rather than randomly.
One common strategy is to remove nodes from the largest node degree to the smallest, based on the idea that removing nodes with many edges is more likely to disrupt the network connectivity.</p>
<p>The degree of the nodes is accessible via <code class="docutils literal notranslate"><span class="pre">Graph.degree</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">g_original</span><span class="o">.</span><span class="n">degree</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>We compute the robustness profile by removing nodes with the largest degree and measuring the connectivity of the network after each removal.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">g_original</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># restore the network</span>
<span class="n">n_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">()</span>  <span class="c1"># Number of nodes</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>  <span class="c1"># Loop if the network has at least one node</span>

    <span class="c1"># Remove the nodes with thelargest degree</span>
    <span class="n">node_idx</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">vs</span><span class="o">.</span><span class="n">indices</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">degree</span><span class="p">())]</span>
    <span class="n">g</span><span class="o">.</span><span class="n">delete_vertices</span><span class="p">(</span><span class="n">node_idx</span><span class="p">)</span>

    <span class="c1"># Evaluate the connectivity</span>
    <span class="n">components</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">connected_components</span><span class="p">()</span>
    <span class="n">connectivity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">components</span><span class="o">.</span><span class="n">sizes</span><span class="p">())</span> <span class="o">/</span> <span class="n">g_original</span><span class="o">.</span><span class="n">vcount</span><span class="p">()</span>

    <span class="c1"># Save the results</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;connectivity&quot;</span><span class="p">:</span> <span class="n">connectivity</span><span class="p">,</span>
            <span class="s2">&quot;frac_nodes_removed&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_nodes</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>

<span class="n">df_robustness_profile_targeted</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;ticks&#39;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;ticks&quot;</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">df_robustness_profile</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;frac_nodes_removed&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;connectivity&quot;</span><span class="p">,</span>
    <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;line&quot;</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random attack&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">df_robustness_profile_targeted</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;frac_nodes_removed&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;connectivity&quot;</span><span class="p">,</span>
    <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;line&quot;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Targeted attack&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Proportion of nodes removed&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Connectivity&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="while-the-network-is-robust-against-the-random-attacks-it-is-vulnerable-to-the-degree-based-targeted-attack-jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">
<h2>While the network is robust against the random attacks, it is vulnerable to the degree-based targeted attack.—
jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3<a class="headerlink" href="#while-the-network-is-robust-against-the-random-attacks-it-is-vulnerable-to-the-degree-based-targeted-attack-jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="network-robustness">
<h1>Network Robustness<a class="headerlink" href="#network-robustness" title="Link to this heading">#</a></h1>
<p>Nodes and edges can fail or be attacked, which disrupt the connectivity of a network.
Roughly speaking, we say a network is robust if it maintain most of its connectivity after failures or attacks.
There are different types of attacks, together with how we quantify the damage they cause. So let us first showcase a case study with code.</p>
<section id="random-node-failures">
<h2>Random node failures<a class="headerlink" href="#random-node-failures" title="Link to this heading">#</a></h2>
<p>Nodes can fail and disconnect from networks, such as power station closures in power grids. This is modeled as a <strong>random failure</strong>, where randomly chosen nodes are removed from the network. When a node fails, it and its edges are removed.</p>
<p>The damage varies depending on the node to be removed. The damage to the network can be measued in many different ways, but an accepted measure is the loss of <strong>connectivity</strong>, defined as the fraction of nodes left in the largest connected part of the network after the failure.</p>
<figure class="align-default" id="single-node-failure">
<a class="reference internal image-reference" href="../_images/single-node-failure.jpg"><img alt="Single node failure" src="../_images/single-node-failure.jpg" style="width: 70%;" /></a>
<figcaption>
<p><span class="caption-text">The impact of removing a single node varies based on which node is removed.</span><a class="headerlink" href="#single-node-failure" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Multiple nodes can fail simultaneously, e.g., due to natural disasters like earthquakes or tsunamis.
Thus it is often useful to assess the robustness of the network against such failures.
<strong>Robustness profile</strong> is a plot of the connectivity drop as a function of the number of nodes removed. It provides a visual summary of the robustness of the network against <em>a given sequential failure of nodes</em>.
In random failure, the order of nodes removed is random.</p>
<figure class="align-default" id="multiple-node-failure">
<a class="reference internal image-reference" href="../_images/robustness-profile.jpg"><img alt="Multiple node failure" src="../_images/robustness-profile.jpg" style="width: 70%;" /></a>
<figcaption>
<p><span class="caption-text">Robustness profile of a network for a sequential failure of nodes.</span><a class="headerlink" href="#multiple-node-failure" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Beyond the qualitative observation, it is useful to quantify the robustness of the network.
The <strong><span class="math notranslate nohighlight">\(R\)</span>-index</strong> is a single number that summarizes the robustness of the network.
It is defined as the area under the connectivity curve with integral approximation.</p>
<div class="math notranslate nohighlight">
\[
R = \frac{1}{N} \sum_{k=1}^{N-1} y_k
\]</div>
<p>where <span class="math notranslate nohighlight">\(y_k\)</span> is the connectivity at fraction <span class="math notranslate nohighlight">\(k/N\)</span> of nodes removed, where <span class="math notranslate nohighlight">\(N\)</span> is the total number of nodes in the network. A higher value indicates that the network is robust against the attack. The <span class="math notranslate nohighlight">\(R\)</span>-index has a maximum value of 1/2 (i.e., which corresponds to a diagonal line in the plot above).</p>
</section>
<section id="id74">
<h2>Targeted attack<a class="headerlink" href="#id74" title="Link to this heading">#</a></h2>
<p>A network robust against random failures can still be fragmented by <strong>targeted attacks</strong>.
In targeted attacks, nodes are removed based on specific criteria rather than randomly.
For example, nodes can be removed in order of their degree, starting with the largest degree to the smallest degree. The rationale for this attack strategy is that large-degree nodes have many connections, so removing them disrupts the network more significantly.</p>
<p>Degree-based attack is not the only form of targeted attacks. Other forms of targeted attacks include removing nodes based on their centrality (closeness centrality, betweenness centrality) and those based on proximity.</p>
</section>
<section id="whats-next">
<h2>What’s next?<a class="headerlink" href="#whats-next" title="Link to this heading">#</a></h2>
<p>In the next section, we will code up a simple example to compute the robustness profile of a network using Python.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="module-3-robustness">
<h1>Module 3: Robustness<a class="headerlink" href="#module-3-robustness" title="Link to this heading">#</a></h1>
<section id="what-to-learn-in-this-module">
<h2>What to learn in this module<a class="headerlink" href="#what-to-learn-in-this-module" title="Link to this heading">#</a></h2>
<p>In this module, we will learn about network robustness. We will learn:</p>
<ul class="simple">
<li><p>Minimum spanning tree</p></li>
<li><p>Network robustness against random and targeted attacks</p></li>
<li><p><strong>Keywords</strong>: minimum spanning tree, Kruskal’s algorithm, Prim’s algorithm, random attacks, targeted attacks, network robustness, robustness index—
jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</p></li>
</ul>
<hr class="docutils" />
<a target="_blank" href="https://colab.research.google.com/github/skojaku/adv-net-sci/blob/main/notebooks/exercise-m04-friendship-paradox.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="degree-distribution">
<h1>Degree distribution<a class="headerlink" href="#degree-distribution" title="Link to this heading">#</a></h1>
<p><img alt="" src="https://barabasi.com/img/6/159.png" /></p>
<p>Understanding degree distribution is the first key step to understand networks! And often, we want to see how the degree distribution looks like by plotting it like using histogram. But, it is not as easy as it may seem…</p>
<section id="visualization-basics">
<h2>Visualization basics<a class="headerlink" href="#visualization-basics" title="Link to this heading">#</a></h2>
<p>To learn the basics of data visualization, please take a <a class="reference internal" href="#./pen-and-paper/exercise.pdf"><span class="xref myst">pen and paper exercise</span></a>.</p>
</section>
<section id="coding-exercise">
<h2>Coding exercise<a class="headerlink" href="#coding-exercise" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://github.com/skojaku/adv-net-sci/blob/main/notebooks/exercise-m04-friendship-paradox.ipynb">Exercise: Plotting degree distribution</a></p>
<section id="plotting-degree-distribution">
<h3>Plotting degree distribution<a class="headerlink" href="#plotting-degree-distribution" title="Link to this heading">#</a></h3>
<p>(The following content includes the answer to the exercise. So please do the exercise first before reading the following content.)</p>
<p>We will first introduce a formal definition of the degree distribution. Then, we will learn how to plot the degree distribution of a network.</p>
<p>The degree of a node <span class="math notranslate nohighlight">\(i\)</span>, denoted by <span class="math notranslate nohighlight">\(d_i\)</span>, is the number of edges connected to it. With the adjacency matrix <span class="math notranslate nohighlight">\(A\)</span>, the degree of node <span class="math notranslate nohighlight">\(i\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[
k_i = \sum_{j=1}^N A_{ij}.
\]</div>
<p>Let us compute the degree distribution of a network. We will create a Barabási-Albert network with <span class="math notranslate nohighlight">\(N=10,000\)</span> nodes and <span class="math notranslate nohighlight">\(m=1\)</span> edge per node.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">igraph</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">igraph</span><span class="o">.</span><span class="n">Graph</span><span class="o">.</span><span class="n">Barabasi</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Create a Barabási-Albert network</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_adjacency</span><span class="p">()</span> <span class="c1"># Get the adjacency matrix</span>
</pre></div>
</div>
</div>
</div>
<p>Compute the degree of each node by summing the elements of the adjacency matrix along the rows.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">deg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">deg</span> <span class="o">=</span> <span class="n">deg</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The degree distribution <span class="math notranslate nohighlight">\(p(k)\)</span> can be computed by counting the number of nodes with each degree and dividing by the total number of nodes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p_deg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">deg</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">deg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us plot the degree distribution. This is not as trivial as you might think… 🤔</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">p_deg</span><span class="p">)),</span> <span class="n">y</span><span class="o">=</span><span class="n">p_deg</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Degree&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>While it clearly shows that most nodes have small degree, it does not show the tail of the distribution clearly, and often it is this tail that is of great interest (e.g., hub nodes). To show the tail of the distribution more clearly, we can use a log-log plot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">p_deg</span><span class="p">)),</span> <span class="n">y</span><span class="o">=</span><span class="n">p_deg</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">p_deg</span><span class="p">[</span><span class="n">p_deg</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="mf">0.01</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Degree&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We see fluctuations for large degree nodes because of the small number of nodes with large degree.
One can use “binning” to smooth the plot. Binning involves grouping the data into bins and calculating the fraction of data within each bin. However, selecting an appropriate bin size can be challenging, and even with a well-chosen bin size, some information may be lost.</p>
<p>A more convenient way is to use the complementary cumulative distribution function (CCDF).
The CCDF at degree <span class="math notranslate nohighlight">\(k\)</span> is the probability that a randomly chosen node has degree <span class="math notranslate nohighlight">\(k'\)</span> greater than <span class="math notranslate nohighlight">\(k\)</span> (<span class="math notranslate nohighlight">\(k' &gt; k\)</span>).  For a visual comparison of CCDF and PDF, see Figure 3 in <a class="footnote-reference brackets" href="#footcite-newman2005power" id="id75" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a> or <a class="reference external" href="https://arxiv.org/pdf/cond-mat/0412004">the arxiv version</a></p>
<div class="math notranslate nohighlight">
\[
\text{CCDF}(k) = P(k' &gt; k) = \sum_{k'=k+1}^\infty p(k')
\]</div>
<ul class="simple">
<li><p>CCDF is a monotonically decreasing function of <span class="math notranslate nohighlight">\(k\)</span>.</p></li>
<li><p>CCDF encompasses the full information of <span class="math notranslate nohighlight">\(p(k)\)</span>, i.e., taking the derivative of CCDF gives <span class="math notranslate nohighlight">\(p(k)\)</span>.</p></li>
<li><p>CCDF can be plotted as a smooth curve on a log-log scale without binning.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ccdf_deg</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">p_deg</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 1 - CDF (cumulative distribution function).</span>
<span class="c1"># The last element is excluded because it is always 1, resulting in CCDF=0, which cannot be plotted on a log-log scale.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ccdf_deg</span><span class="p">)),</span> <span class="n">y</span><span class="o">=</span><span class="n">ccdf_deg</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Degree&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;CCDF&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>CCDF (complementary cumulative distribution function) is used instead of CDF (cumulative distribution function) because it highlights the tail of the distribution better in a log-log plot. A log scale expands small values and compresses large values. In a CDF, large degree nodes have values close to 1, compressing the tail. In a CCDF, large degree nodes have small values, making the tail more visible.</p>
</div>
<p>The slope of the CCDF tells us the heterogeneity of the degree distribution.</p>
<ul class="simple">
<li><p>Steep slope: more <strong>homogeneous</strong> degree distribution (similar degrees)</p></li>
<li><p>Flat slope: more <strong>heterogeneous</strong> degree distribution (wide range of degrees)</p></li>
</ul>
<p>The slope of the CCDF is related to the power-law exponent of the degree distribution.
A power-law degree distribution is described by <em>a continuous distribution</em> with the <em>density function</em> (not the probability mass) <span class="math notranslate nohighlight">\(p(d)\)</span> given by <a class="footnote-reference brackets" href="#footcite-clauset2009power" id="id76" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a>:</p>
<div class="math notranslate nohighlight">
\[
p(k) = \frac{\gamma-1}{k_{\min}} \left( \frac{k}{k_{\min}} \right)^{-\gamma}
\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(p(k)\)</span> is the probability <em>density</em> of a node having degree <span class="math notranslate nohighlight">\(k\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\gamma\)</span> is the power-law exponent</p></li>
<li><p><span class="math notranslate nohighlight">\(k_{\min}\)</span> is the minimum degree</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The degree distribution is <em>discrete</em> but often approximated by a <em>continuous</em> distribution for mathematical convenience. While generally accurate, caution is needed as the reliability varies depending on the range of the degrees. See <a class="footnote-reference brackets" href="#footcite-clauset2009power" id="id77" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a> for more details.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The power-law distribution is ill-defined for <span class="math notranslate nohighlight">\(d=0\)</span>, which is why there must be a minimum degree <span class="math notranslate nohighlight">\(d_{\min}\)</span> to avoid this issue.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There has been a long-standing debate in network science as to whether the power-law well represents the real-world networks. Power-law is just one of many possible distributions with a heavy tail (i.e., a long tail on the right side of the distribution), and other distributions may also fit the data well such as log-normal distribution.
This discussion is critical as many theories in network science are built on the assumption of the form of the degree distribution. See <a class="footnote-reference brackets" href="#footcite-artico2020rare" id="id78" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-holme2019rare" id="id79" role="doc-noteref"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-voitalov2019scale" id="id80" role="doc-noteref"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-barabasi2003scale" id="id81" role="doc-noteref"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></a> for the debate.</p>
</div>
<p>The CCDF for the power-law distribution is given by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\text{CCDF}(k) &amp;= 1 - \int_{k_{\min}}^k p(x) {\rm d}x \\
  &amp;= 1 - \frac{\gamma -1}{k_{\min}}\cdot \frac{1}{1 - \gamma} \left[
\left(\frac{k^{-\gamma + 1}}{k_{\min}^{-\gamma}}\right) - \left(\frac{k_{\min} ^{-\gamma + 1}}{k_{\min} ^{-
\gamma}}\right)\right] \\
&amp;= \left( \frac{k}{k_{\min}}\right)^{-\gamma + 1}
\end{aligned}
\end{split}\]</div>
<p>Taking the logarithm:</p>
<div class="math notranslate nohighlight">
\[
\log \left[ \text{CCDF}(k) \right] = (-\gamma + 1) \cdot \log k + \text{const.}
\]</div>
<p>Thus, the slope of the CCDF in a log-log plot is related to the power-law exponent <span class="math notranslate nohighlight">\(\gamma\)</span>.
Specifically, a steeper negative slope (i.e., a more negative value of <span class="math notranslate nohighlight">\(-\gamma + 1\)</span>) corresponds to a larger <span class="math notranslate nohighlight">\(\gamma\)</span>.
A larger <span class="math notranslate nohighlight">\(\gamma\)</span> indicates a more homogeneous degree distribution, where the probability of finding nodes with very high degrees decreases more rapidly.
Conversely, a flatter slope (i.e., a value of <span class="math notranslate nohighlight">\(-\gamma + 1\)</span> being closer to zero) corresponds to a smaller <span class="math notranslate nohighlight">\(\gamma\)</span>.
A smaller <span class="math notranslate nohighlight">\(\gamma\)</span> indicates a more heterogeneous degree distribution, where there’s a high probability of finding nodes with high degrees compared to that with a large <span class="math notranslate nohighlight">\(\gamma\)</span> value.</p>
<p>For students interested in real-world examples of the CCDF plot, refer to Figure 4 in <a class="footnote-reference brackets" href="#footcite-newman2005power" id="id82" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a>, or <a class="reference external" href="https://arxiv.org/pdf/cond-mat/0412004">the arxiv version</a></p>
<p>In sum, the CCDF in a log-log plot provides a convenient visual summary of the degree distribution, with the slope of the CCDF providing a measure of the heterogeneity of the degree distribution.</p>
</section>
</section>
<section id="degree-distribution-of-a-friend">
<h2>Degree distribution of a friend<a class="headerlink" href="#degree-distribution-of-a-friend" title="Link to this heading">#</a></h2>
<p>Continuing from the previous page, we will now consider the degree distribution of a friend of a node.</p>
<p>There are two ways to sample a friend of a node.</p>
<ol class="arabic simple">
<li><p>Sample a node uniformly at random and then sample a friend of the node.</p></li>
<li><p>Sample a <em>friendship</em> (i.e., edge) uniformly at random and then sample an end node of the edge.</p></li>
</ol>
<p>Let us focus on the second case and leave the first case for interested students as an exercise.
In the second case, we sample an edge from the network.
This sampling is biased towards nodes with many edges, i.e., a person with <span class="math notranslate nohighlight">\(d\)</span> edges is <span class="math notranslate nohighlight">\(d\)</span> times more likely to be sampled than someone with 1 edge.
Thus, the degree distribution <span class="math notranslate nohighlight">\(p'(k)\)</span> of a friend is given by</p>
<div class="math notranslate nohighlight">
\[
p' (k) = C \cdot k \cdot p(k)
\]</div>
<p>The additional term <span class="math notranslate nohighlight">\(k\)</span> reflects the fact that a person with <span class="math notranslate nohighlight">\(k\)</span> friends is <span class="math notranslate nohighlight">\(k\)</span> times more likely to be sampled than someone with 1 friend.
Term <span class="math notranslate nohighlight">\(C\)</span> is the normalization constant that ensures the sum of probabilities <span class="math notranslate nohighlight">\(p'(k)\)</span> over all <span class="math notranslate nohighlight">\(k\)</span> is 1, which can be easily computed as follows:</p>
<div class="math notranslate nohighlight">
\[
C = \frac{1}{\sum_{k} k \cdot p(k)} = \frac{1}{\langle k \rangle}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\langle k \rangle\)</span> is the average degree of the network. Substituting <span class="math notranslate nohighlight">\(C\)</span> into <span class="math notranslate nohighlight">\(p'(k)\)</span>, we get:</p>
<div class="math notranslate nohighlight">
\[
p' (k) = \frac{k}{\langle k \rangle} p(k)
\]</div>
<p>This is the degree distribution of a friend, and it is easy to verify that the average degree of a friend is given by</p>
<div class="math notranslate nohighlight">
\[
\langle k' \rangle = \sum_{k} k \cdot p'(k) = \sum_{k} k \cdot \frac{k}{\langle k \rangle} p(k) = \frac{\langle k^2 \rangle}{\langle k \rangle}
\]</div>
<p>which is always larger than <span class="math notranslate nohighlight">\(\langle k \rangle\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\langle k' \rangle = \frac{\langle k^2 \rangle}{\langle k \rangle} \geq \langle k \rangle
\]</div>
<p>with equality only if every node has the same degree. This is a proof of the friendship paradox 😉!</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The distribution <span class="math notranslate nohighlight">\(p'(k)\)</span> is related to <em>the excess degree distribution</em> given by</p>
<div class="math notranslate nohighlight">
\[
q(k) = \frac{k + 1}{\langle k \rangle} p(k+1)
\]</div>
<p>The term <em>excess</em> comes from the fact that the distribution represents the number of additional connections a randomly chosen friend has, beyond the connection that led to their selection. It excludes the link to the focal node and focuses on the remaining connections of the selected friend.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The friend’s degree, <span class="math notranslate nohighlight">\(\frac{\langle k^2 \rangle}{\langle k \rangle}\)</span>, concides with a term in Molloy-Reed condition:</p>
<div class="math notranslate nohighlight">
\[\frac{\langle k^2 \rangle}{\langle k \rangle} &gt;2\]</div>
<p>which is a condition for the existence of a giant component in a network. The Molloy-Reed condition states that the average degree of a node’s friends must be at least 2 (the inequality is strict because the transition from a small component to a giant component is discontinuous). If a friend has only one edge, you and your friend form an isolated component. If a friend has two edges on average, your friend is a friend of someone else, and that someone else is also friend of another someone else and so on, forming a giant component.</p>
</div>
</section>
<section id="plotting-degree-distribution-of-a-friend">
<h2>Plotting degree distribution of a friend<a class="headerlink" href="#plotting-degree-distribution-of-a-friend" title="Link to this heading">#</a></h2>
<p>Let us compare the degree distribution of a node and its friend.
We first get the edges in the network, from which we sample a friend.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">sparse</span>
<span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sparse.find(A)</span></code> returns the source node, target node, and edge weight of the edge.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">src</span></code> is the source node of the edge</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trg</span></code> is the target node of the edge</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">_</span></code> is used to ignore the edge weight values, as we only need the source and target nodes for this analysis.</p></li>
</ul>
<p>Now, let us get the degree of each friend</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deg_friend</span> <span class="o">=</span> <span class="n">deg</span><span class="p">[</span><span class="n">src</span><span class="p">]</span>
<span class="n">p_deg_friend</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">deg_friend</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">deg_friend</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The CCDF of the degree distributions of a node and a friend can be computed by:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ccdf_deg</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">p_deg</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ccdf_deg_friend</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">p_deg_friend</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>and plotted by:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ccdf_deg</span><span class="p">)),</span> <span class="n">y</span><span class="o">=</span><span class="n">ccdf_deg</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Node&#39;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ccdf_deg</span><span class="p">)),</span> <span class="n">y</span><span class="o">=</span><span class="n">ccdf_deg_friend</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Friend&#39;</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Degree&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;CCDF&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">frameon</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The slope of the CCDF of a friend is flatter than that of a node, indicating that the degree distribution of a friend is biased towards higher degrees.</p>
<div class="docutils container" id="id83">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-newman2005power" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id75">1</a>,<a role="doc-backlink" href="#id82">2</a>)</span>
<p>Mark EJ Newman. Power laws, pareto distributions and zipf’s law. <em>Contemporary physics</em>, 46(5):323–351, 2005.</p>
</aside>
<aside class="footnote brackets" id="footcite-clauset2009power" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id76">1</a>,<a role="doc-backlink" href="#id77">2</a>)</span>
<p>Aaron Clauset, Cosma Rohilla Shalizi, and Mark EJ Newman. Power-law distributions in empirical data. <em>SIAM review</em>, 51(4):661–703, 2009.</p>
</aside>
<aside class="footnote brackets" id="footcite-artico2020rare" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id78">9</a><span class="fn-bracket">]</span></span>
<p>Igor Artico, I Smolyarenko, Veronica Vinciotti, and Ernst C Wit. How rare are power-law networks really? <em>Proceedings of the Royal Society A</em>, 476(2241):20190742, 2020.</p>
</aside>
<aside class="footnote brackets" id="footcite-holme2019rare" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id79">10</a><span class="fn-bracket">]</span></span>
<p>Petter Holme. Rare and everywhere: perspectives on scale-free networks. <em>Nature communications</em>, 10(1):1016, 2019.</p>
</aside>
<aside class="footnote brackets" id="footcite-voitalov2019scale" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id80">11</a><span class="fn-bracket">]</span></span>
<p>Ivan Voitalov, Pim Van Der Hoorn, Remco Van Der Hofstad, and Dmitri Krioukov. Scale-free networks well done. <em>Physical Review Research</em>, 1(3):033034, 2019.</p>
</aside>
<aside class="footnote brackets" id="footcite-barabasi2003scale" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id81">12</a><span class="fn-bracket">]</span></span>
<p>Albert-László Barabási and Eric Bonabeau. Scale-free networks. <em>Scientific american</em>, 288(5):60–69, 2003.</p>
</aside>
</aside>
</div>
<p>┌─────────────────────────────────────────────────────────────┐</p>
<ol class="arabic simple">
<li><p>[📇] Receive Your Card
Get a card with a unique letter</p></li>
<li><p>[🤝] Meet and Greet (5 mins)
Move around, exchange cards with at least one friend</p></li>
<li><p>[🧮] Count Connections (2 mins)
Count received cards, write number, return cards</p></li>
<li><p>[📈] Calculate Average (2 mins)
Calculate average ‘friend count’ of your friends</p></li>
<li><p>[📝] Fill Form
Write your average and your own friend count
in a separate sheet</p></li>
</ol>
<p>└─────────────────────────────────────────────────────────────┘</p>
<p>❗ Important Notes:
• This is a fun experiment, not a popularity contest
• Be respectful and inclusive during the meet and greet
• If you finish early, wait patiently for further instructions</p>
<div class="highlight-# notranslate"><div class="highlight"><pre><span></span>

## The origin of the friendship paradox

The paradox arises not because of the way we form friendships. It&#39;s about measurement! For example a person with 100 friends generates 100 cards, while a person with 1 friend generates only 1 card. If we average friend counts over the cards, popular people are counted more. This is where the friendship paradox comes from.

In network terms, cards represent edges and people represent nodes. The friendship paradox arises because we measure at different levels: nodes or edges. The average friend count at the node level is lower than at the edge level because popular people are counted more often at the edge level.

- **🎉 Fun Challenge**: Can you create a network where your friends have the most friends? 🤔💡 Give it a try in this {{ &#39;[Friendship Paradox Game! 🎮✨]( BASE_URL/vis/friendship-paradox-game.html)&#39;.replace(&#39;BASE_URL&#39;, base_url) }}

- **Question**: Can you create a network where the friendship paradox is absent? In other words, can you create a graph, where your friends have the same number of friends as you?
# Vaccination Game

Beyond an interesting trivia, the friendship paradox has many practical utilities.

- **🎉 Fun Challenge**: Can you control the spread of a virus by strategically vaccinating individuals? 🤔💡 Give it a try in this {{ &#39;[Vaccination Game! 🎮✨]( BASE_URL/vis/vaccination-game.html)&#39;.replace(&#39;BASE_URL&#39;, base_url) }}
# Module 4: Friendship Paradox

## What to learn in this module

In this module, we will learn about the friendship paradox. Specifically,
- Friendship paradox: what is it, why it&#39;s important, and what are the consequences?
- **Keywords**: friendship paradox, degree bias---
jupytext:
  cell_metadata_filter: -all
  formats: md:myst
  text_representation:
    extension: .Rmd
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.16.3
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/skojaku/adv-net-sci/blob/main/notebooks/exercise-m05-clustering.ipynb&quot;&gt;
  &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;
&lt;/a&gt;

# Hands-on: Clustering

```{code-cell} ipython3
# If you are using Google Colab, uncomment the following line to install igraph
# !sudo apt install libcairo2-dev pkg-config python3-dev
# !pip install pycairo cairocffi
# !pip install igraph
</pre></div>
</div>
</section>
<section id="modularity-maximization">
<h2>Modularity maximization<a class="headerlink" href="#modularity-maximization" title="Link to this heading">#</a></h2>
<p>Let us showcase how to use <code class="docutils literal notranslate"><span class="pre">igraph</span></code> to detect communities with modularity. We will use the Karate Club Network as an example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">igraph</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">igraph</span><span class="o">.</span><span class="n">Graph</span><span class="o">.</span><span class="n">Famous</span><span class="p">(</span><span class="s2">&quot;Zachary&quot;</span><span class="p">)</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vertex_size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>When it comes to maximizing modularity, there are a variety of algorithms to choose from.
Two of the most popular ones are the <code class="docutils literal notranslate"><span class="pre">Louvain</span></code> and <code class="docutils literal notranslate"><span class="pre">Leiden</span></code> algorithms, both of which are implemented in <code class="docutils literal notranslate"><span class="pre">igraph</span></code>. The Louvain algorithm has been around for quite some time and is a classic choice, while the Leiden algorithm is a newer bee that often yields better accuracy. For our example, we’ll be using the <code class="docutils literal notranslate"><span class="pre">Leiden</span></code> algorithm, and I think you’ll find it really effective!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">communities</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">community_leiden</span><span class="p">(</span><span class="n">resolution</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">objective_function</span><span class="o">=</span> <span class="s2">&quot;modularity&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>What is <code class="docutils literal notranslate"><span class="pre">resolution</span></code>? It is a parameter that helps us tackle the resolution limit of the modularity maximization algorithm <a class="footnote-reference brackets" href="#footcite-fortunato2007resolution" id="id84" role="doc-noteref"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></a>!
In simple terms, when we use the resolution parameter <span class="math notranslate nohighlight">\(\rho\)</span>, the modularity formula can be rewritten as
follow:</p>
<div class="math notranslate nohighlight">
\[
Q(M) = \frac{1}{2m} \sum_{i=1}^n \sum_{j=1}^n \left(A_{ij} - \rho \frac{k_i k_j}{2m}\right) \delta(c_i, c_j)
\]</div>
<p>Here, the parameter <span class="math notranslate nohighlight">\(\rho\)</span> plays a crucial role in balancing the positive and negative parts of the equation.
The resolution limit comes into play because of the diminishing effect of the negative term as the number of edges <span class="math notranslate nohighlight">\(m\)</span> increases.
The parameter <span class="math notranslate nohighlight">\(\rho\)</span> can adjust this balance and allow us to circumvent the resolution limit.</p>
<p>What is <code class="docutils literal notranslate"><span class="pre">communities</span></code>? This is a list of communities, where each community is represented by a list of nodes by their indices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">communities</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us visualize the communities by coloring the nodes in the graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">community_membership</span> <span class="o">=</span> <span class="n">communities</span><span class="o">.</span><span class="n">membership</span>
<span class="n">palette</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()</span><span class="o">.</span><span class="n">as_hex</span><span class="p">()</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">palette</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">community_membership</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">community_membership</span></code>: This is a list of community membership for each node.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">palette</span></code>: This is a list of colors to use for the communities.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">igraph.plot(g,</span> <span class="pre">vertex_color=[palette[i]</span> <span class="pre">for</span> <span class="pre">i</span> <span class="pre">in</span> <span class="pre">community_membership])</span></code>: This plots the graph ‘g’ with nodes colored by their community.</p></li>
</ul>
<section id="id85">
<h3>Exercise 01 🏋️‍♀️💪🧠<a class="headerlink" href="#id85" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Select a network of your choice from <a class="reference external" href="https://networks.skewed.de/">Netzschleuder</a>. For convenience, choose a network of nodes less than 5000.</p></li>
<li><p>Download the csv version of the data by clicking something like “3KiB” under <code class="docutils literal notranslate"><span class="pre">csv</span></code> column.</p></li>
<li><p>Unzip the file and find “edges.csv”, open it with a text editor to familiarize yourself with the format.</p></li>
<li><p>Load the data using <code class="docutils literal notranslate"><span class="pre">pandas</span></code>.</p></li>
<li><p>Get the source and target nodes from the data to create an edge list.</p></li>
<li><p>Construct a graph from the edge list, either using <code class="docutils literal notranslate"><span class="pre">igraph</span></code> or <code class="docutils literal notranslate"><span class="pre">scipy</span></code>.</p></li>
<li><p>Find communities by maximizing the modularity and visualize them.</p></li>
<li><p>Try at least three different values of the resolution parameter and observe how the community structure changes.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="stochstic-block-model">
<h2>Stochstic Block Model<a class="headerlink" href="#stochstic-block-model" title="Link to this heading">#</a></h2>
<p>Let us turn the SBM as our community detection tool using <a class="reference external" href="https://graph-tool.skewed.de/">graph-tool</a>. This is a powerful library for network analysis, with a focus on the stochastic block model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#</span>
<span class="c1"># Uncomment the following code if you are using Google Colab</span>
<span class="c1">#</span>
<span class="c1">#!wget https://downloads.skewed.de/skewed-keyring/skewed-keyring_1.0_all_$(lsb_release -s -c).deb</span>
<span class="c1">#!dpkg -i skewed-keyring_1.0_all_$(lsb_release -s -c).deb</span>
<span class="c1">#!echo &quot;deb [signed-by=/usr/share/keyrings/skewed-keyring.gpg] https://downloads.skewed.de/apt $(lsb_release -s -c) main&quot; &gt; /etc/apt/sources.list.d/skewed.list</span>
<span class="c1">#!apt-get update</span>
<span class="c1">#!apt-get install python3-graph-tool python3-matplotlib python3-cairo</span>
<span class="c1">#!apt purge python3-cairo</span>
<span class="c1">#!apt install libcairo2-dev pkg-config python3-dev</span>
<span class="c1">#!pip install --force-reinstall pycairo</span>
<span class="c1">#!pip install zstandard</span>
</pre></div>
</div>
</div>
</div>
<p>We will identify the communities using the stochastic block model as follows.
First, we will convert the graph object in igraph to that in graph-tool.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">graph_tool.all</span>  <span class="k">as</span> <span class="nn">gt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">igraph</span>

<span class="c1"># igraph object</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">igraph</span><span class="o">.</span><span class="n">Graph</span><span class="o">.</span><span class="n">Famous</span><span class="p">(</span><span class="s2">&quot;Zachary&quot;</span><span class="p">)</span>

<span class="c1"># Set random seed for reproducibility</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Convert the graph object in igraph to that in graph-tool</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_edgelist</span><span class="p">()</span>
<span class="n">r</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">edges</span><span class="p">)</span>
<span class="n">g_gt</span> <span class="o">=</span> <span class="n">gt</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">g_gt</span><span class="o">.</span><span class="n">add_edge_list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we will fit the stochastic block model to the graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit the stochastic block model</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">gt</span><span class="o">.</span><span class="n">minimize_blockmodel_dl</span><span class="p">(</span>
     <span class="n">g_gt</span><span class="p">,</span>
     <span class="n">state_args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;deg_corr&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;B_min&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;B_max&quot;</span><span class="p">:</span><span class="mi">10</span><span class="p">},</span>
<span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get_blocks</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">B_min</span></code> and <code class="docutils literal notranslate"><span class="pre">B_max</span></code> are the minimum and maximum number of communities to consider.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">deg_corr</span></code> is a boolean flag to switch to the degree-corrected SBM <a class="footnote-reference brackets" href="#footcite-karrer2011stochastic" id="id86" role="doc-noteref"><span class="fn-bracket">[</span>14<span class="fn-bracket">]</span></a>.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Here’s a fun fact: the likelihood maximization on its own can’t figure out how many communities there should be. But <code class="docutils literal notranslate"><span class="pre">graph-tool</span></code> has a clever trick to circumvent this limitation.
<code class="docutils literal notranslate"><span class="pre">graph-tool</span></code> actually fits multiple SBMs, each with a different number of communities. Then, it picks the most plausible one based on a model selection criterion.</p>
</div>
<p>Let’s visualize the communities to see what we got.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert the block assignments to a list</span>
<span class="n">community_membership</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">get_array</span><span class="p">()</span>

<span class="c1"># The community labels may consist of non-consecutive integers, e.g., 10, 8, 1, 4, ...</span>
<span class="c1"># So we reassign the community labels to be 0, 1, 2, ...</span>
<span class="n">community_membership</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">community_membership</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">community_membership</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a color palette</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">palette</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()</span><span class="o">.</span><span class="n">as_hex</span><span class="p">()</span>
<span class="c1"># Plot the graph with nodes colored by their community</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">g</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">palette</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">community_membership</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>What we’re seeing here isn’t a failure at all. In fact, it’s the best partition according to our stochastic block model. The model has discovered something called a <strong>core-periphery structure</strong> <a class="footnote-reference brackets" href="#footcite-borgatti2000models" id="id87" role="doc-noteref"><span class="fn-bracket">[</span>15<span class="fn-bracket">]</span></a>. Let me break that down:</p>
<ul class="simple">
<li><p>Think of a major international airport (the core) and smaller regional airports (the periphery).</p></li>
<li><p>Major international airports have many flights connecting to each other (densely connected).</p></li>
<li><p>Smaller regional airports have fewer connections among themselves (sparsely connected).</p></li>
<li><p>Many regional airports have flights to major hubs (periphery connected to the core).</p></li>
</ul>
<p>That’s exactly what our model found in this network.</p>
<p>If we look at the adjacency matrix, we would see something that looks like an upside-down “L”. This shape is like a signature for core-periphery structures.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert igraph Graph to adjacency matrix</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_adjacency</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Sort nodes based on their community (core first, then periphery)</span>
<span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">community_membership</span><span class="p">)</span>
<span class="n">A_sorted</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">sorted_indices</span><span class="p">][:,</span> <span class="n">sorted_indices</span><span class="p">]</span>

<span class="c1"># Plot the sorted adjacency matrix</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">A_sorted</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Sorted Adjacency Matrix: Core-Periphery Structure&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Node Index (sorted)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Node Index (sorted)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="id88">
<h3>Exercise 02 🏋️‍♀️💪🧠<a class="headerlink" href="#id88" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Select a network of your choice from <a class="reference external" href="https://networks.skewed.de/">Netzschleuder</a>. For convenience, choose a network of nodes less than 5000.</p></li>
<li><p>Download the csv version of the data by clicking something like “3KiB” under <code class="docutils literal notranslate"><span class="pre">csv</span></code> column.</p></li>
<li><p>Unzip the file and find “edges.csv”, open it with a text editor to familiarize yourself with the format.</p></li>
<li><p>Load the data using <code class="docutils literal notranslate"><span class="pre">pandas</span></code>.</p></li>
<li><p>Get the source and target nodes from the data to create an edge list.</p></li>
<li><p>Construct a graph from the edge list, either using <code class="docutils literal notranslate"><span class="pre">igraph</span></code> or <code class="docutils literal notranslate"><span class="pre">scipy</span></code>.</p></li>
<li><p>Find communities by fitting the stochastic block model and visualize them.</p></li>
<li><p>Try <code class="docutils literal notranslate"><span class="pre">deg_corr=True</span></code> and compare the results with those from <code class="docutils literal notranslate"><span class="pre">deg_corr=False</span></code>.</p></li>
</ol>
<div class="docutils container" id="id89">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-fortunato2007resolution" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id84">1</a>,<a role="doc-backlink" href="#id90">2</a>)</span>
<p>Santo Fortunato and Marc Barthelemy. Resolution limit in community detection. <em>Proceedings of the national academy of sciences</em>, 104(1):36–41, 2007.</p>
</aside>
<aside class="footnote brackets" id="footcite-karrer2011stochastic" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id86">14</a><span class="fn-bracket">]</span></span>
<p>Brian Karrer and Mark EJ Newman. Stochastic blockmodels and community structure in networks. <em>Physical Review E—Statistical, Nonlinear, and Soft Matter Physics</em>, 83(1):016107, 2011.</p>
</aside>
<aside class="footnote brackets" id="footcite-borgatti2000models" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id87">15</a><span class="fn-bracket">]</span></span>
<p>Stephen P Borgatti and Martin G Everett. Models of core/periphery structures. <em>Social networks</em>, 21(4):375–395, 2000.</p>
</aside>
</aside>
</div>
</section>
</section>
<section id="modularity-demo">
<h2>Modularity Demo<a class="headerlink" href="#modularity-demo" title="Link to this heading">#</a></h2>
<p>Let’s learn how the modularity works by playing with a community detection game!</p>
<div class="tip admonition">
<p class="admonition-title">Exercise 1</p>
<p>Find communities by maximizing the modularity. <a href='https://skojaku.github.io/adv-net-sci/vis/community-detection/index.html?scoreType=modularity&numCommunities=2&randomness=1&dataFile=two-cliques.json'>Modularity maximization (two communities) 🎮</a></p>
</div>
<p>One of the good things about modularity is that it can figure out how many communities there should be all by itself! 🕵️‍♀️ Let’s have some fun with this idea. We’re going to play the same game again, but this time, we’ll start with a different number of communities. See how the modularity score changes as we move things around.</p>
<div class="tip admonition">
<p class="admonition-title">Exercise 2</p>
<p>Find communities by maximizing the modularity. <a href='https://skojaku.github.io/adv-net-sci/vis/community-detection/index.html?scoreType=modularity&numCommunities=4&randomness=1&dataFile=two-cliques.json'>Modularity maximization (four communities) 🎮</a></p>
</div>
<p>Now, let’s take our modularity maximization for a real-world example! 🥋 We’re going to use the famous karate club network. This network represents friendships between members of a university karate club. It’s a classic in the world of network science, and it’s perfect for seeing how modularity works in practice.</p>
<div class="tip admonition">
<p class="admonition-title">Exercise 3</p>
<p>Find communities by maximizing the modularity. <a href='https://skojaku.github.io/adv-net-sci/vis/community-detection/index.html?scoreType=modularity&numCommunities=4&randomness=0.25&dataFile=net_karate.json'>Modularity maximization (four communities) 🎮</a></p>
</div>
</section>
<section id="limitation-of-modularity">
<h2>Limitation of Modularity<a class="headerlink" href="#limitation-of-modularity" title="Link to this heading">#</a></h2>
<p>Like many other community detection methods, modularity is not a silver bullet. Thanks to extensive research, we know many limitations of modularity. Let’s take a look at a few of them.</p>
<section id="resolution-limit">
<h3>Resolution limit<a class="headerlink" href="#resolution-limit" title="Link to this heading">#</a></h3>
<p>The modularity finds two cliques connected by a single edge as two separate communities.
But what if we add another community to this network?
Our intuition tells us that, because communities are <em>local</em> structure, the two cliques should remain separated by the modularity. But is this the case?</p>
<div class="tip admonition">
<p class="admonition-title">Exercise 4</p>
<p>Find communities by maximizing the modularity. <a href='https://skojaku.github.io/adv-net-sci/vis/community-detection/index.html?scoreType=modularity&numCommunities=3&randomness=0.9&dataFile=two-cliques-big-clique.json'>Modularity maximization (four communities) 🎮</a></p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Click here to see the solution<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">The best modularity score actually comes from merging our two cliques into one big community. This behavior is what we call the <strong>Resolution limit</strong> <a class="footnote-reference brackets" href="#footcite-fortunato2007resolution" id="id90" role="doc-noteref"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></a>. Modularity can’t quite make out communities that are smaller than a certain size!</p>
<p class="sd-card-text">Think of it like this: modularity is trying to see the big picture, but it misses the little details. In network terms, the number of edges <span class="math notranslate nohighlight">\(m_c\)</span> in a community <span class="math notranslate nohighlight">\(c\)</span> has to be bigger than a certain size. This size is related to the total number of edges <span class="math notranslate nohighlight">\(m\)</span> in the whole network. We write this mathematically as <span class="math notranslate nohighlight">\({\cal O}(m)\)</span>.</p>
</div>
</details></div>
</section>
<section id="spurious-communities">
<h3>Spurious communities<a class="headerlink" href="#spurious-communities" title="Link to this heading">#</a></h3>
<p>What if the network does not have any communities at all? Does the modularity find no communities? To find out, let’s run the modularity on a random network, where each pair of nodes is connected randomly with the same probability.</p>
<div class="tip admonition">
<p class="admonition-title">Exercise 5</p>
<p>Find communities by maximizing the modularity. <a href='https://skojaku.github.io/adv-net-sci/vis/community-detection/index.html?scoreType=modularity&numCommunities=3&randomness=0.8&dataFile=random-net.json'>Modularity maximization (four communities) 🎮</a></p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Click here to see the solution<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Surprise, surprise! 😮 Modularity finds communities even in our random network, and with a very high score too! It’s like finding shapes in clouds - sometimes our brains (or algorithms) see patterns where there aren’t any.</p>
<p class="sd-card-text">The wild thing is that the modularity score for this random network is even higher than what we saw for our network with two clear cliques!</p>
<p class="sd-card-text">This teaches us two important lessons:</p>
<ol class="arabic simple">
<li><p class="sd-card-text">We can’t compare modularity scores between different networks. It’s like comparing apples and oranges! 🍎🍊</p></li>
<li><p class="sd-card-text">A high modularity score doesn’t always mean we’ve found communities.</p></li>
</ol>
<p class="sd-card-text">Interested readers can read more about this in <a class="reference external" href="https://twitter.com/tiagopeixoto/status/1466352013856358400">this tweet by Tiago Peixoto</a> and the discussion <a class="reference external" href="https://reticular.hypotheses.org/1924">here</a>.</p>
<blockquote class="twitter-tweet" style="max-width: 550px;"><p lang="en" dir="ltr">Modularity maximization is not a reliable method to find communities in networks. Here&#39;s a simple example showing why:<br><br>1. Generate an Erdős-Rényi random graph with N nodes and average degree &lt;k&gt;.<br><br>2. Find the maximum modularity partition. <a href="https://t.co/MTt5DdFXSX">pic.twitter.com/MTt5DdFXSX</a></p>&mdash; Tiago Peixoto (@tiagopeixoto) <a href="https://twitter.com/tiagopeixoto/status/1466352013856358400?ref_src=twsrc%5Etfw">December 2, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</details></div>
</section>
</section>
<section id="so-should-we-avoid-modularity">
<h2>So should we avoid modularity?<a class="headerlink" href="#so-should-we-avoid-modularity" title="Link to this heading">#</a></h2>
<p>The simple answer is no. Modularity is still a powerful tool for finding communities in networks. Like any other method, it has its limitations. And knowing these limitations is crucial for using it effectively. There is “free lunch” in community detection <a class="footnote-reference brackets" href="#footcite-peel2017ground" id="id91" role="doc-noteref"><span class="fn-bracket">[</span>16<span class="fn-bracket">]</span></a>.</p>
<p>When these implicit assumptions are met, modularity is in fact a very powerful method for community detection. For example, it is in fact an “optimal” method for a certain class of networks <a class="footnote-reference brackets" href="#footcite-nadakuditi2012graph" id="id92" role="doc-noteref"><span class="fn-bracket">[</span>17<span class="fn-bracket">]</span></a>.</p>
<p>So, keep modularity in your toolbox. Just remember to use it wisely!</p>
<div class="docutils container" id="id93">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-peel2017ground" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id91">16</a><span class="fn-bracket">]</span></span>
<p>Leto Peel, Daniel B Larremore, and Aaron Clauset. The ground truth about metadata and community detection in networks. <em>Science advances</em>, 3(5):e1602548, 2017.</p>
</aside>
<aside class="footnote brackets" id="footcite-nadakuditi2012graph" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>17<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id92">1</a>,<a role="doc-backlink" href="#id131">2</a>)</span>
<p>Raj Rao Nadakuditi and Mark EJ Newman. Graph spectra and the detectability of community structure in networks. <em>Physical review letters</em>, 108(18):188701, 2012.</p>
</aside>
</aside>
</div>
<div class="tip admonition">
<p class="admonition-title">Exercise</p>
<p>What is the probability of color matches for the random version? Derive the probability by using <span class="math notranslate nohighlight">\(\sum, M, \delta(c_i, c_j), k_i,k_j\)</span>.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Hint<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<ol class="arabic simple">
<li><p class="sd-card-text">Imagine a big bag full of colorful balls, but this time without any strings. 🔴🟢🔵🟡</p></li>
<li><p class="sd-card-text">Now, think about picking one ball out of the bag. What are the chances of picking a specific color?</p></li>
<li><p class="sd-card-text">Then, put that ball back and pick another one. What are the odds this second ball matches the color of the first one?</p></li>
</ol>
</div>
</details></div>
</section>
<section id="the-full-modularity-formula-is-on-the-next-page-jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">
<h2>The full modularity formula is on the next page 😉.—
jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3<a class="headerlink" href="#the-full-modularity-formula-is-on-the-next-page-jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="community-detection-pattern-matching">
<h1>Community detection (pattern matching)<a class="headerlink" href="#community-detection-pattern-matching" title="Link to this heading">#</a></h1>
<p>Community detection is an abstract unsupervised problem. It is abstract because there is no clear-cut definition or ground truth to compare against. The concept of a community in a network is subjective and highly context-dependent.</p>
<p>A classical approach to community detection is based on <em>pattern matching</em>.
Namely, we first explicitly define a community by a specific connectivity pattern of its members. Then, we search for these communities in the network.</p>
<figure class="align-default" id="clique">
<a class="reference internal image-reference" href="https://pythonhosted.org/trustedanalytics/R_images/k-clique_201508281155.png"><img alt="Clique graph" src="https://pythonhosted.org/trustedanalytics/R_images/k-clique_201508281155.png" style="width: 80%;" /></a>
<figcaption>
<p><span class="caption-text">Cliques of different sizes. Taken from <a class="reference external" href="https://pythonhosted.org/trustedanalytics/python_api/graphs/graph-/kclique_percolation.html">https://pythonhosted.org/trustedanalytics/python_api/graphs/graph-/kclique_percolation.html</a></span><a class="headerlink" href="#clique" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Perhaps, the strictest definition of a community is a <em>clique</em>: a group of nodes all connected to each other. Examples include triangles (3-node cliques) and fully-connected squares (4-node cliques).
However, cliques are often too rigid for real-world networks. In social networks, for instance, large groups of friends rarely have every member connected to every other, yet we want to accept such “in-perfect” social circles as communities.
This leads to the idea of relaxed versions of cliques, called <strong>pseudo-cliques</strong>.</p>
<p>Pseudo-cliques are defined by relaxing at least one of the following three dimensions of strictness:</p>
<ol class="arabic simple">
<li><p>Degree: Not all nodes need to connect to every other node.</p>
<ul class="simple">
<li><p><strong><span class="math notranslate nohighlight">\(k\)</span>-plex</strong>: each node connects to all but <span class="math notranslate nohighlight">\(k\)</span> others in the group <a class="footnote-reference brackets" href="#footcite-seidman1978graph" id="id94" role="doc-noteref"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></a>.</p></li>
<li><p><strong><span class="math notranslate nohighlight">\(k\)</span>-core</strong>: each node connects to <span class="math notranslate nohighlight">\(k\)</span> others in the group <a class="footnote-reference brackets" href="#footcite-seidman1983network" id="id95" role="doc-noteref"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></a>.</p></li>
</ul>
</li>
<li><p>Density: The overall connection density can be lower.</p>
<ul class="simple">
<li><p><strong><span class="math notranslate nohighlight">\(\rho\)</span>-dense subgraphs</strong>, with a minimum edge density of <span class="math notranslate nohighlight">\(\rho\)</span> <a class="footnote-reference brackets" href="#footcite-goldberg1984finding" id="id96" role="doc-noteref"><span class="fn-bracket">[</span>20<span class="fn-bracket">]</span></a>.</p></li>
</ul>
</li>
<li><p>Distance: Nodes can be further apart.</p>
<ul class="simple">
<li><p><strong><span class="math notranslate nohighlight">\(n\)</span>-clique</strong>, where all nodes are within n steps of each other <a class="footnote-reference brackets" href="#footcite-luce1950connectivity" id="id97" role="doc-noteref"><span class="fn-bracket">[</span>21<span class="fn-bracket">]</span></a>.</p></li>
</ul>
</li>
<li><p>Combination of the above:</p>
<ul class="simple">
<li><p><strong>n-clan</strong> and <strong>n-club</strong> <a class="footnote-reference brackets" href="#footcite-mokken1979cliques" id="id98" role="doc-noteref"><span class="fn-bracket">[</span>22<span class="fn-bracket">]</span></a></p></li>
<li><p><strong><span class="math notranslate nohighlight">\(k\)</span>-truss</strong>, a maximal subgraph where all edges participate in at least <span class="math notranslate nohighlight">\(k-2\)</span> triangles <a class="footnote-reference brackets" href="#footcite-saito2008extracting" id="id99" role="doc-noteref"><span class="fn-bracket">[</span>23<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-cohen2009graph" id="id100" role="doc-noteref"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-wang2010triangulation" id="id101" role="doc-noteref"><span class="fn-bracket">[</span>25<span class="fn-bracket">]</span></a>.</p></li>
<li><p><strong><span class="math notranslate nohighlight">\(\rho\)</span>-dense core</strong>, a subgraph with minimum conductance <span class="math notranslate nohighlight">\(\rho\)</span> <a class="footnote-reference brackets" href="#footcite-koujaku2016dense" id="id102" role="doc-noteref"><span class="fn-bracket">[</span>26<span class="fn-bracket">]</span></a>.</p></li>
</ul>
</li>
</ol>
<figure class="align-default" id="clique-pattern">
<a class="reference internal image-reference" href="https://ars.els-cdn.com/content/image/1-s2.0-S0378873315000520-gr1.jpg"><img alt="Pseudo-clique patterns" src="https://ars.els-cdn.com/content/image/1-s2.0-S0378873315000520-gr1.jpg" style="width: 80%;" /></a>
<figcaption>
<p><span class="caption-text">Illustation of different pseudo cliques. Taken from <a class="footnote-reference brackets" href="#footcite-koujaku2016dense" id="id103" role="doc-noteref"><span class="fn-bracket">[</span>26<span class="fn-bracket">]</span></a>.</span><a class="headerlink" href="#clique-pattern" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="docutils container" id="id104">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-seidman1978graph" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id94">18</a><span class="fn-bracket">]</span></span>
<p>Stephen B Seidman and Brian L Foster. A graph-theoretic generalization of the clique concept. <em>Journal of Mathematical sociology</em>, 6(1):139–154, 1978.</p>
</aside>
<aside class="footnote brackets" id="footcite-seidman1983network" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id95">19</a><span class="fn-bracket">]</span></span>
<p>Stephen B Seidman. Network structure and minimum degree. <em>Social networks</em>, 5(3):269–287, 1983.</p>
</aside>
<aside class="footnote brackets" id="footcite-goldberg1984finding" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id96">20</a><span class="fn-bracket">]</span></span>
<p>Andrew V Goldberg. Finding a maximum density subgraph. <em>Technical report</em>, 1984.</p>
</aside>
<aside class="footnote brackets" id="footcite-luce1950connectivity" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id97">21</a><span class="fn-bracket">]</span></span>
<p>R Duncan Luce. Connectivity and generalized cliques in sociometric group structure. <em>Psychometrika</em>, 15(2):169–190, 1950.</p>
</aside>
<aside class="footnote brackets" id="footcite-mokken1979cliques" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id98">22</a><span class="fn-bracket">]</span></span>
<p>Robert J Mokken and others. Cliques, clubs and clans. <em>Quality &amp; Quantity</em>, 13(2):161–173, 1979.</p>
</aside>
<aside class="footnote brackets" id="footcite-saito2008extracting" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id99">23</a><span class="fn-bracket">]</span></span>
<p>Kazumi Saito, Takeshi Yamada, and Kazuhiro Kazama. Extracting communities from complex networks by the k-dense method. <em>IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences</em>, 91(11):3304–3311, 2008.</p>
</aside>
<aside class="footnote brackets" id="footcite-cohen2009graph" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id100">24</a><span class="fn-bracket">]</span></span>
<p>Jonathan Cohen. Graph twiddling in a mapreduce world. <em>Computing in Science &amp; Engineering</em>, 11(4):29–41, 2009.</p>
</aside>
<aside class="footnote brackets" id="footcite-wang2010triangulation" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id101">25</a><span class="fn-bracket">]</span></span>
<p>Nan Wang, Jingbo Zhang, Kian-Lee Tan, and Anthony KH Tung. On triangulation-based dense neighborhood graph discovery. <em>Proceedings of the VLDB Endowment</em>, 4(2):58–68, 2010.</p>
</aside>
<aside class="footnote brackets" id="footcite-koujaku2016dense" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>26<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id102">1</a>,<a role="doc-backlink" href="#id103">2</a>)</span>
<p>Sadamori Koujaku, Ichigaku Takigawa, Mineichi Kudo, and Hideyuki Imai. Dense core model for cohesive subgraph discovery. <em>Social Networks</em>, 44:143–152, 2016.</p>
</aside>
</aside>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="pen-and-paper">
<h1>Pen and Paper<a class="headerlink" href="#pen-and-paper" title="Link to this heading">#</a></h1>
<section id="pen-and-paper-exercise">
<h2>✍️ <a class="reference internal" href="#./pen-and-paper/exercise.pdf"><span class="xref myst">Pen and Paper Exercise</span></a> 🚢<a class="headerlink" href="#pen-and-paper-exercise" title="Link to this heading">#</a></h2>
</section>
<section id="jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">
<h2>jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3<a class="headerlink" href="#jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="balanced-cut">
<h1>Balanced cut<a class="headerlink" href="#balanced-cut" title="Link to this heading">#</a></h1>
<section id="ratio-cut">
<h2>Ratio Cut<a class="headerlink" href="#ratio-cut" title="Link to this heading">#</a></h2>
<p>Graph cut often provide unbalanced communities, e.g., a community consisting of a single node, and another consisting of all other nodes. For example, if the network has a node with degree one (e.g., one edge), an optimal cut will be to place this node in its own community, resulting in a cut of one.</p>
<p><strong>Ratio cut</strong> addresses this issue by introducing a normalization factor to balance the cut.
Suppose we cut the network into two communities <span class="math notranslate nohighlight">\(V_1\)</span> and <span class="math notranslate nohighlight">\(V_2\)</span>, then the ratio cut is defined as</p>
<div class="math notranslate nohighlight">
\[
\text{Ratio cut}(V_1, V_2) = \frac{1}{|V_1| \cdot |V_2|} \sum_{i \in V_1} \sum_{j \in V_2} A_{ij}
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(|V_1|\)</span> (or |V_2|) is the number of nodes in the community <span class="math notranslate nohighlight">\(V_1\)</span> (or <span class="math notranslate nohighlight">\(V_2\)</span>).</p></li>
</ul>
<p>The normalization factor <span class="math notranslate nohighlight">\(1/(|V_1| |V_2|)\)</span> balances the community sizes. It’s smallest when communities are equal (<span class="math notranslate nohighlight">\(|V_1| = |V_2|\)</span>) and largest when one community has only one node (<span class="math notranslate nohighlight">\(|V_1| = 1\)</span> or <span class="math notranslate nohighlight">\(|V_2| = 1\)</span>).</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Total number of nodes</span>
<span class="n">total_nodes</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Create an array of possible sizes for V1</span>
<span class="n">V1_sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_nodes</span><span class="p">)</span>

<span class="c1"># Calculate corresponding sizes for V2</span>
<span class="n">V2_sizes</span> <span class="o">=</span> <span class="n">total_nodes</span> <span class="o">-</span> <span class="n">V1_sizes</span>

<span class="c1"># Calculate the normalization factor</span>
<span class="n">normalization_factor</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">V1_sizes</span> <span class="o">*</span> <span class="n">V2_sizes</span><span class="p">)</span>

<span class="c1"># Create the plot</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">V1_sizes</span><span class="p">,</span> <span class="n">normalization_factor</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Normalization Factor vs. Community Size&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Size of V1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;1 / (|V1| * |V2|)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>  <span class="c1"># Use log scale for y-axis due to large range of values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="normalized-cut">
<h2>Normalized cut<a class="headerlink" href="#normalized-cut" title="Link to this heading">#</a></h2>
<p><strong>Normalized cut</strong><a class="footnote-reference brackets" href="#footcite-shi2000normalized" id="id105" role="doc-noteref"><span class="fn-bracket">[</span>27<span class="fn-bracket">]</span></a> balances communities based on edge count, unlike Ratio cut which uses node count. It is defined as:</p>
<div class="math notranslate nohighlight">
\[
\text{Normalized cut}(V_1, V_2) = \frac{1}{|E_1| \cdot |E_2|} \sum_{i \in V_1} \sum_{j \in V_2} A_{ij}
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(|E_1|\)</span> and <span class="math notranslate nohighlight">\(|E_2|\)</span> are the number of edges in the communities <span class="math notranslate nohighlight">\(V_1\)</span> and <span class="math notranslate nohighlight">\(V_2\)</span>, respectively.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Exercise</p>
<p>Compute the ratio cut and normalized cut for the following network. The red edges should be cut.</p>
</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Click here to reveal the answer<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">The graph consists of two cliques, each with 5 nodes (<span class="math notranslate nohighlight">\(|V_1| = |V_2| = 5\)</span>).
Each clique has 10 internal edges and 2 edges connecting to the other clique.
Therefore, <span class="math notranslate nohighlight">\(|E_1| = |E_2| = 10 + 2 = 12\)</span>.
We can now calculate:</p>
<ul class="simple">
<li><p class="sd-card-text"><strong>Ratio cut</strong>: <span class="math notranslate nohighlight">\(2 / (5 \times 5) = 0.08\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Normalized cut</strong>: <span class="math notranslate nohighlight">\(2 / (12 \times 12) = 0.01388889\)</span>.</p></li>
</ul>
</div>
</details><div class="cell tag_hide-input tag_remove-output docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">igraph</span> <span class="k">as</span> <span class="nn">ig</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>

<span class="c1"># Create two cliques of size 5</span>
<span class="n">G1</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">Graph</span><span class="o">.</span><span class="n">Full</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">G2</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">Graph</span><span class="o">.</span><span class="n">Full</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Combine the two cliques</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">G1</span> <span class="o">+</span> <span class="n">G2</span>

<span class="c1"># Add an edge between the two cliques</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>

<span class="c1"># Draw the graph</span>
<span class="n">layout</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">layout_fruchterman_reingold</span><span class="p">()</span>

<span class="c1"># Set up the plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Draw the connecting edge in red</span>
<span class="n">ig</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">G</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">,</span>
    <span class="n">vertex_color</span><span class="o">=</span><span class="s1">&#39;lightblue&#39;</span><span class="p">,</span>
    <span class="n">vertex_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">edge_color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span>
    <span class="n">edge_width</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="c1"># Draw the connecting edge in red behind the graph</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">layout</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">layout</span><span class="p">[</span><span class="mi">5</span><span class="p">][</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">layout</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">layout</span><span class="p">[</span><span class="mi">5</span><span class="p">][</span><span class="mi">1</span><span class="p">]],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">layout</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">layout</span><span class="p">[</span><span class="mi">6</span><span class="p">][</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">layout</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">layout</span><span class="p">[</span><span class="mi">6</span><span class="p">][</span><span class="mi">1</span><span class="p">]],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">ig</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">G</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">,</span>
    <span class="n">vertex_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span>
    <span class="n">vertex_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">edge_color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span>
    <span class="n">edge_width</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="c1"># Add labels to the nodes</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">coords</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layout</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">coords</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Two Cliques Connected by One Edge&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;fig-graph-cut&quot;</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="cut-into-more-than-two-communities">
<h2>Cut into more than two communities<a class="headerlink" href="#cut-into-more-than-two-communities" title="Link to this heading">#</a></h2>
<p>Ratio cut and Normalized cut can be extended to cut into more than two communities. Specifically, we can extend them to cut into <span class="math notranslate nohighlight">\(k\)</span> communities, i.e., <span class="math notranslate nohighlight">\(V_1, V_2, \dots, V_k\)</span> by defining</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\text{Ratio cut}(V_1, V_2, \dots, V_k) &amp;= \sum_{k=1}^K \frac{1}{|V_k|} \left(\sum_{i \in V_k} \sum_{j \notin V_{k}} A_{ij} \right) \\
\text{Normalized cut}(V_1, V_2, \dots, V_k) &amp;= \sum_{k=1}^K \frac{1}{|E_k|} \left(\sum_{i \in V_k} \sum_{j \notin V_{k}} A_{ij} \right)
\end{align}
\end{split}\]</div>
</section>
<section id="algorithms-to-find-the-best-cut">
<h2>Algorithms to find the best cut<a class="headerlink" href="#algorithms-to-find-the-best-cut" title="Link to this heading">#</a></h2>
<p>For both ratio and normalized cut, finding the best cut is a NP-hard problem. Yet, there are some heuristics to find a good cut.
Interested students are encouraged to refer to <a class="reference external" href="https://arxiv.org/abs/0711.0189">Ulrike von Luxburg “A Tutorial on Spectral Clustering”</a> for more details.</p>
</section>
<section id="issue-of-ratio-cut-and-normalized-cut">
<h2>Issue of Ratio cut and Normalized cut<a class="headerlink" href="#issue-of-ratio-cut-and-normalized-cut" title="Link to this heading">#</a></h2>
<p>While Ratio cut and Normalized cut methods are clever approaches, they do come with a couple of challenges we should be aware of.</p>
<p>Firstly, these methods ask us to decide upfront how many communities we want to find. This can be tricky because, in real-world networks, we often don’t know this number in advance. It requires us to make a guess on how many different groups of friends we have before actually looking at our social circle.</p>
<p>Secondly, and perhaps more critically, these methods <em>favor</em> communities of roughly the same size.
It’s as if they’re assuming all our friend groups should have about the same number of people.
But as we know from real life, that’s not always the case.
Some of us might have a large group of college friends and a smaller group of childhood buddies.
Research has shown that in many real-world networks, communities can indeed be quite different in size <a class="footnote-reference brackets" href="#footcite-palla2005uncovering" id="id106" role="doc-noteref"><span class="fn-bracket">[</span>28<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-clauset2004finding" id="id107" role="doc-noteref"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></a>.</p>
<p>These limitations don’t mean these methods should not be used, but they do remind us the importance of understanding the underlying assumptions and limitations of methods we use 😉.
It’s always good to keep these points in mind when we’re working with network data. 🕸️💡</p>
<div class="docutils container" id="id108">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-shi2000normalized" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id105">27</a><span class="fn-bracket">]</span></span>
<p>Jianbo Shi and Jitendra Malik. Normalized cuts and image segmentation. <em>IEEE Transactions on pattern analysis and machine intelligence</em>, 22(8):888–905, 2000.</p>
</aside>
<aside class="footnote brackets" id="footcite-palla2005uncovering" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id106">28</a><span class="fn-bracket">]</span></span>
<p>Gergely Palla, Imre Derényi, Illés Farkas, and Tamás Vicsek. Uncovering the overlapping community structure of complex networks in nature and society. <em>nature</em>, 435(7043):814–818, 2005.</p>
</aside>
<aside class="footnote brackets" id="footcite-clauset2004finding" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id107">29</a><span class="fn-bracket">]</span></span>
<p>Aaron Clauset, Mark EJ Newman, and Cristopher Moore. Finding community structure in very large networks. <em>Physical Review E—Statistical, Nonlinear, and Soft Matter Physics</em>, 70(6):066111, 2004.</p>
</aside>
</aside>
</div>
</section>
<section id="characterizing-network-structures-with-the-sbm">
<h2>Characterizing network structures with the SBM<a class="headerlink" href="#characterizing-network-structures-with-the-sbm" title="Link to this heading">#</a></h2>
<p>Stochastic Block Model is a flexible model that can be used to describe a wide range of network structures.</p>
<p>Let’s start with communities where nodes within a community are more likely to be connected to each other than nodes in different communities. We can describe this using SBM by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P_{c,c'} = \begin{cases}
    p_{\text{in}} &amp; \text{if } c = c' \\
    p_{\text{out}} &amp; \text{if } c \neq c'
\end{cases}
\end{split}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(p_{\text{in}}\)</span> is the chance of a connection between nodes in the same community</p></li>
<li><p><span class="math notranslate nohighlight">\(p_{\text{out}}\)</span> is the chance of a connection between nodes in different communities</p></li>
</ul>
<p>Usually, we set <span class="math notranslate nohighlight">\(p_{\text{in}} &gt; p_{\text{out}}\)</span>, because nodes in the same community tend to be more connected.</p>
<p>But, there’s more SBM can do:</p>
<ol class="arabic simple">
<li><p><strong>Disassortative communities</strong>: What if we flip things around and set <span class="math notranslate nohighlight">\(p_{\text{in}} &lt; p_{\text{out}}\)</span>? Now we have communities where nodes prefer to connect with nodes from other communities. This is not in line with the communities we have focused on so far. Yet, it is still a valid model of community structure, and SBM allows for this generalization of community structure easily.</p></li>
<li><p><strong>Random networks</strong>: If we make <span class="math notranslate nohighlight">\(p_{\text{in}} = p_{\text{out}}\)</span>, we get a completely random network where every node has an equal chance of connecting to any other node. This is what we call an Erdős-Rényi network.</p></li>
</ol>
<p>In sum, SBM has been used as a playground for network scientists. We can use it to create many interesting network structures and study how they behave.</p>
</section>
<section id="generating-networks-with-sbm">
<h2>Generating networks with SBM<a class="headerlink" href="#generating-networks-with-sbm" title="Link to this heading">#</a></h2>
<p>It is easy to generate networks with SBM using igraph.
For example, the assortativity communities can be generated as follows.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">igraph</span>

<span class="n">p_in</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">p_out</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">block_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">]</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">block_sizes</span><span class="p">)</span>

<span class="n">pref_matrix</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">p_in</span><span class="p">,</span> <span class="n">p_out</span><span class="p">,</span> <span class="n">p_out</span><span class="p">],</span>
    <span class="p">[</span><span class="n">p_out</span><span class="p">,</span> <span class="n">p_in</span><span class="p">,</span> <span class="n">p_out</span><span class="p">],</span>
    <span class="p">[</span><span class="n">p_out</span><span class="p">,</span> <span class="n">p_out</span><span class="p">,</span> <span class="n">p_in</span><span class="p">]</span>
<span class="p">]</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">igraph</span><span class="o">.</span><span class="n">Graph</span><span class="o">.</span><span class="n">SBM</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">pref_matrix</span><span class="p">,</span> <span class="n">block_sizes</span><span class="p">)</span>

<span class="c1"># Plot the network</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">palette</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()</span>

<span class="n">community_colors</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">palette</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">*</span> <span class="n">block_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">block_sizes</span><span class="p">))],</span> <span class="p">[])</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="n">community_colors</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">pref_matrix</span></code> is the matrix of connection probabilities between communities. Its <span class="math notranslate nohighlight">\((i,j)\)</span>th-element is the probability of a connection between nodes in community <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>.</p></li>
</ul>
</section>
<section id="detecting-communities-with-sbm">
<h2>Detecting communities with SBM<a class="headerlink" href="#detecting-communities-with-sbm" title="Link to this heading">#</a></h2>
<p>Imagine you’re a detective trying to figure out how a network was created. You have a hunch about the community structure, and you want to know if it matches the network you see. That’s exactly what we’re going to do to find out communities!</p>
<p>Here’s how we can describe the probability of seeing a particular network, given a community structure:</p>
<div class="math notranslate nohighlight">
\[
P(\left\{A_{ij}\right\}_{ij}) = \prod_{i&lt;j} P(A_{ij}=1|c_i, c_j)^{A_{ij}} (1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}}
\]</div>
<p>Let’s break this down into simpler terms:</p>
<ul class="simple">
<li><p>First, <span class="math notranslate nohighlight">\(\left\{A_{ij}\right\}_{ij}\)</span> is just a fancy way of saying “all the connections in our network”. Think of it as a big table showing who’s connected to whom.</p></li>
<li><p>We use <span class="math notranslate nohighlight">\(\prod_{i &lt; j}\)</span> instead of <span class="math notranslate nohighlight">\(\prod_{i,j}\)</span> because we’re dealing with an undirected network. This means if Alice is friends with Bob, Bob is also friends with Alice. We only need to count this friendship once, not twice!</p></li>
<li><p>The last part, <span class="math notranslate nohighlight">\(P(A_{ij}=1|c_i, c_j)^A_{ij}(1-P(A_{ij}=1|c_i, c_j))^{1-A_{ij}}\)</span>, might look scary, but it’s actually quite clever. It’s a shorthand way of saying “what’s the chance of this connection existing or not existing?” If the connection exists (<span class="math notranslate nohighlight">\(A_{ij}=1\)</span>), we use the first part. If it doesn’t (<span class="math notranslate nohighlight">\(A_{ij}=0\)</span>), we use the second part. It’s a two-in-one formula.</p></li>
</ul>
<p>Here’s a neat trick we can use to make our lives easier. We can take the logarithm of both sides of our equation. This turns our big product (multiplication) into a simpler sum (addition).</p>
<div class="math notranslate nohighlight">
\[
{\cal L}=\log P(\left\{A_{ij}\right\}_{ij}) = \sum_{i&lt;j} A_{ij} \log P(A_{ij}=1|c_i, c_j) + (1-A_{ij}) \log (1-P(A_{ij}=1|c_i, c_j))
\]</div>
<p>We call this the <strong>likelihood function</strong>. It tells us how likely we are to see this network given our community guess. We can play around with different community assignments and edge probabilities to see which one gives us the highest likelihood.
To make this game easier, let’s first figure out the best edge probabilities for a given community assignment.</p>
<p>Our likelihood function has a special shape - it is <em>a concave function</em> with respect to <span class="math notranslate nohighlight">\(p_{c,c'}\)</span>. This means that the likelihood function is a hill with only one peak when we look at it in terms of edge probability <span class="math notranslate nohighlight">\(p_{c,c'}\)</span>.</p>
<div class="cell tag_remove-input docutils container">
</div>
<p>So, what does this mean for us? The top of this hill (our maximum value) is flat, and there’s only one flat spot on the whole hill. So if we can find a spot where the hill isn’t sloping at all (that’s what we mean by “zero gradient”), we’ve found the very top of the hill! 🏔️</p>
<p>In math terms, we take the derivative of our likelihood function with respect to <span class="math notranslate nohighlight">\(p_{c,c'}\)</span> and set it to zero, i.e., <span class="math notranslate nohighlight">\(\partial {\cal L}  / \partial p_{cc'} = 0\)</span>. Here is what we get:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\frac{\partial {\cal L}}{\partial p_{c,c'}} &amp;= 0 \\
\Rightarrow &amp; \sum_{i&lt;j} \left[A_{ij} \frac{1}{p_{c_i,c_j}} \delta(c_i,c)\delta(c_j,c') -(1-A_{ij}) \frac{1}{1-p_{c_i,c_j}}\delta(c_i,c')\delta(c_j,c') \right] = 0 \\
\Rightarrow &amp;
\frac{m_{cc'}}{p_{c_i,c_j}} - \frac{\sum_{i &lt; j} \delta(c_i,c)\delta(c_j,c') }{1-p_{c_i,c_j}} = 0 &amp; \text{if } c \neq  c' \\
\Rightarrow &amp; p_{c,c'} = \frac{m_{cc'}}{\sum_{i &lt; j} \delta(c_i,c)\delta(c_j,c')}
\end{aligned}
\end{split}\]</div>
<p>Let’s break down these equations:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(m_{cc'}\)</span> is the number of edges between nodes in community <span class="math notranslate nohighlight">\(c\)</span> and those in community <span class="math notranslate nohighlight">\(c'\)</span>.</p></li>
<li><p>The derivative <span class="math notranslate nohighlight">\(\partial \log p_{cc} / \partial p_{cc}\)</span> is just <span class="math notranslate nohighlight">\(1/p_{cc}\)</span>.</p></li>
</ul>
<p>The denominator <span class="math notranslate nohighlight">\(\sum_{i &lt; j} \delta(c_i,c)\delta(c_j,c')\)</span> is the total number of pairs of nodes that belong to communities <span class="math notranslate nohighlight">\(c\)</span> and <span class="math notranslate nohighlight">\(c'\)</span>. It is given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\sum_{i &lt; j} \delta(c_i,c)\delta(c_j,c') =
\begin{cases}
n_cn_{c'} &amp; \text{if } c \neq c' \\
\frac{n_c (n_c - 1)}{2} &amp; \text{if } c = c'
\end{cases}
\end{split}\]</div>
<p>Why do we have two different equations for <span class="math notranslate nohighlight">\(p_{c,c'}\)</span>? It’s because we are counting each pair of nodes only by once. It is easy to verify when looking at the adjacency matrix:</p>
<div class="cell tag_remove-input docutils container">
</div>
<p>The upper triangle of the adjacency matrix represents <span class="math notranslate nohighlight">\(i &lt; j\)</span> over which we take the sum.
When <span class="math notranslate nohighlight">\(c=c'\)</span> (the diagonal block), we count only the upper half of the block, resulting in <span class="math notranslate nohighlight">\(\frac{n_c (n_c - 1)}{2}\)</span>. When <span class="math notranslate nohighlight">\(c \neq c'\)</span> (different communities), we count all connections between them, resulting in <span class="math notranslate nohighlight">\(n_cn_{c'}\)</span>.</p>
<p>We have now obtaind the likelihood function based only on the community assignment. Maximizing <span class="math notranslate nohighlight">\({\cal L}\)</span> with respect to the community assignment gives us the most likely community assignment for the network.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="module-5-clustering">
<h1>Module 5: Clustering<a class="headerlink" href="#module-5-clustering" title="Link to this heading">#</a></h1>
<section id="id109">
<h2>What to learn in this module<a class="headerlink" href="#id109" title="Link to this heading">#</a></h2>
<p>In this module, we will learn community detection, one of the most widely-used yet controversial techniques in network analysis. We will learn:</p>
<ul class="simple">
<li><p>What is community structure in networks?</p></li>
<li><p>How to operationalize community structure?</p></li>
<li><p>How to find communities in networks?</p></li>
<li><p>Limitations of community detection</p></li>
<li><p><strong>Keywords</strong>: community detection, assortativity, modularity, resolution limit, rugged landscape, random graph, label switching algorithm, Louvain algorithm, stochastic block model, the configuration model.# Assignment</p></li>
</ul>
<p>We will compute the various centrality measures for airport networks.</p>
<ul class="simple">
<li><p><strong>For students enrolled in SSIE 641</strong></p>
<ul>
<li><p>You will receive a dedicated link to the assignment repository from the instructor.</p></li>
</ul>
</li>
<li><p><em>For those who are not enrolled in SSIE 641</em></p>
<ul>
<li><p>You can access the assignment repository at <a class="reference external" href="https://github.com/sk-classroom/adv-net-sci-centrality">Github</a>.</p></li>
<li><p>This repository does not offer auto-grading. But you can grade the assignment by yourself by</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">grading-toolkit/grade_notebook.sh</span> <span class="pre">tests/test_01.py</span> <span class="pre">assignment/assignment.ipynb</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">grading-toolkit/grade_notebook.sh</span> <span class="pre">tests/test_02.py</span> <span class="pre">assignment/assignment.ipynb</span></code></p></li>
</ul>
</li>
</ul>
</li>
</ul>
<section id="harmonic-centrality">
<h3>Harmonic centrality<a class="headerlink" href="#harmonic-centrality" title="Link to this heading">#</a></h3>
<p><strong>Harmonic Centrality</strong> is a measure that adjusts closeness centrality to work even in disconnected networks. The problem with closeness centrality is that it cannot handle disconnected networks. When a network is disconnected, some nodes can’t reach others, making their distance infinite. This causes all centrality values to become zero, which isn’t very helpful!</p>
<p>To fix this, Beauchamp <a class="footnote-reference brackets" href="#footcite-beauchamp1965improved" id="id110" role="doc-noteref"><span class="fn-bracket">[</span>30<span class="fn-bracket">]</span></a> came up with a clever solution called <em>harmonic centrality</em>. It works even when the network is disconnected.</p>
<div class="math notranslate nohighlight">
\[
c_i = \sum_{j\neq i} \frac{1}{\text{shortest path length from } j \text{ to } i}
\]</div>
</section>
<section id="eccentricity-centrality">
<h3>Eccentricity centrality<a class="headerlink" href="#eccentricity-centrality" title="Link to this heading">#</a></h3>
<p><strong>Eccentricity centrality</strong> is baesd on the farthest distance from a node to any other node. The eccentricity centrality is defined as</p>
<div class="math notranslate nohighlight">
\[
c_i = \frac{1}{\max_{j} \text{shortest path length from } i \text{ to } j}
\]</div>
<p>These centrality measures provide different perspectives on the importance of nodes based on their accessibility and reachability within the network.</p>
<p>A central node should be close to all other nodes.</p>
<p>Closeness centrality captures the notion of “centrality” in the network. Namely, a node is <em>central</em> if it is close to all other nodes.</p>
<div class="math notranslate nohighlight">
\[
c_i = \frac{N - 1}{\sum_{j = 1}^N \text{shortest path length from } j \text{ to } i}
\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the number of nodes in the network. The numerator, <span class="math notranslate nohighlight">\(N\)</span>, is the normalization factor to make the centrality to have the maximum value of 1.</p>
</section>
<section id="id111">
<h3>Eccentricity centrality<a class="headerlink" href="#id111" title="Link to this heading">#</a></h3>
<p>Eccentricity centrality is based on the shortest path distance between nodes, just like the closeness centrality, but it is based on the <em>maximum</em> distance as opposed to the average distance like in the closeness centrality.</p>
<div class="math notranslate nohighlight">
\[
c_i = \frac{1}{\max_{j} \text{shortest path length from } i \text{ to } j}
\]</div>
</section>
<section id="betweenness-centrality">
<h3>Betweenness centrality<a class="headerlink" href="#betweenness-centrality" title="Link to this heading">#</a></h3>
<p>Another notion of centrality is <em>betweenness centrality</em>. It considers that a node is important if it lies on many shortest paths between other nodes.</p>
<div class="math notranslate nohighlight">
\[
c_i = \sum_{j &lt; k} \frac{\sigma_{jk}(i)}{\sigma_{jk}}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma_{jk}\)</span> is the number of shortest paths between nodes <span class="math notranslate nohighlight">\(j\)</span> and <span class="math notranslate nohighlight">\(k\)</span>, and <span class="math notranslate nohighlight">\(\sigma_{jk}(i)\)</span> is the number of shortest paths between nodes <span class="math notranslate nohighlight">\(j\)</span> and <span class="math notranslate nohighlight">\(k\)</span> that pass through node <span class="math notranslate nohighlight">\(i\)</span>.</p>
<div class="docutils container" id="id112">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-beauchamp1965improved" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id110">30</a><span class="fn-bracket">]</span></span>
<p>Murray A Beauchamp. An improved index of centrality. <em>Behavioral science</em>, 10(2):161–163, 1965.</p>
</aside>
</aside>
</div>
<div class="tip admonition">
<p class="admonition-title">Exercise</p>
<p>Consider the case where the graph is undirected and we normalize the hub centrality by the degree <span class="math notranslate nohighlight">\(d_j\)</span> of the authority, namely</p>
<div class="math notranslate nohighlight">
\[
x_i = \sum_j \frac{A_{ji}}{d_j} y_j,\quad y_i = \sum_j A_{ij} x_j
\]</div>
<p>Then we will get the hub centrality equivalent to the degree centrality. Confirm this by substituting <span class="math notranslate nohighlight">\(x_i = d_i\)</span>.</p>
</div>
</section>
</section>
<section id="katz-centrality">
<h2>Katz centrality<a class="headerlink" href="#katz-centrality" title="Link to this heading">#</a></h2>
<p>Eigenvector centrality tends to pay too much attention to a small number of nodes that are well connected to the network while under-emphasizing the importance of the rest of the nodes. A solution is to add a little bit of score to all nodes.</p>
<div class="math notranslate nohighlight">
\[
c_i = \beta + \lambda \sum_{j} A_{ij} c_j
\]</div>
<div class="tip admonition">
<p class="admonition-title">Exercise</p>
<p>Derive the solution of the Katz centrality.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Click to see the answer<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">The equation can be solved by</p>
<div class="math notranslate nohighlight">
\[
\mathbf{c} = \beta \mathbf{1} + \lambda \mathbf{A} \mathbf{c}
\]</div>
<p class="sd-card-text">where <span class="math notranslate nohighlight">\(\mathbf{1}\)</span> is the vector of ones. By rewriting the equation, we get</p>
<div class="math notranslate nohighlight">
\[
\left( \mathbf{I} - \lambda \mathbf{A} \right) \mathbf{c} = \beta \mathbf{1}
\]</div>
<p class="sd-card-text">By taking the inverse of <span class="math notranslate nohighlight">\(\mathbf{I} - \lambda \mathbf{A}\)</span>, we get</p>
<div class="math notranslate nohighlight">
\[
\mathbf{c} = \beta \left( \mathbf{I} - \lambda \mathbf{A} \right)^{-1} \mathbf{1}
\]</div>
</div>
</details></div>
</section>
<section id="pagerank">
<h2>PageRank<a class="headerlink" href="#pagerank" title="Link to this heading">#</a></h2>
<p>You’ve probably heard PageRank, a celebrated idea behind Google Search. It is like a cousin of Katz centrality.</p>
<div class="math notranslate nohighlight">
\[
c_i = (1-\beta) \sum_j A_{ji}\frac{c_j}{d^{\text{out}}_j} + \beta \cdot \frac{1}{N}
\]</div>
<p>where <span class="math notranslate nohighlight">\(d^{\text{out}}_j\)</span> is the out-degree of node <span class="math notranslate nohighlight">\(j\)</span> (the number of edges pointing out from node <span class="math notranslate nohighlight">\(j\)</span>).
The term <span class="math notranslate nohighlight">\(c_j/d^{\text{out}}_j\)</span> represents that the score of node <span class="math notranslate nohighlight">\(j\)</span> is divided by the number of nodes to which node <span class="math notranslate nohighlight">\(j\)</span> points. In Web, this is like a web page distributes its score to the web pages it points to. It is based on an idea of traffic, where the viewers of a web page are evenly transferred to the linked web pages. A web page is important if it has a high traffic of viewers.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">igraph</span>
<span class="n">names</span>  <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Sarah&#39;</span><span class="p">,</span> <span class="s1">&#39;Mike&#39;</span><span class="p">,</span> <span class="s1">&#39;Emma&#39;</span><span class="p">,</span> <span class="s1">&#39;Alex&#39;</span><span class="p">,</span> <span class="s1">&#39;Olivia&#39;</span><span class="p">,</span> <span class="s1">&#39;James&#39;</span><span class="p">,</span> <span class="s1">&#39;Sophia&#39;</span><span class="p">,</span> <span class="s1">&#39;Ethan&#39;</span><span class="p">,</span> <span class="s1">&#39;Ava&#39;</span><span class="p">,</span> <span class="s1">&#39;Noah&#39;</span><span class="p">,</span> <span class="s1">&#39;Lily&#39;</span><span class="p">,</span> <span class="s1">&#39;Lucas&#39;</span><span class="p">,</span> <span class="s1">&#39;Henry&#39;</span><span class="p">]</span>
<span class="n">edge_list</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">12</span><span class="p">)]</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">igraph</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_vertices</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">vs</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">names</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_edges</span><span class="p">(</span><span class="n">edge_list</span><span class="p">)</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vertex_label</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">vs</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">igraph</span></code> offers a wide range of centrality measures as methods of the <code class="docutils literal notranslate"><span class="pre">igraph.Graph</span></code> class.</p>
<ul class="simple">
<li><p><strong>Degree centrality</strong>: <code class="docutils literal notranslate"><span class="pre">igraph.Graph.degree()</span></code></p></li>
<li><p><strong>Closeness centrality</strong>: <code class="docutils literal notranslate"><span class="pre">igraph.Graph.closeness()</span></code></p></li>
<li><p><strong>Betweenness centrality</strong>: <code class="docutils literal notranslate"><span class="pre">igraph.Graph.betweenness()</span></code></p></li>
<li><p><strong>Harmonic centrality</strong>: <code class="docutils literal notranslate"><span class="pre">igraph.Graph.harmonic_centrality()</span></code></p></li>
<li><p><strong>Eccentricity</strong>: <code class="docutils literal notranslate"><span class="pre">igraph.Graph.eccentricity()</span></code></p></li>
<li><p><strong>Eigenvector centrality</strong>: <code class="docutils literal notranslate"><span class="pre">igraph.Graph.eigenvector_centrality()</span></code></p></li>
<li><p><strong>PageRank centrality</strong>: <code class="docutils literal notranslate"><span class="pre">igraph.Graph.personalized_pagerank()</span></code></p></li>
</ul>
<p>For example, the closeness centrality is computed by</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">g</span><span class="o">.</span><span class="n">closeness</span><span class="p">()</span>
</pre></div>
</div>
<section id="computing-katz-centrality">
<h3>Computing Katz centrality<a class="headerlink" href="#computing-katz-centrality" title="Link to this heading">#</a></h3>
<p>Let’s compute the Katz centrality without using igraph.
Let us first define the adjacency matrix of the graph</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_adjacency_sparse</span><span class="p">()</span>
</pre></div>
</div>
<p>which is the scipy CSR sparse matrix. The Katz centrality is given by</p>
<div class="math notranslate nohighlight">
\[\mathbf{c} = \beta \mathbf{1} + \alpha \mathbf{A} \mathbf{c}\]</div>
<p>So, how do we solve this? We can use a linear solver but here we will use a simple method:</p>
<ol class="arabic simple">
<li><p>Initialize <span class="math notranslate nohighlight">\(\mathbf{c}\)</span> with a random vector.</p></li>
<li><p>Compute the right hand side of the equation and update <span class="math notranslate nohighlight">\(\mathbf{c}\)</span>.</p></li>
<li><p>Repeat the process until <span class="math notranslate nohighlight">\(\mathbf{c}\)</span> converges.</p></li>
</ol>
<p>Let’s implement this.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span> <span class="c1"># Hyperparameters</span>
<span class="n">n_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">()</span> <span class="c1"># number of nodes</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># column random vector</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">c_next</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_nodes</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">A</span> <span class="o">*</span> <span class="n">c</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">c_next</span> <span class="o">-</span> <span class="n">c</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-6</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">c_next</span>
<span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Does the centrality converge?</p></li>
<li><p>Change the hyperparameter and see how the result changes 😉
If the centrality diverges, think about why it diverges.</p></li>
</ul>
<p><em>Hint</em>: Katz centrality can be analytically computed by</p>
<div class="math notranslate nohighlight">
\[\mathbf{c} = \beta \left(\mathbf{I} -  \alpha \mathbf{A} \right)^{-1} \mathbf{1}\]</div>
</section>
<section id="exercise-optional">
<h3>Exercise (Optional)<a class="headerlink" href="#exercise-optional" title="Link to this heading">#</a></h3>
<p>Compute the PageRank centrality of this graph</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
</section>
<section id="network-of-ancient-roman-roads">
<h2>Network of ancient Roman roads<a class="headerlink" href="#network-of-ancient-roman-roads" title="Link to this heading">#</a></h2>
<section id="load-the-data-construct-the-network">
<h3>Load the data &amp; construct the network<a class="headerlink" href="#load-the-data-construct-the-network" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">root</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/skojaku/adv-net-sci/main/data/roman-roads&quot;</span>
<span class="n">node_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">root</span><span class="si">}</span><span class="s2">/node_table.csv&quot;</span><span class="p">)</span>
<span class="n">edge_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">root</span><span class="si">}</span><span class="s2">/edge_table.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The node table:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">node_table</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p>The edge table:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">edge_table</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s construct a network from the node and edge tables.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">igraph</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">igraph</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span> <span class="c1"># create an empty graph</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_vertices</span><span class="p">(</span><span class="n">node_table</span><span class="p">[</span><span class="s2">&quot;node_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span> <span class="c1"># add nodes</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_edges</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">edge_table</span><span class="p">[</span><span class="s2">&quot;src&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">edge_table</span><span class="p">[</span><span class="s2">&quot;trg&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)))</span> <span class="c1"># add edges</span>
</pre></div>
</div>
<p>which looks like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">coord</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">node_table</span><span class="p">[</span><span class="s2">&quot;lon&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="o">-</span><span class="n">node_table</span><span class="p">[</span><span class="s2">&quot;lat&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">layout</span> <span class="o">=</span> <span class="n">coord</span><span class="p">,</span> <span class="n">vertex_size</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id113">
<h3>Exercise 🏛️<a class="headerlink" href="#id113" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Compute the following centrality measures:</p>
<ul class="simple">
<li><p>Degree centrality 🔢</p></li>
<li><p>Eigenvector centrality</p></li>
<li><p>PageRank centrality</p></li>
<li><p>Katz centrality</p></li>
<li><p>Betweenness centrality</p></li>
<li><p>Closeness centrality</p></li>
</ul>
</li>
<li><p>Plot the centrality measures on the map and see in which centrality Rome is the most important node. 🗺️🏛️ (as beautiful as possible!!)</p></li>
</ol>
</section>
</section>
<hr class="docutils" />
<section id="id114">
<h2>jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3<a class="headerlink" href="#id114" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="pen-and-paper-exercises">
<h1>Pen and paper exercises<a class="headerlink" href="#pen-and-paper-exercises" title="Link to this heading">#</a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="#./pen-and-paper/exercise.pdf"><span class="xref myst">️️School </span></a></p></li>
</ul>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="module-6-centrality">
<h1>Module 6: Centrality<a class="headerlink" href="#module-6-centrality" title="Link to this heading">#</a></h1>
<section id="id115">
<h2>What to learn in this module<a class="headerlink" href="#id115" title="Link to this heading">#</a></h2>
<p>In this module, we will learn centrality, one of the most widely-used yet controversial techniques in network analysis. We will learn:</p>
<ul class="simple">
<li><p>What is centrality in networks?</p></li>
<li><p>How to operationalize centrality?</p></li>
<li><p>How to find centrality in networks?</p></li>
<li><p>Limitations of centrality</p></li>
<li><p><strong>Keywords</strong>: degree centrality, closeness centrality, betweenness centrality, eigenvector centrality, PageRank, Katz centrality, HITS, random walk—
jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="ladder-lottery">
<h1>Ladder Lottery<a class="headerlink" href="#ladder-lottery" title="Link to this heading">#</a></h1>
<div class="tip admonition">
<p class="admonition-title">Ladder Lottery</p>
<p>Ladder Lottery is a fun East Asian game, also known as “鬼腳圖” (Guijiaotu) in Chinese, “阿弥陀籤” (Amida-kuzi) in Japanese, “사다리타기” (Sadaritagi) in Korean, and “Ladder Lottery” in English. The game is played as follows:</p>
<ol class="arabic simple">
<li><p>A player is given a board with a set of vertical lines.</p></li>
<li><p>The player chooses a line and starts to move along the line</p></li>
<li><p>When hitting a horizontal line, the player must move along the horizontal line and then continue to move along the next vertical line.</p></li>
<li><p>The player wins if the player can hit a marked line at the bottom of the board.</p></li>
<li><p>You cannot see the horizontal lines in advance!</p></li>
</ol>
<p>Play the <a class="reference external" href="https://skojaku.github.io/adv-net-sci/vis/amida-kuji.html?">Ladder Lottery Game! 🎮✨</a> and try to answer the following questions:</p>
<ol class="arabic simple">
<li><p>Is tehre a strategy to maximize the probability of winning?</p></li>
<li><p>How does the probability of winning change as the number of horizontal lines increases?</p></li>
</ol>
<p><img alt="" src="https://upload.wikimedia.org/wikipedia/commons/6/64/Amidakuji_2022-05-10.gif" /></p>
<div class="highlight-# notranslate"><div class="highlight"><pre><span></span>
- [✍️ Pen and paper exercises](pen-and-paper/exercise.pdf)
---
jupytext:
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Random Walks in Python

## Simulating Random Walks

We will simulate random walks on a simple graph of five nodes as follows.

```{code-cell} ipython3
import numpy as np
import igraph

g = igraph.Graph()

g.add_vertices([0, 1, 2, 3, 4])
g.add_edges([(0, 1), (0, 2), (0, 3), (1, 3), (2, 3), (2, 4), (3, 4)])
igraph.plot(g, vertex_size=20, vertex_label=g.vs[&quot;name&quot;])
</pre></div>
</div>
</div>
<p>A random walk is characterized by the transition probabilities between nodes.</p>
<div class="math notranslate nohighlight">
\[
P_{ij} = \frac{A_{ij}}{k_i}
\]</div>
<p>Let us first compute the transition probabilities and store them in a matrix, <span class="math notranslate nohighlight">\(\mathbf{P}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_adjacency_sparse</span><span class="p">()</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">degree</span><span class="p">())</span>
<span class="n">n_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">()</span>

<span class="c1"># A simple but inefficient way to compute P</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">/</span> <span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Alternative, more efficient way to compute P</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">A</span> <span class="o">/</span> <span class="n">k</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

<span class="c1"># or even more efficiently</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ij,i-&gt;ij&quot;</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Transition probability matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;YlGnBu&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Each row and column of <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> corresponds to a node, with entries representing the transition probabilities from the row node to the column node.</p>
<p>Now, let us simulate a random walk on this graph. We represent a position of the walker by a vector, <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, with five elements, each of which represents a node. We mark the node that the walker is currently at by <code class="docutils literal notranslate"><span class="pre">1</span></code> and others as <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Initial position of the walker:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This vector representation is convenient to get the probabilities of transitions to other nodes from the current node:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x} \mathbf{P}
\]</div>
<p>which is translated into the following code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">probs</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">P</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Position of the walker after one step:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">probs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can then draw the next node based on the probabilities</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">next_node</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">probs</span><span class="p">)</span>
<span class="n">x</span><span class="p">[:]</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># zero out the vector</span>
<span class="n">x</span><span class="p">[</span><span class="n">next_node</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># set the next node to 1</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Position of the walker after one step:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>By repeating this process, we can simulate the random walk.</p>
<section id="id116">
<h2>Exercise 01<a class="headerlink" href="#id116" title="Link to this heading">#</a></h2>
<p>Write the following function to simulate the random walk for a given number of steps and return the <span class="math notranslate nohighlight">\(x\)</span> for each step.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">random_walk</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simulate the random walk on a graph with adjacency matrix A.</span>

<span class="sd">    Args:</span>
<span class="sd">        A (np.ndarray): The adjacency matrix of the graph.</span>
<span class="sd">        x (np.ndarray): The initial position of the walker.</span>
<span class="sd">        n_steps (int): The number of steps to simulate.</span>

<span class="sd">    Returns:</span>
<span class="sd">        np.ndarray: The position of the walker after each step.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Your code here</span>
    <span class="k">pass</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="expected-behavior-of-random-walks">
<h2>Expected behavior of random walks<a class="headerlink" href="#expected-behavior-of-random-walks" title="Link to this heading">#</a></h2>
<p>What is the expected position of the walker after multiple steps? It is easy to compute the expected position of the walker after one step from initial position <span class="math notranslate nohighlight">\(x(0)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[x(1)] = x(0) P
\]</div>
<p>where <span class="math notranslate nohighlight">\(x(t)\)</span> is the probability distribution of the walker at time <span class="math notranslate nohighlight">\(t\)</span>. In Python, the expected position of the walker at time <span class="math notranslate nohighlight">\(t=1\)</span> is given by</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">x_1</span> <span class="o">=</span> <span class="n">x_0</span> <span class="o">@</span> <span class="n">P</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Expected position of the walker after one step:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">x_1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For the second step, the expected position of the walker is given by</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[x(2)] = \mathbb{E}[x(1) P] = \mathbb{E}[x(0) P] P = x(0) P^2
\]</div>
<p>In other words,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_2</span> <span class="o">=</span> <span class="n">x_1</span> <span class="o">@</span> <span class="n">P</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Expected position of the walker after two steps:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">x_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Following the same argument, the expected position of the walker at time <span class="math notranslate nohighlight">\(t\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[x(t)] = x(0) P^t
\]</div>
<section id="id117">
<h3>Exercise 02<a class="headerlink" href="#id117" title="Link to this heading">#</a></h3>
<p>Write a function to compute the expected position of the walker at time <span class="math notranslate nohighlight">\(t\)</span> using the above formula:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">expected_position</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the expected position of the walker at time t.</span>

<span class="sd">    Args:</span>
<span class="sd">        A (np.ndarray): The adjacency matrix of the graph.</span>
<span class="sd">        x_0 (np.ndarray): The initial position of the walker.</span>
<span class="sd">        t (int): The number of steps to simulate.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Your code here</span>
    <span class="k">pass</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="exercise-03">
<h3>Exercise 03<a class="headerlink" href="#exercise-03" title="Link to this heading">#</a></h3>
<p>Plot each element of <span class="math notranslate nohighlight">\(x(t)\)</span> as a function of <span class="math notranslate nohighlight">\(t\)</span> for <span class="math notranslate nohighlight">\(t=0,1,2,\ldots, 1000\)</span>. Try different initial positions and compare the results!</p>
<p>Steps:</p>
<ol class="arabic simple">
<li><p>Define the initial position of the walker.</p></li>
<li><p>Compute the expected position of the walker at time <span class="math notranslate nohighlight">\(t\)</span> using the function you wrote above.</p></li>
<li><p>Draw a line for each element of <span class="math notranslate nohighlight">\(x(t)\)</span>, totalling 5 lines.</p></li>
<li><p>Create multiple such plots for different initial positions and compare them.</p></li>
</ol>
</section>
</section>
<section id="community-structure">
<h2>Community structure<a class="headerlink" href="#community-structure" title="Link to this heading">#</a></h2>
<p>Random walks can capture community structure of a network.
To see this, let us consider a network of a ring of cliques.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">igraph</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">n_cliques</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">n_nodes_per_clique</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ring_of_cliques</span><span class="p">(</span><span class="n">n_cliques</span><span class="p">,</span> <span class="n">n_nodes_per_clique</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">igraph</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">Adjacency</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">to_numpy_array</span><span class="p">(</span><span class="n">G</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span><span class="o">.</span><span class="n">as_undirected</span><span class="p">()</span>
<span class="n">membership</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_cliques</span><span class="p">),</span> <span class="n">n_nodes_per_clique</span><span class="p">)</span>

<span class="n">color_map</span> <span class="o">=</span> <span class="p">[</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">membership</span><span class="p">]</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vertex_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="n">color_map</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us compute the expected position of the walker after 1 to 10 steps.</p>
<p><strong>Compute the transition matrix</strong>:</p>
<div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">sparse</span>

<span class="c1"># Get the adjacency matrix and degree</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_adjacency_sparse</span><span class="p">()</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">degree</span><span class="p">())</span>

<span class="c1"># This is an efficient way to compute the transition matrix</span>
<span class="c1"># using scipy.sparse</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">diags</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">k</span><span class="p">)</span> <span class="o">@</span> <span class="n">A</span>
</pre></div>
</div>
</div>
</details>
</div>
<p><strong>Compute the expected position of the walker after 1 to 300 steps</strong>:</p>
<div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">())</span>
<span class="n">x_t</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">x_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_t</span><span class="p">]</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">300</span><span class="p">):</span>
    <span class="n">x_t</span> <span class="o">=</span> <span class="n">x_t</span> <span class="o">@</span> <span class="n">P</span>
    <span class="n">x_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_t</span><span class="p">)</span>
<span class="n">x_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p><strong>Plot the expected position of the walker at each step</strong>:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;ticks&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">ncols</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">nrows</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">t_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">299</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">t_list</span><span class="p">):</span>
    <span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vertex_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">cmap</span><span class="p">(</span><span class="n">x_list</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x_list</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">())],</span> <span class="n">target</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="o">//</span><span class="mi">3</span><span class="p">][</span><span class="n">i</span><span class="o">%</span><span class="k">3</span>])
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="o">//</span><span class="mi">3</span><span class="p">][</span><span class="n">i</span><span class="o">%</span><span class="k">3</span>].set_title(f&quot;$t$ = {t}&quot;, fontsize = 25)
</pre></div>
</div>
</div>
</details>
</div>
<p>where the color of each node represents the probability of the walker being at that node.</p>
<p>An important observation is that the walker spends more time in the clique that it started from and then diffuse to others. Thus, the position of the walker before reaching the steady state tells us the community structure of the network.</p>
</section>
<section id="exercise-04">
<h2>Exercise 04<a class="headerlink" href="#exercise-04" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Generate a network of 100 nodes with 4 communities using a stochastic block model, with inter-community edge probability <span class="math notranslate nohighlight">\(0.05\)</span> and intra-community edge probability <span class="math notranslate nohighlight">\(0.2\)</span>. Then, compute the expected position of the walker starting from node zero after <span class="math notranslate nohighlight">\(x\)</span> steps. Plot the results for <span class="math notranslate nohighlight">\(x = 0, 5, 10, 1000\)</span>.</p></li>
<li><p>Increase the inter-community edge probability to <span class="math notranslate nohighlight">\(0.15\)</span> and repeat the simulation. Compare the results with the previous simulation.</p></li>
</ol>
</section>
<hr class="docutils" />
<section id="id118">
<h2>jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3<a class="headerlink" href="#id118" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="characteristics-of-random-walks">
<h1>Characteristics of Random Walks<a class="headerlink" href="#characteristics-of-random-walks" title="Link to this heading">#</a></h1>
<section id="stationary-state">
<h2>Stationary State<a class="headerlink" href="#stationary-state" title="Link to this heading">#</a></h2>
<p>Let’s dive into the math behind random walks in a way that’s easy to understand.</p>
<p>Imagine you’re at node <span class="math notranslate nohighlight">\(i\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>. You randomly move to a neighboring node <span class="math notranslate nohighlight">\(j\)</span>. The probability of this move, called the transition probability <span class="math notranslate nohighlight">\(p_{ij}\)</span>, is:</p>
<div class="math notranslate nohighlight">
\[
p_{ij} = \frac{A_{ij}}{k_i},
\]</div>
<p>Here, <span class="math notranslate nohighlight">\(A_{ij}\)</span> is an element of the adjacency matrix, and <span class="math notranslate nohighlight">\(k_i\)</span> is the degree of node <span class="math notranslate nohighlight">\(i\)</span>. For a network with <span class="math notranslate nohighlight">\(N\)</span> nodes, we can represent all transition probabilities in a transition probability matrix <span class="math notranslate nohighlight">\(P\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{P} = \begin{pmatrix}
p_{11} &amp; p_{12} &amp; \cdots &amp; p_{1N} \\
p_{21} &amp; p_{22} &amp; \cdots &amp; p_{2N} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
p_{N1} &amp; p_{N2} &amp; \cdots &amp; p_{NN}
\end{pmatrix}
\end{split}\]</div>
<p>This matrix <span class="math notranslate nohighlight">\(P\)</span> encapsulates the entire random walk process. We can use it to calculate the probability of visiting each node after any number of steps. For instance:</p>
<ul class="simple">
<li><p>After one step: <span class="math notranslate nohighlight">\(P_{ij} = p_{ij}\)</span></p></li>
<li><p>After two steps: <span class="math notranslate nohighlight">\(\left(\mathbf{P}^{2}\right)_{ij} = \sum_{k} P_{ik} P_{kj}\)</span></p></li>
<li><p>After <span class="math notranslate nohighlight">\(T\)</span> steps: <span class="math notranslate nohighlight">\(\left(\mathbf{P}^{T}\right)_{ij}\)</span></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Let’s explore why <span class="math notranslate nohighlight">\(\mathbf{P}^2\)</span> represents the transition probabilities after two steps.</p>
<p>First, recall that <span class="math notranslate nohighlight">\(\mathbf{P}_{ij}\)</span> is the probability of moving from node <span class="math notranslate nohighlight">\(i\)</span> to node <span class="math notranslate nohighlight">\(j\)</span> in one step. Now, consider a two-step walk from <span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(j\)</span>. We can express this as:</p>
<div class="math notranslate nohighlight">
\[(\mathbf{P}^2)_{ij} = \sum_k \mathbf{P}_{ik} \mathbf{P}_{kj}\]</div>
<p>This equation encapsulates a key idea: to go from <span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(j\)</span> in two steps, we must pass through some intermediate node <span class="math notranslate nohighlight">\(k\)</span>. Let’s break this down step by step:</p>
<ol class="arabic simple">
<li><p>The probability of the first step (<span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(k\)</span>) is <span class="math notranslate nohighlight">\(\mathbf{P}_{ik}\)</span>.</p></li>
<li><p>The probability of the second step (<span class="math notranslate nohighlight">\(k\)</span> to <span class="math notranslate nohighlight">\(j\)</span>) is <span class="math notranslate nohighlight">\(\mathbf{P}_{kj}\)</span>.</p></li>
<li><p>The probability of this specific path (<span class="math notranslate nohighlight">\(i\)</span> → <span class="math notranslate nohighlight">\(k\)</span> → <span class="math notranslate nohighlight">\(j\)</span>) is the product <span class="math notranslate nohighlight">\(\mathbf{P}_{ik} \mathbf{P}_{kj}\)</span>.</p></li>
<li><p>We sum over all possible intermediate nodes <span class="math notranslate nohighlight">\(k\)</span> to get the total probability.</p></li>
</ol>
<p>Likewise, for three steps, we have:</p>
<div class="math notranslate nohighlight">
\[(\mathbf{P}^3)_{ij} = \sum_k \left( \mathbf{P}\right)^2_{ik} \mathbf{P}_{kj}\]</div>
<p>where:</p>
<ol class="arabic simple">
<li><p>The probability of going from <span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(k\)</span> in two steps is <span class="math notranslate nohighlight">\(\left( \mathbf{P}\right)^2_{ik}\)</span>.</p></li>
<li><p>The probability of going from <span class="math notranslate nohighlight">\(k\)</span> to <span class="math notranslate nohighlight">\(j\)</span> in one step is <span class="math notranslate nohighlight">\(\mathbf{P}_{kj}\)</span>.</p></li>
<li><p>The probability of this specific path (<span class="math notranslate nohighlight">\(i\)</span> →…→<span class="math notranslate nohighlight">\(k\)</span> → <span class="math notranslate nohighlight">\(j\)</span>) is the product <span class="math notranslate nohighlight">\(\left( \mathbf{P}\right)^2_{ik} \mathbf{P}_{kj}\)</span>.</p></li>
<li><p>We sum over all possible intermediate nodes <span class="math notranslate nohighlight">\(k\)</span> to get the total probability.</p></li>
</ol>
<p>And we can extend this reasoning for any number of steps <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>In summary, for any number of steps <span class="math notranslate nohighlight">\(t\)</span>, <span class="math notranslate nohighlight">\(\left( \mathbf{P}^t \right)_{ij}\)</span> gives the probability of being at node <span class="math notranslate nohighlight">\(j\)</span> after <span class="math notranslate nohighlight">\(t\)</span> steps, starting from node <span class="math notranslate nohighlight">\(i\)</span>.</p>
</div>
<p>As <span class="math notranslate nohighlight">\(T\)</span> becomes very large, the probability distribution of being at each node, <span class="math notranslate nohighlight">\(\mathbf{x}(t)\)</span>, approaches a constant value:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}(t+1) =\mathbf{x}(t) \mathbf{P}
\]</div>
<p>This is an eigenvector equation. The solution, given by the Perron-Frobenius theorem, is called the stationary distribution:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}(\infty) = \mathbb{\pi}, \; \mathbf{\pi} = [\pi_1, \ldots, \pi_N]
\]</div>
<p>For undirected networks, this stationary distribution always exists and is proportional to the degree of each node:</p>
<div class="math notranslate nohighlight">
\[
\pi_j = \frac{k_j}{\sum_{\ell} k_\ell} \propto k_j
\]</div>
<p>This means the probability of being at node <span class="math notranslate nohighlight">\(j\)</span> in the long run is proportional to the degree of node <span class="math notranslate nohighlight">\(j\)</span>. The normalization ensures that the sum of all probabilities is 1, i.e., <span class="math notranslate nohighlight">\(\sum_{j=1}^N \pi_j = 1\)</span>.</p>
</section>
<section id="experiment">
<h2>Experiment<a class="headerlink" href="#experiment" title="Link to this heading">#</a></h2>
<p>Let us demonstrate the above math by using a small network using Python. Let us consider a small network of 5 nodes, which looks like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">igraph</span> <span class="k">as</span> <span class="nn">ig</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">edge_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
        <span class="n">edge_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>
        <span class="n">edge_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="o">+</span><span class="mi">5</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">5</span><span class="p">))</span>
<span class="n">edge_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="n">edge_list</span><span class="p">)</span>
<span class="n">ig</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vertex_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">vertex_label</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<p>The transition probability matrix <span class="math notranslate nohighlight">\(P\)</span> is given by:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sparse</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_adjacency_sparse</span><span class="p">()</span>
<span class="n">deg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">Dinv</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">diags</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">deg</span><span class="p">)</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">Dinv</span> <span class="o">@</span> <span class="n">A</span>
<span class="n">P</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let us compute the stationary distribution by using the power method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">())</span>
<span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># Start from node 1</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">xt</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">@</span> <span class="n">P</span>
    <span class="n">xt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">xt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span> <span class="c1"># Stack the results vertically</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">palette</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()</span><span class="o">.</span><span class="n">as_hex</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">()):</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">y</span><span class="o">=</span><span class="n">xt</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Node </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">palette</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Probability&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Stationary distribution of a random walk&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.05</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We see that the distributions of the walker converges, and there are three characteristic features in the convergence:</p>
<ol class="arabic simple">
<li><p>The distribution of the walker occilates with a decying amplitude and eventually converges.</p></li>
<li><p>Nodes of the same degree converge to the same stationary probability.</p></li>
<li><p>Nodes with higher degree converge to the higher stationary probability.</p></li>
</ol>
<p>To validate the last two observation, let us compare the stationary distribution of a random walker with the expected stationary distribution, which is proportional to the degree of the nodes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">n_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">deg</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">expected_stationary_dist</span> <span class="o">=</span> <span class="n">deg</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_edges</span><span class="p">)</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Expected stationary distribution&quot;</span><span class="p">:</span> <span class="n">expected_stationary_dist</span><span class="p">,</span>
    <span class="s2">&quot;Stationary distribution of a random walk&quot;</span><span class="p">:</span> <span class="n">xt</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="p">})</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">set_caption</span><span class="p">(</span><span class="s2">&quot;Comparison of Expected and Observed Stationary Distributions&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;cividis&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="time-to-reach-the-stationary-state">
<h2>Time to reach the stationary state<a class="headerlink" href="#time-to-reach-the-stationary-state" title="Link to this heading">#</a></h2>
<p>Let’s explore how quickly a random walker reaches its stationary state. The convergence speed is influenced by two main factors: edge density and community structure. In sparse networks, the walker needs more steps to explore the entire network. Additionally, the walker tends to remain within its starting community for some time.</p>
<p>The mixing time, denoted as <span class="math notranslate nohighlight">\(t_{\text{mix}}\)</span>, is defined as the minimum number of steps required for a random walk to get close to the stationary distribution, regardless of the starting point, with the maximum error less than <span class="math notranslate nohighlight">\(\epsilon\)</span>:</p>
<div class="math notranslate nohighlight">
\[t_{\text{mix}} = \min\{t : \max_{{\bf x}(0)} \|{\bf x}(t) - {\bf \pi}\|_{1} \leq \epsilon\}\]</div>
<p>where <span class="math notranslate nohighlight">\(\|{\bf x}(t) - {\bf \pi}\|_{1} = 2\max_{i} |x_i(t) - \pi_i|\)</span> represents the L1 distance between two probability distributions. The choice of <span class="math notranslate nohighlight">\(\epsilon\)</span> is arbitrary.</p>
<p>We know that the distribution of a walker after <span class="math notranslate nohighlight">\(t\)</span> steps is given by:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}(t) =  \mathbf{x}(0) \mathbf{P} ^{t}
\]</div>
<p>To find this distribution, we need to compute <span class="math notranslate nohighlight">\(\mathbf{P}^t\)</span>. However, we face a challenge: <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> is not diagonalizable.</p>
<p>A diagonalizable matrix <span class="math notranslate nohighlight">\(\mathbf{S}\)</span> can be written as <span class="math notranslate nohighlight">\(\mathbf{S} = \mathbf{Q} \mathbf{\Lambda} \mathbf{Q}^{-1}\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{\Lambda}\)</span> is a diagonal matrix and <span class="math notranslate nohighlight">\(\mathbf{Q}\)</span> is an orthogonal matrix. Visually, it looks like this:</p>
<p><img alt="" src="../_images/diagonalizable.jpg" /></p>
<p>It is useful because we can then compute the power of the matrix as follows:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{S}^t = \mathbf{Q} \mathbf{\Lambda}^t \mathbf{Q}^{-1}
\]</div>
<p>And it is easy to find <span class="math notranslate nohighlight">\({\bf Q}\)</span> and <span class="math notranslate nohighlight">\({\bf \Lambda}\)</span> by using eigenvalue decomposition if <span class="math notranslate nohighlight">\({\bf S}\)</span> is symmetric and consists only of real values. Namely, the eigenvectors form <span class="math notranslate nohighlight">\({\cal Q}\)</span> and the eigenvalues form the diagonal matrix <span class="math notranslate nohighlight">\({\cal \Lambda}\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Let us demonstrate the above relation by calculating <span class="math notranslate nohighlight">\(\mathbf{S}^2\)</span>.
$$</p>
<div class="amsmath math notranslate nohighlight" id="equation-c1f46e0a-d438-42d9-a674-da4c070ecbfc">
<span class="eqno">()<a class="headerlink" href="#equation-c1f46e0a-d438-42d9-a674-da4c070ecbfc" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathbf{S}^2 &amp;= \mathbf{Q} \mathbf{\Lambda} \mathbf{Q}^{-1} \mathbf{Q} \mathbf{\Lambda} \mathbf{Q}^{-1} \\
&amp;= \mathbf{Q} \mathbf{\Lambda}^2 \mathbf{Q}^{-1}.
\end{align}\]</div>
<p>$<span class="math notranslate nohighlight">\(
(Note that \)</span>\mathbf{Q} \mathbf{Q}^{-1} = {\bf I}$.)</p>
<p><img alt="" src="../_images/diagonalizable-squared.jpg" /></p>
</div>
<p><span class="math notranslate nohighlight">\(\mathbf{P}\)</span> is also diagonalizable but not symmetric like <span class="math notranslate nohighlight">\(\mathbf{\overline A}\)</span> so that we cannot use the above relation directly. So we do a trick by rewriteing <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> as:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{P} = \mathbf{D}^{-1} \mathbf{A} = \mathbf{D}^{-\frac{1}{2}} \overline {\bf A} \mathbf{D}^{\frac{1}{2}}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\overline{\bf A} = \mathbf{D}^{-\frac{1}{2}} \mathbf{A} \mathbf{D}^{-\frac{1}{2}}\)</span> is the normalized adjacency matrix.</p>
<p>The advantage is that <span class="math notranslate nohighlight">\(\overline{\bf A}\)</span> is diagonalizable: <span class="math notranslate nohighlight">\(\overline{\bf A} = \mathbf{Q} \mathbf{\Lambda} \mathbf{Q}^\top\)</span>. Using this, we can compute <span class="math notranslate nohighlight">\(\mathbf{P}^t\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{P}^t = \mathbf{D}^{-\frac{1}{2}} \mathbf{Q} \mathbf{\Lambda}^t \mathbf{Q}^\top \mathbf{D}^{\frac{1}{2}} = \mathbf{Q}_L \mathbf{\Lambda}^t \mathbf{Q}_R ^\top
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{Q}_L = \mathbf{D}^{-\frac{1}{2}} \mathbf{Q}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Q}_R = \mathbf{D}^{\frac{1}{2}} \mathbf{Q}\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Let us demonstrate the above relation by calculating <span class="math notranslate nohighlight">\(\mathbf{P}^2\)</span>.</p>
<p>$$</p>
<div class="amsmath math notranslate nohighlight" id="equation-159353b9-d7ee-48be-9be1-a62861402e9e">
<span class="eqno">()<a class="headerlink" href="#equation-159353b9-d7ee-48be-9be1-a62861402e9e" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathbf{P}^2 &amp;= \mathbf{D}^{-\frac{1}{2}} \overline{\bf A} \mathbf{D}^{\frac{1}{2}} \mathbf{D}^{-\frac{1}{2}} \overline{\bf A} \mathbf{D}^{\frac{1}{2}}\\
&amp;=  \mathbf{D}^{-\frac{1}{2}} \overline{\bf A} ^2 \mathbf{D}^{\frac{1}{2}}\\
&amp;= \mathbf{Q}_L \mathbf{\Lambda}^2 \mathbf{Q}_R ^\top
\end{align}\]</div>
</div>
<p>The probability distribution after <span class="math notranslate nohighlight">\(t\)</span> steps is then:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}(t) = \mathbf{x}(0) \mathbf{Q}_L \mathbf{\Lambda}^t \mathbf{Q}_R ^\top
\]</div>
<p>We can rewrite this in a more intuitive form:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{pmatrix}
x_1(t) \\
x_2(t) \\
\vdots \\
x_N(t)
\end{pmatrix}
 =
 \sum_{\ell=1}^N
 \left[
 \lambda_\ell^t
 \begin{pmatrix}
 q^{(L)}_{\ell 1} \\
 q^{(L)}_{\ell 2} \\
 \vdots \\
 q^{(L)}_{\ell N}
 \end{pmatrix}
 \langle\mathbf{q}^{(R)}_{\ell},  \mathbf{x}(0) \rangle
 \right]
\end{split}\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Visualize the above equation by using the following figure.</p>
<p><img alt="" src="../_images/diagonalizable-sum.jpg" /></p>
</div>
<p>The term <span class="math notranslate nohighlight">\(\lambda_\ell^t\)</span> represents the contribution of each eigenvalue to the stationary distribution over time. As <span class="math notranslate nohighlight">\(t\)</span> increases, all terms decay exponentially except for the largest eigenvalue (<span class="math notranslate nohighlight">\(\lambda_1 = 1\)</span>). This explains how the random walk converges to the stationary distribution:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pi_i = \lim_{t\to\infty} x_i(t) = \begin{pmatrix} q^{(L)}_{1 1} \\ q^{(L)}_{1 2} \\ \vdots \\ q^{(L)}_{1 N} \end{pmatrix} \langle\mathbf{q}^{(R)}_{1},  \mathbf{x}(0) \rangle
\end{split}\]</div>
<p>The second largest eigenvalue primarily determines the convergence speed to the stationary distribution. A larger second eigenvalue leads to slower convergence. Thus, the mixing time is closely related to the second largest eigenvalue.</p>
<p>Levin-Peres-Wilmer theorem states that the mixing time is bounded by the relaxation time as</p>
<div class="math notranslate nohighlight">
\[
t_{\text{mix}} &lt; \tau \log \left( \frac{1}{\epsilon \min_{i} \pi_i} \right), \quad \tau = \frac{1}{\lambda_2}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda_2\)</span> is the second largest eigenvalue of the normalized adjacency matrix. The mixing time is known to be bounded by the relaxation time as</p>
<p>More commonly, it is expressed using the second smallest eigenvalue <span class="math notranslate nohighlight">\(\mu\)</span> of the normalized laplacian matrix as</p>
<div class="math notranslate nohighlight">
\[
t_{\text{mix}} \leq \frac{1}{1-\mu}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu = 1-\lambda_2\)</span>.</p>
<section id="compute-the-mixing-time">
<h3>Compute the mixing time<a class="headerlink" href="#compute-the-mixing-time" title="Link to this heading">#</a></h3>
<p>Let us demonstrate the above math by using the network of two cliques.</p>
<section id="normalized-adjacency-matrix">
<h4>Normalized Adjacency Matrix<a class="headerlink" href="#normalized-adjacency-matrix" title="Link to this heading">#</a></h4>
<p>First, let us construct the normalized adjacency matrix <span class="math notranslate nohighlight">\(\overline{\bf A}\)</span> of the network.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Dinv_sqrt</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">diags</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">deg</span><span class="p">))</span>
<span class="n">A_norm</span> <span class="o">=</span> <span class="n">Dinv_sqrt</span> <span class="o">@</span> <span class="n">A</span> <span class="o">@</span> <span class="n">Dinv_sqrt</span>
</pre></div>
</div>
</div>
</div>
<p>Next, let us compute the eigenvalues and eigenvectors of the normalized adjacency matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">evals</span><span class="p">,</span> <span class="n">evecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">A_norm</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">evals</span></code> and <code class="docutils literal notranslate"><span class="pre">evecs</span></code> are sorted in descending order of the eigenvalues. <code class="docutils literal notranslate"><span class="pre">evecs[:,</span> <span class="pre">0]</span></code> is the eigenvector corresponding to the largest eigenvalue, which is always 1.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>There is a similar function called <code class="docutils literal notranslate"><span class="pre">np.linalg.eig</span></code> which returns the eigenvalues and eigenvectors. It can be used for any matrices, while <code class="docutils literal notranslate"><span class="pre">np.linalg.eigh</span></code> is specifically for symmetric matrices. <code class="docutils literal notranslate"><span class="pre">np.linalg.eigh</span></code> is faster and more stable and therefore preferred if your matrix is symmetric. <code class="docutils literal notranslate"><span class="pre">np.linalg.eig</span></code> is more susceptible to numerical errors and therefore less stable.</p>
</div>
<p>The eigenvalues and eigenvectors are shown below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Eigenvalue&quot;</span><span class="p">:</span> <span class="n">evals</span>
<span class="p">})</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;cividis&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">set_caption</span><span class="p">(</span><span class="s2">&quot;Eigenvalues of the normalized adjacency matrix&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Eigenvector </span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">i</span><span class="p">:</span> <span class="n">evecs</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="p">})</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;cividis&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">set_caption</span><span class="p">(</span><span class="s2">&quot;Eigenvectors of the normalized adjacency matrix&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that the largest eigenvalue is 1, which is always true for a normalized adjacency matrix.
The largest eigenvector (the leftmost one) is associated with the stationary distribution of the random walk.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The sign of the eigenvector is indeterminate, which means we can choose the sign of the eigenvector arbitrarily. In fact, <code class="docutils literal notranslate"><span class="pre">np.linalg.eigh</span></code> returns the eigenvector whose sign can vary for a different run.</p>
</div>
<p>We decompose <span class="math notranslate nohighlight">\(\overline{\bf A}\)</span> as</p>
<div class="math notranslate nohighlight">
\[\overline {\bf A} = {\bf Q}{\bf \Lambda}{\bf Q}^\top\]</div>
<p>where <span class="math notranslate nohighlight">\({\bf Q}\)</span> corresponds to <code class="docutils literal notranslate"><span class="pre">eigvecs</span></code> and <span class="math notranslate nohighlight">\({\bf \Lambda}\)</span> corresponds to <code class="docutils literal notranslate"><span class="pre">np.diag(evals)</span></code> (since <span class="math notranslate nohighlight">\({\bf \Lambda}\)</span> is a diagonal matrix). Let’s see if this is correct:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">A_norm</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;cividis&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">set_caption</span><span class="p">(</span><span class="s2">&quot;Normalized Adjacency Matrix&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A_norm_reconstructed</span> <span class="o">=</span> <span class="n">evecs</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span> <span class="o">@</span> <span class="n">evecs</span><span class="o">.</span><span class="n">T</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">A_norm_reconstructed</span><span class="p">)</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;cividis&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">set_caption</span><span class="p">(</span><span class="s2">&quot;Reconstruction of the Normalized Adjacency Matrix&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that the reconstruction is not perfect due to the numerical error, although overall the structure is correct.</p>
</section>
<section id="multi-step-transition-probability">
<h4>Multi-step Transition Probability<a class="headerlink" href="#multi-step-transition-probability" title="Link to this heading">#</a></h4>
<p>Let us first conform whether we can compute the transition probability after <span class="math notranslate nohighlight">\(t\)</span> steps by using the eigenvalues and eigenvectors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">x_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">())</span>
<span class="n">x_0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Compute x_t by using the eigenvalues and eigenvectors</span>
<span class="n">Q_L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">deg</span><span class="p">))</span> <span class="o">@</span> <span class="n">evecs</span>
<span class="n">Q_R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">deg</span><span class="p">))</span> <span class="o">@</span> <span class="n">evecs</span>
<span class="n">x_t</span> <span class="o">=</span> <span class="n">x_0</span> <span class="o">@</span> <span class="n">Q_L</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">evals</span><span class="o">**</span><span class="n">t</span><span class="p">)</span> <span class="o">@</span> <span class="n">Q_R</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># Compute x_t by using the power iteration</span>
<span class="n">x_t_power</span> <span class="o">=</span> <span class="n">x_0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
    <span class="n">x_t_power</span> <span class="o">=</span> <span class="n">x_t_power</span> <span class="o">@</span> <span class="n">P</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Eigenvector&quot;</span><span class="p">:</span> <span class="n">x_t</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
    <span class="s2">&quot;Power iteration&quot;</span><span class="p">:</span> <span class="n">x_t_power</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="p">})</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;cividis&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">set_caption</span><span class="p">(</span><span class="s2">&quot;Comparison of Eigenvector and Power Iteration&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="relaxation-time-and-mixing-time">
<h4>Relaxation Time and Mixing Time<a class="headerlink" href="#relaxation-time-and-mixing-time" title="Link to this heading">#</a></h4>
<p>Let us measure the relaxation time of the random walk.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">evals</span><span class="p">,</span> <span class="n">evecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">A_norm</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
<span class="n">lambda_2</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="o">-</span><span class="n">evals</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">tau</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">lambda_2</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The relaxation time of the random walk is </span><span class="si">{</span><span class="n">tau</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="err">```</span><span class="o">---</span>
<span class="n">jupytext</span><span class="p">:</span>
  <span class="n">formats</span><span class="p">:</span> <span class="n">md</span><span class="p">:</span><span class="n">myst</span>
  <span class="n">text_representation</span><span class="p">:</span>
    <span class="n">extension</span><span class="p">:</span> <span class="o">.</span><span class="n">md</span>
    <span class="n">format_name</span><span class="p">:</span> <span class="n">myst</span>
<span class="n">kernelspec</span><span class="p">:</span>
  <span class="n">display_name</span><span class="p">:</span> <span class="n">Python</span> <span class="mi">3</span>
  <span class="n">language</span><span class="p">:</span> <span class="n">python</span>
  <span class="n">name</span><span class="p">:</span> <span class="n">python3</span>
<span class="o">---</span>

<span class="c1"># Random Walks</span>

<span class="n">Suppose</span> <span class="n">you</span> <span class="n">walk</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">city</span><span class="o">.</span> <span class="n">You</span> <span class="n">are</span> <span class="n">drunk</span> <span class="ow">and</span> <span class="n">your</span> <span class="n">feet</span> <span class="n">have</span> <span class="n">no</span> <span class="n">idea</span> <span class="n">where</span> <span class="n">to</span> <span class="n">go</span><span class="o">.</span> <span class="n">You</span> <span class="n">just</span> <span class="n">take</span> <span class="n">a</span> <span class="n">step</span> <span class="n">wherever</span> <span class="n">your</span> <span class="n">feet</span> <span class="n">take</span> <span class="n">you</span><span class="o">.</span> <span class="n">At</span> <span class="n">every</span> <span class="n">intersection</span><span class="p">,</span> <span class="n">you</span> <span class="n">make</span> <span class="n">a</span> <span class="n">random</span> <span class="n">decision</span> <span class="ow">and</span> <span class="n">take</span> <span class="n">a</span> <span class="n">step</span><span class="o">.</span> <span class="n">This</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">core</span> <span class="n">idea</span> <span class="n">of</span> <span class="n">a</span> <span class="n">random</span> <span class="n">walk</span><span class="o">.</span>

<span class="n">While</span> <span class="n">your</span> <span class="n">feet</span> <span class="n">are</span> <span class="n">taking</span> <span class="n">you</span> <span class="n">to</span> <span class="n">a</span> <span class="n">random</span> <span class="n">street</span><span class="p">,</span> <span class="n">after</span> <span class="n">making</span> <span class="n">many</span> <span class="n">steps</span> <span class="ow">and</span> <span class="n">looking</span> <span class="n">back</span><span class="p">,</span> <span class="n">you</span> <span class="n">will</span> <span class="n">realize</span> <span class="n">that</span> <span class="n">you</span> <span class="n">have</span> <span class="n">been</span> <span class="n">to</span> <span class="n">certain</span> <span class="n">places</span> <span class="n">more</span> <span class="n">frequently</span> <span class="n">than</span> <span class="n">others</span><span class="o">.</span> <span class="n">If</span> <span class="n">you</span> <span class="n">were</span> <span class="n">to</span> <span class="nb">map</span> <span class="n">the</span> <span class="n">frequency</span> <span class="n">of</span> <span class="n">your</span> <span class="n">visits</span> <span class="n">to</span> <span class="n">each</span> <span class="n">street</span><span class="p">,</span> <span class="n">you</span> <span class="n">will</span> <span class="n">end</span> <span class="n">up</span> <span class="k">with</span> <span class="n">a</span> <span class="n">distribution</span> <span class="n">that</span> <span class="n">tells</span> <span class="n">you</span> <span class="n">about</span> <span class="n">salient</span> <span class="n">structure</span> <span class="n">of</span> <span class="n">the</span> <span class="n">street</span> <span class="n">network</span><span class="o">.</span> <span class="n">It</span> <span class="ow">is</span> <span class="n">surprising</span> <span class="n">that</span> <span class="n">this</span> <span class="n">seemingly</span> <span class="n">random</span><span class="p">,</span> <span class="n">brainless</span> <span class="n">behavior</span> <span class="n">can</span> <span class="n">tell</span> <span class="n">us</span> <span class="n">something</span> <span class="n">deep</span> <span class="n">about</span> <span class="n">the</span> <span class="n">structure</span> <span class="n">of</span> <span class="n">the</span> <span class="n">city</span><span class="o">.</span>


<span class="o">&lt;</span><span class="n">img</span> <span class="n">src</span><span class="o">=</span><span class="s2">&quot;../figs/random-walk.png&quot;</span> <span class="n">alt</span><span class="o">=</span><span class="s2">&quot;Random walk on a network&quot;</span> <span class="n">width</span><span class="o">=</span><span class="s2">&quot;50%&quot;</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;display: block; margin-left: auto; margin-right: auto;&quot;</span><span class="o">&gt;</span>

<span class="c1">## Random walks in a network</span>

<span class="n">A</span> <span class="n">random</span> <span class="n">walk</span> <span class="ow">in</span> <span class="n">undirected</span> <span class="n">networks</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">following</span> <span class="n">process</span><span class="p">:</span>
<span class="mf">1.</span> <span class="n">Start</span> <span class="n">at</span> <span class="n">a</span> <span class="n">node</span> <span class="err">$</span><span class="n">i</span><span class="err">$</span>
<span class="mf">2.</span> <span class="n">Randomly</span> <span class="n">choose</span> <span class="n">an</span> <span class="n">edge</span> <span class="n">to</span> <span class="n">traverse</span> <span class="n">to</span> <span class="n">a</span> <span class="n">neighbor</span> <span class="n">node</span> <span class="err">$</span><span class="n">j</span><span class="err">$</span>
<span class="mf">3.</span> <span class="n">Repeat</span> <span class="n">step</span> <span class="mi">2</span> <span class="n">until</span> <span class="n">you</span> <span class="n">have</span> <span class="n">taken</span> <span class="err">$</span><span class="n">T</span><span class="err">$</span> <span class="n">steps</span><span class="o">.</span>


<span class="err">```</span><span class="p">{</span><span class="n">figure</span><span class="o">-</span><span class="n">md</span><span class="p">}</span> <span class="n">random</span><span class="o">-</span><span class="n">walk</span><span class="o">-</span><span class="n">example</span>

<span class="o">&lt;</span><span class="n">img</span> <span class="n">src</span><span class="o">=</span><span class="s2">&quot;https://d3i71xaburhd42.cloudfront.net/a56ca795f324f75baab70bb3b49e0544c89e05f7/2-Figure1-1.png&quot;</span> <span class="n">alt</span><span class="o">=</span><span class="s2">&quot;Random walk example&quot;</span> <span class="n">width</span><span class="o">=</span><span class="s2">&quot;100%&quot;</span><span class="o">&gt;</span>

<span class="n">Random</span> <span class="n">walk</span> <span class="n">on</span> <span class="n">a</span> <span class="n">small</span> <span class="n">network</span><span class="o">.</span> <span class="n">The</span> <span class="n">figure</span> <span class="ow">is</span> <span class="n">taken</span> <span class="kn">from</span> <span class="nn">Li</span><span class="p">,</span> <span class="n">Xing</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="err">“</span><span class="n">Representation</span> <span class="n">Learning</span> <span class="n">of</span> <span class="n">Reconstructed</span> <span class="n">Graphs</span> <span class="n">Using</span> <span class="n">Random</span> <span class="n">Walk</span> <span class="n">Graph</span> <span class="n">Convolutional</span> <span class="n">Network</span><span class="o">.</span><span class="err">”</span> <span class="n">ArXiv</span> <span class="nb">abs</span><span class="o">/</span><span class="mf">2101.00417</span> <span class="p">(</span><span class="mi">2021</span><span class="p">)</span><span class="o">.</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In case of directed networks, a random walker can only move along the edge direction, and it can be that the random walker is stuck in a so-called ``dead end’’ that does not have any outgoing edges.</p>
</div>
<p>How does this simple process tell us something about the network structure? To get some insights, let us play with a simple interactive visualization.</p>
<div class="tip admonition">
<p class="admonition-title">Random Walk Simulation</p>
<p>Play with the <a class="reference external" href="https://skojaku.github.io/adv-net-sci/vis/random-walks/index.html?">Random Walk Simulator! 🎮✨</a> and try to answer the following questions:</p>
<ol class="arabic simple">
<li><p>When the random walker makes many steps, where does it tend to visit most frequently?</p></li>
<li><p>When the walker makes only a few steps, where does it tend to visit?</p></li>
<li><p>Does the behavior of the walker inform us about centrality of the nodes?</p></li>
<li><p>Does the behavior of the walker inform us about communities in the network?</p></li>
</ol>
</div>
</section>
</section>
</section>
<hr class="docutils" />
<section id="id119">
<h2>jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3<a class="headerlink" href="#id119" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="random-walks-unify-centrality-and-communities">
<h1>Random walks unify centrality and communities<a class="headerlink" href="#random-walks-unify-centrality-and-communities" title="Link to this heading">#</a></h1>
<section id="modularity-interpretation-from-random-walk-perspective">
<h2>Modularity: Interpretation from random walk perspective<a class="headerlink" href="#modularity-interpretation-from-random-walk-perspective" title="Link to this heading">#</a></h2>
<p>Modularity can be intepreted as a random walk perspective. Modularity is given by</p>
<div class="math notranslate nohighlight">
\[
Q = \frac{1}{2m} \sum_{ij} \left( A_{ij} - \frac{d_i d_j}{2m} \right) \delta(c_i, c_j)
\]</div>
<p>where <span class="math notranslate nohighlight">\(m\)</span> is the number of edges in the network, <span class="math notranslate nohighlight">\(A_{ij}\)</span> is the adjacency matrix, <span class="math notranslate nohighlight">\(d_i\)</span> is the degree of node <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(c_i\)</span> is the community of node <span class="math notranslate nohighlight">\(i\)</span>, and <span class="math notranslate nohighlight">\(\delta(c_i, c_j)\)</span> is the Kronecker delta function (which is 1 if <span class="math notranslate nohighlight">\(c_i = c_j\)</span> and 0 otherwise).</p>
<p>We can rewrite the modularity using the language of random walks as follows.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
Q &amp;= \sum_{ij} \left(\frac{A_{ij}}{2m}  - \frac{d_i}{2m} \frac{d_j}{2m} \right) \delta(c_i, c_j) \\
&amp;= \sum_{ij} \left(\pi_i P_{ij}  - \pi_i \pi_j \right) \delta(c_i, c_j)
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\pi_i\)</span> is the stationary distribution of the random walk given by</p>
<div class="math notranslate nohighlight">
\[
\pi_i = \frac{d_i}{2m}
\]</div>
<p>and <span class="math notranslate nohighlight">\(P_{ij}\)</span> is the transition probability between nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Let’s break down this derivation step by step:</p>
<ol class="arabic">
<li><p>We start with the original modularity formula:</p>
<div class="math notranslate nohighlight">
\[Q = \frac{1}{2m} \sum_{ij} \left( A_{ij} - \frac{d_i d_j}{2m} \right) \delta(c_i, c_j)\]</div>
</li>
<li><p>First, we move the constant <span class="math notranslate nohighlight">\(1/(2m)\)</span> to the inside of the parentheses:</p>
<div class="math notranslate nohighlight">
\[Q = \sum_{ij} \left(\frac{A_{ij}}{2m} - \frac{d_i d_j}{2m^2} \right) \delta(c_i, c_j)\]</div>
</li>
<li><p>Now, we recognize that <span class="math notranslate nohighlight">\(\frac{A_{ij}}{2m}\)</span> can be rewritten as:</p>
<div class="math notranslate nohighlight">
\[\frac{A_{ij}}{2m} = \frac{d_i}{2m} \cdot \frac{A_{ij}}{d_i} = \pi_i P_{ij}\]</div>
</li>
<li><p>We also recognize that <span class="math notranslate nohighlight">\(\frac{d_i}{2m}\)</span> is the stationary distribution of the random walk, which we denote as <span class="math notranslate nohighlight">\(\pi_i\)</span>:</p>
<div class="math notranslate nohighlight">
\[\frac{d_i}{2m} = \pi_i\]</div>
</li>
<li><p>Substituting these into our equation:</p>
<div class="math notranslate nohighlight">
\[Q = \sum_{ij} \left(\pi_i P_{ij} - \pi_i \pi_j \right) \delta(c_i, c_j)\]</div>
</li>
</ol>
</div>
<p>The expression suggests that:</p>
<ol class="arabic simple">
<li><p>The first term, <span class="math notranslate nohighlight">\(\pi_i P_{ij} \delta(c_i, c_j)\)</span>, represents the probability that a walker is at node <span class="math notranslate nohighlight">\(i\)</span> and moves to node <span class="math notranslate nohighlight">\(j\)</span> within the same community <strong>by one step</strong>.</p></li>
<li><p>The second term, <span class="math notranslate nohighlight">\(\pi_i \pi_j\)</span>, represents the probability that a walker is at node <span class="math notranslate nohighlight">\(i\)</span> and moves to another node <span class="math notranslate nohighlight">\(j\)</span> within the same community <strong>after long steps</strong>.</p></li>
</ol>
<p>In summary, modularity compares short-term and long-term random walk probabilities. High modularity indicates that a random walker is more likely to stay within the same community after one step than after many steps.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Building on this perspective from random walks, Delvenne et al. <a class="footnote-reference brackets" href="#footcite-delvenne2010stability" id="id120" role="doc-noteref"><span class="fn-bracket">[</span>31<span class="fn-bracket">]</span></a> extends the modularity by comparing multi-step and long-step transition probabilities of a random walk. This approach, known as “Markov stability”, shows that the number of steps acts as a “resolution parameter” that determines the scale of detectable communities.</p>
</div>
</section>
<section id="pagerank-interpretation-from-random-walk-perspective">
<h2>PageRank: Interpretation from random walk perspective<a class="headerlink" href="#pagerank-interpretation-from-random-walk-perspective" title="Link to this heading">#</a></h2>
<p>PageRank can be interpreted from a random walk perspective:</p>
<div class="math notranslate nohighlight">
\[
c_i = (1-\beta) \sum_j P_{ji} c_j + \beta \cdot \frac{1}{N}
\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(c_i\)</span> is the PageRank of node <span class="math notranslate nohighlight">\(i\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P_{ji}\)</span> is the transition probability from node <span class="math notranslate nohighlight">\(j\)</span> to node <span class="math notranslate nohighlight">\(i\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\beta\)</span> is the teleportation probability</p></li>
<li><p><span class="math notranslate nohighlight">\(N\)</span> is the total number of nodes</p></li>
</ul>
<p>This equation represents a random walk where:</p>
<ol class="arabic simple">
<li><p>With probability <span class="math notranslate nohighlight">\((1-\beta)\)</span>, the walker follows a link to the next node.</p></li>
<li><p>With probability <span class="math notranslate nohighlight">\(\beta\)</span>, the walker <em>teleports</em> to a random node in the network.</p></li>
</ol>
<p>The PageRank <span class="math notranslate nohighlight">\(c_i\)</span> is the stationary distribution of this random walk, representing the long-term probability of finding the walker at node <span class="math notranslate nohighlight">\(i\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This sounds odd at first glance. But it makes sense when you think about what PageRank was invented for, i.e., Web search. It characterizes a web surfer as a random walker that chooses the next page by randomly jumping to a random page with probability <span class="math notranslate nohighlight">\(\beta\)</span> or by following a link to a page with probability <span class="math notranslate nohighlight">\(1-\beta\)</span>. The web page with the largest PageRank means that the page is most likely to be visited by this random web surfer.</p>
</div>
<div class="docutils container" id="id121">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-delvenne2010stability" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id120">31</a><span class="fn-bracket">]</span></span>
<p>J-C Delvenne, Sophia N Yaliraki, and Mauricio Barahona. Stability of graph communities across time scales. <em>Proceedings of the national academy of sciences</em>, 107(29):12755–12760, 2010.</p>
</aside>
</aside>
</div>
<section id="step-2-generate-random-walks">
<h3>Step 2: Generate random walks<a class="headerlink" href="#step-2-generate-random-walks" title="Link to this heading">#</a></h3>
<p>Next, we generate the training data for the word2vec model by generating multiple random walks starting from each node in the network.
Let us first implement a function to sample random walks from a given network.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">random_walk</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">start_node</span><span class="p">,</span> <span class="n">walk_length</span><span class="p">):</span>
    <span class="c1"># Initialize the walk with the starting node</span>
    <span class="n">walk</span> <span class="o">=</span> <span class="p">[</span><span class="n">start_node</span><span class="p">]</span>

    <span class="c1"># Continue the walk until the desired length is reached</span>
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">walk</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">walk_length</span><span class="p">:</span>
        <span class="c1"># Get the current node (the last node in the walk)</span>
        <span class="n">cur</span> <span class="o">=</span> <span class="n">walk</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Get the neighbors of the current node</span>
        <span class="n">cur_nbrs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="n">cur</span><span class="p">]</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>

        <span class="c1"># If the current node has neighbors, randomly choose one and add it to the walk</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cur_nbrs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">walk</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">cur_nbrs</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If the current node has no neighbors, terminate the walk</span>
            <span class="k">break</span>

    <span class="c1"># Return the generated walk</span>
    <span class="k">return</span> <span class="n">walk</span>
</pre></div>
</div>
</div>
</div>
<p>Generate 10 random walks of length 50 starting from each node.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">()</span>
<span class="n">n_walkers_per_node</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">walk_length</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">walks</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_walkers_per_node</span><span class="p">):</span>
        <span class="n">walks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random_walk</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">walk_length</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-3-train-the-word2vec-model">
<h3>Step 3: Train the word2vec model<a class="headerlink" href="#step-3-train-the-word2vec-model" title="Link to this heading">#</a></h3>
<p>Then, we feed the random walks to the word2vec model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">walks</span><span class="p">,</span> <span class="n">vector_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sg</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hs</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">vector_size</span></code> is the dimension of the embedding vectors.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">window</span></code> indicates the maximum distance between a word and its context words. For example, in the random walk <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">4,</span> <span class="pre">5,</span> <span class="pre">6,</span> <span class="pre">7]</span></code>, the context words of node 2 are <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">3,</span> <span class="pre">4,</span> <span class="pre">5]</span></code> when <code class="docutils literal notranslate"><span class="pre">window=3</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_count</span></code> is the minimum number of times a word must appear in the training data to be included in the vocabulary.</p></li>
</ul>
<p>Two parameters <code class="docutils literal notranslate"><span class="pre">sg=1</span></code> and <code class="docutils literal notranslate"><span class="pre">hs=1</span></code> indicate that we are using the skip-gram model with negative sampling. Let us understand what they mean in detail as follows.</p>
<ul>
<li><p><strong>Skip-gram model</strong>: it trains word2vec by predicting context words given a target word. For example, given the sentence “The quick brown fox jumps over the lazy dog”, in the skip-gram model, given the target word “fox”, the model will try to predict the context words “quick”, “brown”, “jumps”, and “over”. If <code class="docutils literal notranslate"><span class="pre">sg=0</span></code>, the input and output are swapped: the model will predict the target word from the context words, e.g., given the context words “quick”, “brown”, “jumps”, and “over”, the model will predict the target word “fox”.</p></li>
<li><p><strong>Hierarchical softmax</strong>: To understand hierarchical softmax better, let’s break down how the word2vec model works. The goal of word2vec is to predict context words given a target word. For example, if our target word is <span class="math notranslate nohighlight">\(w_t\)</span> and our context word is <span class="math notranslate nohighlight">\(w_c\)</span>, we want to find the probability of <span class="math notranslate nohighlight">\(w_c\)</span> given <span class="math notranslate nohighlight">\(w_t\)</span>. This probability is calculated using the softmax function:</p>
<div class="math notranslate nohighlight">
\[
    P(w_c | w_t) = \frac{\exp(\mathbf{v}_{w_c} \cdot \mathbf{v}_{w_t})}{\sum_{w \in V} \exp(\mathbf{v}_w \cdot \mathbf{u}_{w_t})}
   \]</div>
<p>Here, <span class="math notranslate nohighlight">\(\mathbf{v}_w\)</span> and <span class="math notranslate nohighlight">\(\mathbf{u}_w\)</span> represent the vector for word <span class="math notranslate nohighlight">\(w\)</span> as context and target respectively, and <span class="math notranslate nohighlight">\(V\)</span> is the entire vocabulary. The tricky part is the denominator, which requires summing over all words in the vocabulary. If we have a large vocabulary, this can be very computationally expensive. Imagine having to compute 100,000 exponentials and their sum for each training example if our vocabulary size is 100,000!</p>
<p>Hierarchical softmax helps us solve this problem. Instead of calculating the probability directly, it organizes the vocabulary into a binary tree, where each word is a leaf node. To find the probability of a word, we calculate the product of probabilities along the path from the root to the leaf node. This method significantly reduces the computational complexity. Instead of being proportional to the vocabulary size, it becomes proportional to the logarithm of the vocabulary size. This makes it much more efficient, especially for large vocabularies.</p>
<p><img alt="" src="https://lh5.googleusercontent.com/proxy/_omrC8G6quTl2SGarwFe57qzbIs-PtGkEA5yODFE5I0Ny2IHGiJwsUhMrcuUqg5o-R2nD9hkgMuZsQJKoCggP29zXtj-Vz-X8BE" /></p>
</li>
</ul>
<p>By using the skip-gram model with hierarchical softmax, we can efficiently learn high-quality word embeddings even when dealing with large vocabularies.</p>
<p>Now, we extract the node embeddings from the word2vec model. In the word2vec model, the embeddings are stored in the <code class="docutils literal notranslate"><span class="pre">wv</span></code> attribute. The embedding of node <span class="math notranslate nohighlight">\(i\)</span> is given by <code class="docutils literal notranslate"><span class="pre">model.wv[i]</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedding</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>
    <span class="n">embedding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">embedding</span></code> is the matrix of node embeddings. It has the same number of rows as the number of nodes in the network, and the number of columns is the embedding dimension.</p>
<p><strong>Print the first 3 nodes</strong></p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedding</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Let’s visualize the node embeddings using UMAP.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">umap</span>
<span class="kn">from</span> <span class="nn">bokeh.plotting</span> <span class="kn">import</span> <span class="n">figure</span><span class="p">,</span> <span class="n">show</span>
<span class="kn">from</span> <span class="nn">bokeh.io</span> <span class="kn">import</span> <span class="n">output_notebook</span>
<span class="kn">from</span> <span class="nn">bokeh.models</span> <span class="kn">import</span> <span class="n">ColumnDataSource</span><span class="p">,</span> <span class="n">HoverTool</span>


<span class="n">reducer</span> <span class="o">=</span> <span class="n">umap</span><span class="o">.</span><span class="n">UMAP</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">)</span>
<span class="n">xy</span> <span class="o">=</span> <span class="n">reducer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

<span class="n">output_notebook</span><span class="p">()</span>

<span class="c1"># Calculate the degree of each node</span>
<span class="n">degrees</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">A1</span>

<span class="n">source</span> <span class="o">=</span> <span class="n">ColumnDataSource</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">size</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">degrees</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">degrees</span><span class="p">))</span> <span class="o">*</span> <span class="mi">30</span><span class="p">,</span>
    <span class="n">community</span><span class="o">=</span><span class="p">[</span><span class="n">palette</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">vs</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]]</span>
<span class="p">))</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">figure</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Node Embeddings from Word2Vec&quot;</span><span class="p">,</span> <span class="n">x_axis_label</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">y_axis_label</span><span class="o">=</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>

<span class="n">p</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span> <span class="n">line_color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;community&quot;</span><span class="p">)</span>

<span class="n">show</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="step-4-clustering">
<h3>Step 4: Clustering<a class="headerlink" href="#step-4-clustering" title="Link to this heading">#</a></h3>
<p>One of the interesting applications with node embeddings is clustering. While we have good community detection methods, like the modularity maximization and stochastic block model, we can use clustering methods from machine learning, such as <span class="math notranslate nohighlight">\(K\)</span>-means and Gaussian mixture model. Let’s see what we can get from the node embeddings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>

<span class="c1"># Determine the optimal number of clusters using the silhouette score</span>
<span class="k">def</span> <span class="nf">Kmeans_with_silhouette</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">n_clusters_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)):</span>
    <span class="n">silhouette_scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Iterate over a range of cluster numbers from 2 to 9</span>
    <span class="k">for</span> <span class="n">n_clusters</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">*</span><span class="n">n_clusters_range</span><span class="p">):</span>
        <span class="c1"># Create a KMeans object with the current number of clusters</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">)</span>

        <span class="c1"># Fit the KMeans model to the embedding data</span>
        <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

        <span class="c1"># Calculate the silhouette score for the current clustering</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>

        <span class="c1"># Append the number of clusters and its corresponding silhouette score to the list</span>
        <span class="n">silhouette_scores</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>

    <span class="c1"># Find the number of clusters that has the highest silhouette score</span>
    <span class="n">optimal_n_clusters</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">silhouette_scores</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Create a KMeans object with the optimal number of clusters</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">optimal_n_clusters</span><span class="p">)</span>

    <span class="c1"># Fit the KMeans model to the embedding data with the optimal number of clusters</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

    <span class="c1"># Return the labels (cluster assignments) for each data point</span>
    <span class="k">return</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">Kmeans_with_silhouette</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()</span><span class="o">.</span><span class="n">as_hex</span><span class="p">()</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">cmap</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">],</span> <span class="n">bbox</span><span class="o">=</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="node2vec">
<h2>node2vec<a class="headerlink" href="#node2vec" title="Link to this heading">#</a></h2>
<p>node2vec is a sibling of DeepWalk proposed by <a class="footnote-reference brackets" href="#footcite-grover2016node2vec" id="id122" role="doc-noteref"><span class="fn-bracket">[</span>32<span class="fn-bracket">]</span></a>. Both use word2vec trained on random walks on networks. So, it appears that they are very similar. However, the following two components make them very different.</p>
<ul>
<li><p><strong>Biased random walk</strong>: node2vec uses biased random walks that can move in different directions. The bias walk is parameterized by two parameters, <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(q\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    P(v_{t+1} = x | v_t = v, v_{t-1} = t) \propto
    \begin{cases}
    \frac{1}{p} &amp; \text{if } d(v,t) = 0 \\
    1 &amp; \text{if } d(v,t) = 1 \\
    \frac{1}{q} &amp; \text{if } d(v,t) = 2 \\
    \end{cases}
    \end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(d(v,x)\)</span> is the shortest path distance between node <span class="math notranslate nohighlight">\(v\)</span> and <span class="math notranslate nohighlight">\(x\)</span>. A smaller <span class="math notranslate nohighlight">\(p\)</span> leads to more biased towards the previous node, <span class="math notranslate nohighlight">\(v_{t-1} = t\)</span>. A smaller <span class="math notranslate nohighlight">\(q\)</span> leads to more biased towards the nodes that are further away from the previous node, <span class="math notranslate nohighlight">\(v_{t-1} = t\)</span>.</p>
<p>By adjusting the parameters <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(q\)</span>, we can influence the random walk to behave more like either breadth-first sampling (BFS) or depth-first sampling (DFS).</p>
<ul class="simple">
<li><p><strong>Breadth-First Sampling (BFS)</strong>: This type of sampling explores all the neighbors of a node before moving on to the next level of neighbors. It is useful for capturing community structures within the graph. When we set the parameters to favor BFS, the resulting embeddings will reflect these community structures.</p></li>
<li><p><strong>Depth-First Sampling (DFS)</strong>: This type of sampling goes deep into the graph, exploring as far as possible along each branch before backtracking. It is useful for capturing structural equivalence, where nodes that have similar roles in the graph (even if they are not directly connected) are represented similarly. When we set the parameters to favor DFS, the resulting embeddings will reflect these structural equivalences.</p></li>
</ul>
<p><img alt="" src="https://www.researchgate.net/publication/354654762/figure/fig3/AS:1069013035655173&#64;1631883977008/A-biased-random-walk-procedure-of-node2vec-B-BFS-and-DFS-search-strategies-from-node-u.png" /></p>
<p>The embeddings generated by node2vec can capture different aspects of the graph depending on the sampling strategy used. With BFS, we capture community structures, and with DFS, we capture structural equivalence.</p>
<p><img alt="" src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*nCyF5jFSU5uJVdAPdf-0HA.png" /></p>
</li>
<li><p><strong>Negative sampling</strong>: node2vec uses negative sampling, instead of hierarchical softmax. This difference appears to be minor, but it has significant consequences on the characteristics of the embeddings. This is beyond the scope of this lecture, but you can refer to <a class="footnote-reference brackets" href="#footcite-kojaku2021neurips" id="id123" role="doc-noteref"><span class="fn-bracket">[</span>33<span class="fn-bracket">]</span></a> and <a class="footnote-reference brackets" href="#footcite-dyer2014notes" id="id124" role="doc-noteref"><span class="fn-bracket">[</span>34<span class="fn-bracket">]</span></a> for more details.</p></li>
</ul>
<section id="exercise-02-implement-node2vec">
<h3>Exercise 02: Implement node2vec<a class="headerlink" href="#exercise-02-implement-node2vec" title="Link to this heading">#</a></h3>
<p>Let’s implement the biased random walk for node2vec</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">node2vec_random_walk</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">start_node</span><span class="p">,</span> <span class="n">walk_length</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample a random walk starting from start_node.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Initialize the walk with the start_node</span>
    <span class="n">walk</span> <span class="o">=</span> <span class="p">[</span><span class="n">start_node</span><span class="p">]</span>

    <span class="c1"># Continue the walk until it reaches the desired length</span>
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">walk</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">walk_length</span><span class="p">:</span>
        <span class="c1"># Get the current node in the walk</span>
        <span class="n">cur</span> <span class="o">=</span> <span class="n">walk</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Get the neighbors of the current node</span>
        <span class="n">cur_nbrs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="n">cur</span><span class="p">]</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
        <span class="c1"># Check if the current node has any neighbors</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cur_nbrs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># If the walk has just started, randomly choose the next node from the neighbors</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">walk</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">walk</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">cur_nbrs</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Get the previous node in the walk</span>
                <span class="n">prev</span> <span class="o">=</span> <span class="n">walk</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
                <span class="c1"># Use the alias sampling method to choose the next node based on the bias parameters p and q</span>
                <span class="n">next_node</span> <span class="o">=</span> <span class="n">alias_sample</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">cur_nbrs</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
                <span class="c1"># Append the chosen next node to the walk</span>
                <span class="n">walk</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_node</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If the current node has no neighbors, terminate the walk</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">walk</span>

<span class="k">def</span> <span class="nf">alias_sample</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">neighbors</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to sample the next node in the walk.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Implement the logic to sample the next node based on the bias parameters p and q</span>
    <span class="c1"># You can use the formula provided in the instructions to calculate the probabilities</span>
    <span class="c1"># and then sample the next node accordingly.</span>
    <span class="c1"># Initialize an empty list to store the unnormalized probabilities for each neighbor</span>
    <span class="n">unnormalized_probs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Iterate over each neighbor of the current node</span>
    <span class="k">for</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">:</span>
        <span class="c1"># If the neighbor is the same as the previous node in the walk</span>
        <span class="k">if</span> <span class="n">neighbor</span> <span class="o">==</span> <span class="n">prev</span><span class="p">:</span>
            <span class="c1"># Append the probability 1/p to the unnormalized probabilities list</span>
            <span class="n">unnormalized_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">p</span><span class="p">)</span>
        <span class="c1"># If the neighbor is connected to the previous node in the walk</span>
        <span class="k">elif</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="n">net</span><span class="p">[</span><span class="n">prev</span><span class="p">]</span><span class="o">.</span><span class="n">indices</span><span class="p">:</span>
            <span class="c1"># Append the probability 1 to the unnormalized probabilities list</span>
            <span class="n">unnormalized_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># If the neighbor is not connected to the previous node in the walk</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Append the probability 1/q to the unnormalized probabilities list</span>
            <span class="n">unnormalized_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">q</span><span class="p">)</span>

    <span class="c1"># Calculate the normalization constant by summing all unnormalized probabilities</span>
    <span class="n">norm_const</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">unnormalized_probs</span><span class="p">)</span>

    <span class="c1"># Normalize the probabilities by dividing each unnormalized probability by the normalization constant</span>
    <span class="n">normalized_probs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span> <span class="o">/</span> <span class="n">norm_const</span> <span class="k">for</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">unnormalized_probs</span><span class="p">]</span>

    <span class="c1"># Randomly choose the next node from the neighbors based on the normalized probabilities</span>
    <span class="n">next_node</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">normalized_probs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Return the chosen next node</span>
    <span class="k">return</span> <span class="n">next_node</span>
</pre></div>
</div>
</div>
</div>
<p>Now, let’s set up the word2vec model for node2vec.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">walks</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">q</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_walkers_per_node</span><span class="p">):</span>
        <span class="n">walks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node2vec_random_walk</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">walk_length</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">))</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">walks</span><span class="p">,</span> <span class="n">vector_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sg</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hs</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">hs=0</span></code> indicates that we are using negative sampling.
Notice that we set <code class="docutils literal notranslate"><span class="pre">sg=1</span></code> and <code class="docutils literal notranslate"><span class="pre">hs=1</span></code> instead of <code class="docutils literal notranslate"><span class="pre">sg=1</span></code> and <code class="docutils literal notranslate"><span class="pre">hs=0</span></code> in DeepWalk. This is because node2vec uses the skip-gram model with negative sampling.</p>
<p>Now, we extract the node embeddings from the word2vec model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedding</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>
    <span class="n">embedding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s visualize the node embeddings from node2vec.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reducer</span> <span class="o">=</span> <span class="n">umap</span><span class="o">.</span><span class="n">UMAP</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">)</span>
<span class="n">xy</span> <span class="o">=</span> <span class="n">reducer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

<span class="n">output_notebook</span><span class="p">()</span>

<span class="c1"># Calculate the degree of each node</span>
<span class="n">degrees</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">A1</span>

<span class="n">source</span> <span class="o">=</span> <span class="n">ColumnDataSource</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">size</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">degrees</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">degrees</span><span class="p">))</span> <span class="o">*</span> <span class="mi">30</span><span class="p">,</span>
    <span class="n">community</span><span class="o">=</span><span class="p">[</span><span class="n">palette</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">vs</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]],</span>
    <span class="n">name</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">)]</span>
<span class="p">))</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">figure</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Node Embeddings from Word2Vec&quot;</span><span class="p">,</span> <span class="n">x_axis_label</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">y_axis_label</span><span class="o">=</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>

<span class="n">p</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span> <span class="n">line_color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;community&quot;</span><span class="p">)</span>

<span class="n">hover</span> <span class="o">=</span> <span class="n">HoverTool</span><span class="p">()</span>
<span class="n">hover</span><span class="o">.</span><span class="n">tooltips</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;Name&quot;</span><span class="p">,</span> <span class="s2">&quot;@name&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Community&quot;</span><span class="p">,</span> <span class="s2">&quot;@community&quot;</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">p</span><span class="o">.</span><span class="n">add_tools</span><span class="p">(</span><span class="n">hover</span><span class="p">)</span>

<span class="n">show</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>The results for clustering are as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">labels</span> <span class="o">=</span> <span class="n">Kmeans_with_silhouette</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>


<span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()</span><span class="o">.</span><span class="n">as_hex</span><span class="p">()</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">cmap</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">],</span> <span class="n">bbox</span><span class="o">=</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span> <span class="n">vertex_label</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span>  <span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span>  <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">)])</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="line">
<h2>LINE<a class="headerlink" href="#line" title="Link to this heading">#</a></h2>
<p>LINE <a class="footnote-reference brackets" href="#footcite-tang2015line" id="id125" role="doc-noteref"><span class="fn-bracket">[</span>35<span class="fn-bracket">]</span></a> is another pioneering work to learn node embeddings by directly optimizing the graph structure.
It is equivalent to node2vec with <span class="math notranslate nohighlight">\(p=1\)</span>, <span class="math notranslate nohighlight">\(q=1\)</span>, and window size 1.</p>
<div class="docutils container" id="id126">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-grover2016node2vec" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id122">32</a><span class="fn-bracket">]</span></span>
<p>Aditya Grover and Jure Leskovec. Node2vec: scalable feature learning for networks. In <em>Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</em>, 855–864. 2016.</p>
</aside>
<aside class="footnote brackets" id="footcite-kojaku2021neurips" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id123">33</a><span class="fn-bracket">]</span></span>
<p>Sadamori Kojaku, Jisung Yoon, Isabel Constantino, and Yong-Yeol Ahn. Residual2vec: debiasing graph embedding using random graphs. In <em>Advances in Neural Information Processing Systems</em>, volume. Curran Associates, Inc., 2021.</p>
</aside>
<aside class="footnote brackets" id="footcite-dyer2014notes" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id124">34</a><span class="fn-bracket">]</span></span>
<p>Chris Dyer. Notes on noise contrastive estimation and negative sampling. <em>arXiv preprint arXiv:1410.8251</em>, 2014.</p>
</aside>
<aside class="footnote brackets" id="footcite-tang2015line" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id125">35</a><span class="fn-bracket">]</span></span>
<p>Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. Line: large-scale information network embedding. In <em>Proceedings of the 24th International Conference on World Wide Web</em>, WWW ‘15, 1067–1077. Republic and Canton of Geneva, CHE, 2015. International World Wide Web Conferences Steering Committee. URL: <a class="reference external" href="https://doi.org/10.1145/2736277.2741093">https://doi.org/10.1145/2736277.2741093</a>, <a class="reference external" href="https://doi.org/10.1145/2736277.2741093">doi:10.1145/2736277.2741093</a>.</p>
</aside>
</aside>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute the spectral decomposition</span>
<span class="n">eigvals</span><span class="p">,</span> <span class="n">eigvecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="c1"># Find the top d eigenvectors</span>
<span class="n">d</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">eigvals</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">d</span><span class="p">]</span>
<span class="n">eigvals</span> <span class="o">=</span> <span class="n">eigvals</span><span class="p">[</span><span class="n">sorted_indices</span><span class="p">]</span>
<span class="n">eigvecs</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="n">sorted_indices</span><span class="p">]</span>

<span class="c1"># Plot the results</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Spectral Embedding&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Eigenvector 1&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Eigenvector 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Interestingly, the first eigenvector corresponds to the eigen centrality of the network, representing the centrality of the nodes.
The second eigenvector captures the community structure of the network, clearly separating the two communities in the network.</p>
</section>
<section id="modularity-embedding">
<h2>Modularity embedding<a class="headerlink" href="#modularity-embedding" title="Link to this heading">#</a></h2>
<p>In a similar vein, we can use the modularity matrix to generate a low-dimensional embedding of the network.
Namely, let us define the modularity matrix <span class="math notranslate nohighlight">\(\mathbf{Q}\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[
Q_{ij} = \frac{1}{2m}A_{ij} - \frac{k_i k_j}{4m^2}
\]</div>
<p>where <span class="math notranslate nohighlight">\(k_i\)</span> is the degree of node <span class="math notranslate nohighlight">\(i\)</span>, and <span class="math notranslate nohighlight">\(m\)</span> is the number of edges in the network.</p>
<p>We then compute the eigenvectors of <span class="math notranslate nohighlight">\(\mathbf{Q}\)</span> and use them to embed the network into a low-dimensional space just as we did for the adjacency matrix.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">deg</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">A</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">deg</span><span class="p">,</span> <span class="n">deg</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span>
<span class="n">Q</span><span class="o">/=</span> <span class="mi">2</span><span class="o">*</span><span class="n">m</span>

<span class="n">eigvals</span><span class="p">,</span> <span class="n">eigvecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>

<span class="c1"># Sort the eigenvalues and eigenvectors</span>
<span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">eigvals</span><span class="p">)[:</span><span class="n">d</span><span class="p">]</span>  <span class="c1"># Exclude the first eigenvector</span>
<span class="n">eigvals</span> <span class="o">=</span> <span class="n">eigvals</span><span class="p">[</span><span class="n">sorted_indices</span><span class="p">]</span>
<span class="n">eigvecs</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="n">sorted_indices</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Modularity Embedding&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Eigenvector 1&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Eigenvector 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The modularity embedding can be used to bipartition the network into two communities using a simple algorithm: group nodes with the same sign of the second eigenvector <a class="footnote-reference brackets" href="#footcite-newman2006modularity" id="id127" role="doc-noteref"><span class="fn-bracket">[</span>36<span class="fn-bracket">]</span></a>.</p>
</div>
</section>
<section id="laplacian-eigenmap">
<h2>Laplacian Eigenmap<a class="headerlink" href="#laplacian-eigenmap" title="Link to this heading">#</a></h2>
<p>Laplacian Eigenmap <a class="footnote-reference brackets" href="#footcite-belkin2003laplacian" id="id128" role="doc-noteref"><span class="fn-bracket">[</span>37<span class="fn-bracket">]</span></a> is another approach to compress a network into a low-dimensional space. The fundamental idea behind this method is to position connected nodes close to each other in the low-dimensional space. This approach leads to the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[
\min_{\mathbf{U}} J_{LE}(\mathbf{U}),\quad J_{LE}(\mathbf{U}) = \frac{1}{2}\sum_{i,j} A_{ij} \| u_i - u_j \|^2
\]</div>
<p>In this equation, <span class="math notranslate nohighlight">\(\| u_i - u_j \|^2\)</span> represents the squared distance between nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> in the low-dimensional space. The goal is to minimize this distance for connected nodes (where <span class="math notranslate nohighlight">\(A_{ij} = 1\)</span>). The factor <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span> is included for mathematical convenience in later calculations.</p>
<p>To solve this optimization problem, we rewrite <span class="math notranslate nohighlight">\(J_{LE}(\mathbf{U})\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
J_{LE}(\mathbf{U}) &amp;= \frac{1}{2}\sum_{i}\sum_{j} A_{ij} \| u_i - u_j \|^2 \\
&amp;= \frac{1}{2}\sum_{i}\sum_{j} A_{ij} \left( \| u_i \|^2 - 2 u_i^\top u_j + \| u_j \|^2 \right) \\
&amp;= \sum_{i}\sum_{j} A_{ij} \| u_i \|^2 - \sum_{i}\sum_{j} A_{ij} u_i^\top u_j\\
&amp;= \sum_{i} k_i \| u_i \|^2 - \sum_{i,j} A_{ij} u_i^\top u_j\\
&amp;= \sum_{i,j} L_{ij} u_i^\top u_j
\end{aligned}
\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
L_{ij} = \begin{cases}
k_i &amp; \text{if } i = j \\
-A_{ij} &amp; \text{if } i \neq j
\end{cases}
\end{split}\]</div>
<p>Let us go through the derivation step by step.</p>
<ol class="arabic simple">
<li><p>In the first step (i.e., the second line), we expand the squared norm using the vector identity <span class="math notranslate nohighlight">\(\|a-b\|^2 = \|a\|^2 - 2a^\top b + \|b\|^2\)</span>.</p></li>
<li><p>In the second step (i.e., the third line), we distribute the sum and the factor <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span>.
The middle term gets a factor of 1 because it appears twice in the expansion (once for <span class="math notranslate nohighlight">\(i,j\)</span> and once for <span class="math notranslate nohighlight">\(j,i\)</span>), canceling out the <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span>. Note that the term <span class="math notranslate nohighlight">\(A_{ij}\)</span> is symmetric, i.e., <span class="math notranslate nohighlight">\(A_{ij} = A_{ji}\)</span>.</p></li>
<li><p>In the third step (i.e., the fourth line), we recognize that <span class="math notranslate nohighlight">\(\sum_j A_{ij}\)</span> is the degree of node <span class="math notranslate nohighlight">\(i\)</span>, which we denote as <span class="math notranslate nohighlight">\(k_i\)</span>.</p></li>
<li><p>Finally, we combine the terms by using the Laplacian matrix <span class="math notranslate nohighlight">\(\mathbf{L}\)</span>.</p></li>
</ol>
<p>The minimization problem can be rewritten as:</p>
<div class="math notranslate nohighlight">
\[
J_{LE}(\mathbf{U}) = \text{Tr}(\mathbf{U}^\top \mathbf{L} \mathbf{U})
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{U} =
\begin{bmatrix}
\mathbf{u}_1 ^\top \\
\mathbf{u}_2 ^\top \\
\vdots \\
\mathbf{u}_N ^\top \\
\end{bmatrix}
\end{split}\]</div>
<p>See the <a class="reference internal" href="#./appendix.md"><span class="xref myst">Appendix section</span></a> for the detailed derivation.</p>
<p>By taking the derivative of <span class="math notranslate nohighlight">\(J_{LE}(\mathbf{U})\)</span> with respect to <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> and set it to zero, we obtain the following equation:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial J_{LE}}{\partial \mathbf{U}} = 0 \implies \mathbf{L} \mathbf{U} = \lambda \mathbf{U}
\]</div>
<p>The solution is the <span class="math notranslate nohighlight">\(d\)</span> eigenvectors associated with the <span class="math notranslate nohighlight">\(d\)</span> smallest eigenvalues of <span class="math notranslate nohighlight">\(\mathbf{L}\)</span>.</p>
<p>It is important to note that the eigenvector corresponding to the smallest eigenvalue (which is always zero for connected graphs) is trivial - it’s the all-one vector. Therefore, in practice, we typically compute the <span class="math notranslate nohighlight">\(d+1\)</span> smallest eigenvectors and discard the one corresponding to the zero eigenvalue.</p>
<section id="an-example-for-the-laplacian-eigenmap">
<h3>An example for the Laplacian Eigenmap<a class="headerlink" href="#an-example-for-the-laplacian-eigenmap" title="Link to this heading">#</a></h3>
<p>Let us first compute the Laplacian matrix and its eigenvectors.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">D</span> <span class="o">-</span> <span class="n">A</span>

<span class="n">eigvals</span><span class="p">,</span> <span class="n">eigvecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>

<span class="c1"># Sort the eigenvalues and eigenvectors</span>
<span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">eigvals</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Exclude the first eigenvector</span>
<span class="n">eigvals</span> <span class="o">=</span> <span class="n">eigvals</span><span class="p">[</span><span class="n">sorted_indices</span><span class="p">]</span>
<span class="n">eigvecs</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="n">sorted_indices</span><span class="p">]</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>The eigenvectors corresponding to the <span class="math notranslate nohighlight">\(d\)</span> smallest eigenvalues are:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Laplacian Eigenmap&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Eigenvector 2&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Eigenvector 3&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="docutils container" id="id129">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-newman2006modularity" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id127">36</a><span class="fn-bracket">]</span></span>
<p>M. E. J. Newman. Modularity and community structure in networks. <em>Proceedings of the National Academy of Sciences</em>, 103(23):8577–8582, 2006. URL: <a class="reference external" href="https://www.pnas.org/doi/abs/10.1073/pnas.0601602103">https://www.pnas.org/doi/abs/10.1073/pnas.0601602103</a>, <a class="reference external" href="https://arxiv.org/abs/https://www.pnas.org/doi/pdf/10.1073/pnas.0601602103">arXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.0601602103</a>, <a class="reference external" href="https://doi.org/10.1073/pnas.0601602103">doi:10.1073/pnas.0601602103</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-belkin2003laplacian" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id128">37</a><span class="fn-bracket">]</span></span>
<p>Mikhail Belkin and Partha Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. <em>Neural Computation</em>, 15(6):1373–1396, 2003. <a class="reference external" href="https://doi.org/10.1162/089976603321780317">doi:10.1162/089976603321780317</a>.</p>
</aside>
</aside>
</div>
</section>
</section>
<hr class="docutils" />
<section id="id130">
<h2>jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3<a class="headerlink" href="#id130" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="spectral-vs-neural-embedding">
<h1>Spectral vs Neural Embedding<a class="headerlink" href="#spectral-vs-neural-embedding" title="Link to this heading">#</a></h1>
<p>We have learned two types of graph embedding methods: spectral methods and neural embedding methods. But which one is better than the other? We will compare the two types of methods from multiple aspects as follows.</p>
<ol class="arabic">
<li><p><strong>Analytical Tractability</strong>: Spectral methods are more analytically tractable and thus are easier to understand using linear algebra. It is even possible to derive the capability and limitation of the spectral methods. For example, spectral methods based on adjacency matrices and normalized laplacian matrices are shown to be optimal for detecting communities in the stochastic block model <a class="footnote-reference brackets" href="#footcite-nadakuditi2012graph" id="id131" role="doc-noteref"><span class="fn-bracket">[</span>17<span class="fn-bracket">]</span></a>. Neural embedding methods are less analytically tractable. But still possible to analyze the theoretical properties by using an equivalence between a spectral embedding and a neural embedding under a very specific condition <a class="footnote-reference brackets" href="#footcite-qiu2018network" id="id132" role="doc-noteref"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-kojaku2023network" id="id133" role="doc-noteref"><span class="fn-bracket">[</span>39<span class="fn-bracket">]</span></a>. These theoretical results have demonstrated that DeepWalk, node2vec, and LINE are in fact an optimal embedding methods for community detection for the stochatic block model.</p></li>
<li><p><strong>Scalability</strong>: A key limitation of the spectral embedding is the computational cost. While efficient methods exist like randomized singular value decomposition (implemented in scikit learn package as <code class="docutils literal notranslate"><span class="pre">TruncatedSVD</span></code>), they might be unstable depending on the spectrum distribution of the matrix to be decomposed. Neural embedding methods are often more stable and scalable.</p></li>
<li><p><strong>Flexibility</strong>: Neural embeddings are more flexible than spectral embeddings. It is easy to change the objective functions of neural embeddings using the same training procedure. For example, the proximity of nodes in both embedding spaces are inherently dot similarity, but one can train neural embeddings to optimize for other metrics to embed the network in a non-Euclidean space. An interesting example of this is the Poincaré embeddings <a class="footnote-reference brackets" href="#footcite-nickel2017poincare" id="id134" role="doc-noteref"><span class="fn-bracket">[</span>40<span class="fn-bracket">]</span></a> for embedding networks in hyperbolic space.</p>
<p><img alt="" src="https://pbs.twimg.com/media/DUUj0sxU8AACV50.jpg" /></p>
</li>
</ol>
<div class="docutils container" id="id135">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-qiu2018network" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id132">38</a><span class="fn-bracket">]</span></span>
<p>Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, and Jie Tang. Network embedding as matrix factorization: unifying deepwalk, line, pte, and node2vec. In <em>Proceedings of the eleventh ACM international conference on web search and data mining</em>, 459–467. 2018.</p>
</aside>
<aside class="footnote brackets" id="footcite-kojaku2023network" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id133">39</a><span class="fn-bracket">]</span></span>
<p>Sadamori Kojaku, Filippo Radicchi, Yong-Yeol Ahn, and Santo Fortunato. Network community detection via neural embeddings. <em>arXiv preprint arXiv:2306.13400</em>, 2023.</p>
</aside>
<aside class="footnote brackets" id="footcite-nickel2017poincare" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id134">40</a><span class="fn-bracket">]</span></span>
<p>Maximillian Nickel and Douwe Kiela. Poincaré embeddings for learning hierarchical representations. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, <em>Advances in Neural Information Processing Systems</em>, volume 30. Curran Associates, Inc., 2017. URL: <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/59dfa2df42d9e3d41f5b02bfc32229dd-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2017/file/59dfa2df42d9e3d41f5b02bfc32229dd-Paper.pdf</a>.</p>
</aside>
</aside>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="module-8-embedding">
<h1>Module 8: Embedding<a class="headerlink" href="#module-8-embedding" title="Link to this heading">#</a></h1>
<section id="id136">
<h2>What to learn in this module<a class="headerlink" href="#id136" title="Link to this heading">#</a></h2>
<p>In this module, we will learn how to embed networks into low-dimensional spaces. We will learn:</p>
<ul class="simple">
<li><p>Spectral embedding</p></li>
<li><p>Neural embedding</p></li>
<li><p><strong>Keywords</strong>: Laplacian EigenMap, Normalized Spectral Embedding, DeepWalk, Node2Vec—
jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="word2vec">
<h1>word2vec<a class="headerlink" href="#word2vec" title="Link to this heading">#</a></h1>
<p>In this section, we will introduce <em>word2vec</em>, a powerful technique for learning word embeddings. word2vec is a neural network model that learns words embeddings in a continuous vector space. It was introduced by Tomas Mikolov and his colleagues at Google in 2013 <a class="footnote-reference brackets" href="#footcite-mikolov2013distributed" id="id137" role="doc-noteref"><span class="fn-bracket">[</span>41<span class="fn-bracket">]</span></a>.</p>
<section id="how-it-works">
<h2>How it works<a class="headerlink" href="#how-it-works" title="Link to this heading">#</a></h2>
<p>“You shall know a word by the company it keeps”  is a famous quote in linguistics. It means that you can understand the meaning of a word by looking at the words that appear in the same context.
word2vec operates on the same principle.
word2vec identifies a word’s context by examining the words within a fixed window around it. For example, in the sentence:</p>
<blockquote>
<div><p>The quick brown fox jumps over a lazy dog</p>
</div></blockquote>
<p>The context of the word <em>fox</em> includes <em>quick</em>, <em>brown</em>, <em>jumps</em>, <em>over</em>, and <em>lazy</em>. word2vec is trained to predict which words are likely to appear as the context of an input word.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There are two main architectures for word2vec:</p>
<ol class="arabic simple">
<li><p><strong>Continuous Bag of Words (CBOW)</strong>: Predicts the target word (center word) from the context words (surrounding words).</p></li>
<li><p><strong>Skip-gram</strong>: Predicts the context words (surrounding words) from the target word (center word).</p></li>
</ol>
</div>
<p>So how are word embeddings learned? word2vec is a neural network model that looks like a bow tie. It has two layers of the vocabulary size coupled with a much smaller hidden layer.</p>
<p><img alt="" src="../_images/word2vec.png" /></p>
<ul class="simple">
<li><p><strong>Input layer</strong>: The input layer consists of <span class="math notranslate nohighlight">\(N\)</span> neurons, where <span class="math notranslate nohighlight">\(N\)</span> is the size of the vocabulary (i.e., the number of unique words in the corpus). Each neuron corresponds to a unique word in the vocabulary. When a word is inputted, its corresponding neuron is activated and the other neurons are inhibited. Thus, the input layer is essentially a lookup mechanism that transforms the input word into a corresponding one-hot vector.</p></li>
<li><p><strong>Output layer</strong>: The output layer also consists of <span class="math notranslate nohighlight">\(N\)</span> neurons, each corresponding to a unique word in the vocabulary. Unlike the input layer, multiple neurons can be activated for a single input. The strength of the activation of each neuron (with a normalization by the softmax function) represents the probability of the corresponding word being the input word’s context.</p></li>
<li><p><strong>Hidden layer</strong>: The hidden layer is much smaller than the input and output layers. Multiple neurons in the hidden layer can be activated for a single input, and this activation pattern represents the word’s <em>embedding</em>.</p></li>
</ul>
<p>We can consider word2vec as a <em>dimensionality reduction</em> technique that reduces the dimensionality of the input layer to the hidden layer based on the co-occurrence of words within a short distance. The distance is named the <em>window size</em>, which is a user-defined hyperparameter.</p>
</section>
<section id="whats-special-about-word2vec">
<h2>What’s special about word2vec?<a class="headerlink" href="#whats-special-about-word2vec" title="Link to this heading">#</a></h2>
<p>With word2vec, words are represented as dense vectors, enabling us to explore their relationships using simple linear algebra. This is in contrast to traditional natural language processing (NLP) methods, such as bag-of-words and topic modeling, which represent words as discrete units or high-dimensional vectors.</p>
<p><img alt="" src="https://miro.medium.com/v2/resize:fit:678/1*5F4TXdFYwqi-BWTToQPIfg.jpeg" /></p>
<p>To showcase the effectiveness of word2vec, let’s walk through an example using the <code class="docutils literal notranslate"><span class="pre">gensim</span></code> library.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gensim</span>
<span class="kn">import</span> <span class="nn">gensim.downloader</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>

<span class="c1"># Load pre-trained word2vec model from Google News</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">downloader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;word2vec-google-news-300&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Our first example is to find the words most similar to <em>king</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Example usage</span>
<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;king&quot;</span>
<span class="n">similar_words</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Words most similar to &#39;</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2">&#39;:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">similar_word</span><span class="p">,</span> <span class="n">similarity</span> <span class="ow">in</span> <span class="n">similar_words</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">similar_word</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">similarity</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>A cool (yet controversial) application of word embeddings is analogy solving. Let us consider the following puzzle:</p>
<blockquote>
<div><p><em>man</em> is to <em>woman</em> as <em>king</em> is to ___ ?</p>
</div></blockquote>
<p>We can use word embeddings to solve this puzzle.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We solve the puzzle by</span>
<span class="c1">#</span>
<span class="c1">#  vec(king) - vec(man) + vec(woman)</span>
<span class="c1">#</span>
<span class="c1"># To solve this, we use the model.most_similar function, with positive words being &quot;king&quot; and &quot;woman&quot; (additive), and negative words being &quot;man&quot; (subtractive).</span>
<span class="c1">#</span>
<span class="n">model</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;woman&#39;</span><span class="p">,</span> <span class="s2">&quot;king&quot;</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;man&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The last example is to visualize the word embeddings.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="n">countries</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Germany&#39;</span><span class="p">,</span> <span class="s1">&#39;France&#39;</span><span class="p">,</span> <span class="s1">&#39;Italy&#39;</span><span class="p">,</span> <span class="s1">&#39;Spain&#39;</span><span class="p">,</span> <span class="s1">&#39;Portugal&#39;</span><span class="p">,</span> <span class="s1">&#39;Greece&#39;</span><span class="p">]</span>
<span class="n">capital_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Berlin&#39;</span><span class="p">,</span> <span class="s1">&#39;Paris&#39;</span><span class="p">,</span> <span class="s1">&#39;Rome&#39;</span><span class="p">,</span> <span class="s1">&#39;Madrid&#39;</span><span class="p">,</span> <span class="s1">&#39;Lisbon&#39;</span><span class="p">,</span> <span class="s1">&#39;Athens&#39;</span><span class="p">]</span>

<span class="c1"># Get the word embeddings for the countries and capitals</span>
<span class="n">country_embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">model</span><span class="p">[</span><span class="n">country</span><span class="p">]</span> <span class="k">for</span> <span class="n">country</span> <span class="ow">in</span> <span class="n">countries</span><span class="p">])</span>
<span class="n">capital_embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">model</span><span class="p">[</span><span class="n">capital</span><span class="p">]</span> <span class="k">for</span> <span class="n">capital</span> <span class="ow">in</span> <span class="n">capital_words</span><span class="p">])</span>

<span class="c1"># Compute the PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">country_embeddings</span><span class="p">,</span> <span class="n">capital_embeddings</span><span class="p">])</span>
<span class="n">embeddings_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

<span class="c1"># Create a DataFrame for seaborn</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">embeddings_pca</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;PC1&#39;</span><span class="p">,</span> <span class="s1">&#39;PC2&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">countries</span> <span class="o">+</span> <span class="n">capital_words</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Country&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">countries</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;Capital&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">capital_words</span><span class="p">)</span>

<span class="c1"># Plot the data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="c1"># Create a scatter plot with seaborn</span>
<span class="n">scatter_plot</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;PC1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;PC2&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;Type&#39;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">&#39;Type&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;deep&#39;</span><span class="p">,</span> <span class="n">markers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">])</span>

<span class="c1"># Annotate the points</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC1&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC2&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.08</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">,</span>
             <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">))</span>

<span class="c1"># Draw arrows between countries and capitals</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">countries</span><span class="p">)):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC1&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC2&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC1&#39;</span><span class="p">][</span><span class="n">i</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">countries</span><span class="p">)]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC1&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC2&#39;</span><span class="p">][</span><span class="n">i</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">countries</span><span class="p">)]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC2&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span>
              <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">head_width</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">head_length</span><span class="o">=</span><span class="mf">0.03</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Type&#39;</span><span class="p">,</span> <span class="n">title_fontsize</span><span class="o">=</span><span class="s1">&#39;13&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;11&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;PCA of Country and Capital Word Embeddings&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 2&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>We can see that word2vec places the words representing countries close to each other and so do the words representing their capitals. The country-capital relationship is also roughly preserved, e.g., <em>Germany</em>-<em>Berlin</em> vector is roughly parallel to <em>France</em>-<em>Paris</em> vector.</p>
<div class="docutils container" id="id138">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-mikolov2013distributed" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id137">41</a><span class="fn-bracket">]</span></span>
<p>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations of words and phrases and their compositionality. <em>Advances in neural information processing systems</em>, 2013.</p>
</aside>
</aside>
</div>
</section>
<hr class="docutils" />
<section id="id139">
<h2>jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3<a class="headerlink" href="#id139" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="appendix">
<h1>Appendix<a class="headerlink" href="#appendix" title="Link to this heading">#</a></h1>
<section id="brunas-spectral-gcn">
<h2>Bruna’s Spectral GCN<a class="headerlink" href="#brunas-spectral-gcn" title="Link to this heading">#</a></h2>
<p>Let’s first implement Bruna’s spectral GCN.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">scipy.sparse.linalg</span> <span class="k">as</span> <span class="nn">slinalg</span>

<span class="k">class</span> <span class="nc">BrunaGraphConv</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Bruna&#39;s Spectral Graph Convolution Layer</span>

<span class="sd">    This implementation follows the original formulation by Joan Bruna et al.,</span>
<span class="sd">    using the eigendecomposition of the graph Laplacian for spectral convolution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the Bruna Graph Convolution layer</span>

<span class="sd">        Args:</span>
<span class="sd">            in_features (int): Number of input features</span>
<span class="sd">            out_features (int): Number of output features</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BrunaGraphConv</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span> <span class="o">=</span> <span class="n">in_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span>

        <span class="c1"># Learnable spectral filter parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">n_nodes</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Initialize parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize weights using Glorot initialization&quot;&quot;&quot;</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>


    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">get_laplacian_eigenvectors</span><span class="p">(</span><span class="n">adj</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute eigendecomposition of the normalized graph Laplacian</span>

<span class="sd">        Args:</span>
<span class="sd">            adj: Adjacency matrix</span>

<span class="sd">        Returns:</span>
<span class="sd">            eigenvalues, eigenvectors of the normalized Laplacian</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Compute normalized Laplacian</span>
        <span class="c1"># Add self-loops</span>
        <span class="n">adj</span> <span class="o">=</span> <span class="n">adj</span> <span class="o">+</span> <span class="n">sp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">adj</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Compute degree matrix</span>
        <span class="n">deg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">adj</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">Dsqrt_inv</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">diags</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">deg</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="c1"># Compute normalized Laplacian: D^(-1/2) A D^(-1/2)</span>
        <span class="n">laplacian</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">adj</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="n">Dsqrt_inv</span> <span class="o">@</span> <span class="n">adj</span> <span class="o">@</span> <span class="n">Dsqrt_inv</span>

        <span class="c1"># Compute eigendecomposition</span>
        <span class="c1"># Using k=adj.shape[0]-1 to get all non-zero eigenvalues</span>
        <span class="n">eigenvals</span><span class="p">,</span> <span class="n">eigenvecs</span> <span class="o">=</span> <span class="n">slinalg</span><span class="o">.</span><span class="n">eigsh</span><span class="p">(</span><span class="n">laplacian</span><span class="o">.</span><span class="n">tocsc</span><span class="p">(),</span> <span class="n">k</span><span class="o">=</span><span class="n">adj</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;SM&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">eigenvals</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">eigenvecs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">eigenvecs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass implementing Bruna&#39;s spectral convolution</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Input features [num_nodes, in_features]</span>
<span class="sd">            eigenvecs: Eigenvectors of the graph Laplacian [num_nodes, num_nodes-1]</span>

<span class="sd">        Returns:</span>
<span class="sd">            Output features [num_nodes, out_features]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Transform to spectral domain</span>
        <span class="n">x_spectral</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">eigenvecs</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span> <span class="n">x</span><span class="p">)</span>  <span class="c1"># [num_nodes-1, in_features]</span>

        <span class="c1"># Initialize output tensor</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># For each input-output feature pair</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">):</span>
                <span class="c1"># Element-wise multiplication in spectral domain</span>
                <span class="c1"># This is the actual spectral filtering operation</span>
                <span class="n">filtered</span> <span class="o">=</span> <span class="n">x_spectral</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># [num_spectrum]</span>

                <span class="c1"># Transform back to spatial domain and accumulate</span>
                <span class="n">out</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">eigenvecs</span><span class="p">,</span> <span class="n">filtered</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Next, we will train the model on the karate club network to predict the given node labels indicating nodes’ community memberships. We load the data by</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Load karate club network</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">karate_club_graph</span><span class="p">()</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_scipy_sparse_array</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">())</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;club&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Officer&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">()],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>We apply the convolution twice with ReLu activation in between. This can be implemented by preparing two independent <code class="docutils literal notranslate"><span class="pre">BrunaGraphConv</span></code> layers, applying them consecutively, and adding a ReLu activation in between.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define a simple GCN model</span>
<span class="k">class</span> <span class="nc">SimpleGCN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleGCN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">BrunaGraphConv</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">BrunaGraphConv</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">eigenvecs</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">eigenvecs</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">eigenvecs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>We then train the model by</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Get eigenvectors of the Laplacian</span>
<span class="n">eigenvals</span><span class="p">,</span> <span class="n">eigenvecs</span> <span class="o">=</span> <span class="n">BrunaGraphConv</span><span class="o">.</span><span class="n">get_laplacian_eigenvectors</span><span class="p">(</span><span class="n">adj</span><span class="p">)</span>

<span class="c1"># Initialize the model</span>
<span class="n">hidden_features</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">input_features</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">output_features</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_nodes</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleGCN</span><span class="p">(</span><span class="n">input_features</span><span class="p">,</span> <span class="n">output_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Split the data into training and testing sets</span>
<span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">()),</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>


<span class="n">n_train</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_train</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">eigenvecs</span><span class="p">[</span><span class="n">train_idx</span><span class="p">,</span> <span class="p">:])</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Evaluate the model</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">eigenvecs</span><span class="p">[</span><span class="n">test_idx</span><span class="p">,</span> <span class="p">:])</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">test_labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">n_train</span><span class="si">}</span><span class="s1">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Observe that the accuracy increases as the training progresses. We can use the model to predict the labels.
The model has a hidden layer, and let’s visualize the data in the hidden space.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>

<span class="c1"># Visualize the learned embeddings</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">eigenvecs</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">xy</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">xy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">y</span> <span class="o">=</span> <span class="n">xy</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">hue</span><span class="o">=</span><span class="n">labels</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;tab10&#39;</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Learned Node Embeddings&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="chebnet">
<h2>ChebNet<a class="headerlink" href="#chebnet" title="Link to this heading">#</a></h2>
<p>Let’s implement the ChebNet layer.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>


<span class="k">def</span> <span class="nf">sparse_mx_to_torch_sparse</span><span class="p">(</span><span class="n">sparse_mx</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert scipy sparse matrix to torch sparse tensor.&quot;&quot;&quot;</span>
    <span class="n">sparse_mx</span> <span class="o">=</span> <span class="n">sparse_mx</span><span class="o">.</span><span class="n">tocoo</span><span class="p">()</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">sparse_mx</span><span class="o">.</span><span class="n">row</span><span class="p">,</span> <span class="n">sparse_mx</span><span class="o">.</span><span class="n">col</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">sparse_mx</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">sparse_mx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ChebConv</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Chebyshev Spectral Graph Convolutional Layer</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">K</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ChebConv</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">K</span>

        <span class="c1"># Trainable parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">bias</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">out_channels</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize parameters.&quot;&quot;&quot;</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_normalize_laplacian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute normalized Laplacian L = I - D^(-1/2)AD^(-1/2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Convert to scipy if it&#39;s not already</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sp</span><span class="o">.</span><span class="n">isspmatrix</span><span class="p">(</span><span class="n">adj_matrix</span><span class="p">):</span>
            <span class="n">adj_matrix</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">(</span><span class="n">adj_matrix</span><span class="p">)</span>

        <span class="n">adj_matrix</span> <span class="o">=</span> <span class="n">adj_matrix</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

        <span class="c1"># Compute degree matrix D</span>
        <span class="n">rowsum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">adj_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">d_inv_sqrt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">rowsum</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">d_inv_sqrt</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">d_inv_sqrt</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">d_mat_inv_sqrt</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">diags</span><span class="p">(</span><span class="n">d_inv_sqrt</span><span class="p">)</span>

        <span class="c1"># Compute L = I - D^(-1/2)AD^(-1/2)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">adj_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">L</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">-</span> <span class="n">d_mat_inv_sqrt</span> <span class="o">@</span> <span class="n">adj_matrix</span> <span class="o">@</span> <span class="n">d_mat_inv_sqrt</span>
        <span class="k">return</span> <span class="n">L</span>

    <span class="k">def</span> <span class="nf">_scale_laplacian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">L</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Scale Laplacian eigenvalues to [-1, 1] interval</span>
<span class="sd">        L_scaled = 2L/lambda_max - I</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Compute largest eigenvalue</span>
            <span class="n">eigenval</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigsh</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;LM&quot;</span><span class="p">,</span> <span class="n">return_eigenvectors</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">lambda_max</span> <span class="o">=</span> <span class="n">eigenval</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="c1"># Approximate lambda_max = 2 if eigenvalue computation fails</span>
            <span class="n">lambda_max</span> <span class="o">=</span> <span class="mf">2.0</span>

        <span class="n">n</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">L_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="n">lambda_max</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span> <span class="o">-</span> <span class="n">sp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">L_scaled</span>

    <span class="k">def</span> <span class="nf">chebyshev_basis</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">L_sparse</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute Chebyshev polynomials basis up to order K.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># List to store Chebyshev polynomials</span>
        <span class="n">cheb_polynomials</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># T_0(L) = I</span>
        <span class="n">cheb_polynomials</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># T_1(L) = L</span>
            <span class="n">X_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">L_sparse</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
            <span class="n">cheb_polynomials</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>

        <span class="c1"># Recurrence T_k(L) = 2L·T_{k-1}(L) - T_{k-2}(L)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">):</span>
            <span class="n">X_k</span> <span class="o">=</span> <span class="p">(</span>
                <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">L_sparse</span><span class="p">,</span> <span class="n">cheb_polynomials</span><span class="p">[</span><span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
                <span class="o">-</span> <span class="n">cheb_polynomials</span><span class="p">[</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">cheb_polynomials</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_k</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">cheb_polynomials</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># [K, num_nodes, in_channels]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">:</span> <span class="n">sp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: Node features tensor of shape [num_nodes, in_channels]</span>
<span class="sd">            adj_matrix: Adjacency matrix in scipy sparse format</span>

<span class="sd">        Returns:</span>
<span class="sd">            Output tensor of shape [num_nodes, out_channels]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Compute normalized and scaled Laplacian</span>
        <span class="n">L_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_laplacian</span><span class="p">(</span><span class="n">adj_matrix</span><span class="p">)</span>
        <span class="n">L_scaled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale_laplacian</span><span class="p">(</span><span class="n">L_norm</span><span class="p">)</span>

        <span class="c1"># Convert to torch sparse tensor</span>
        <span class="n">L_scaled</span> <span class="o">=</span> <span class="n">sparse_mx_to_torch_sparse</span><span class="p">(</span><span class="n">L_scaled</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Compute Chebyshev polynomials basis</span>
        <span class="n">Tx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">chebyshev_basis</span><span class="p">(</span><span class="n">L_scaled</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>  <span class="c1"># [K, num_nodes, in_channels]</span>

        <span class="c1"># Perform convolution using learned weights</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;kni,kio-&gt;no&quot;</span><span class="p">,</span> <span class="n">Tx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>

        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>We stack the layers to form a simple GCN model.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ChebNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ChebNet model for node classification</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">hidden_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">K</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ChebNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>

        <span class="c1"># First layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ChebConv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">K</span><span class="p">))</span>

        <span class="c1"># Hidden layers</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ChebConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">K</span><span class="p">))</span>

        <span class="c1"># Output layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ChebConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">K</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">:</span> <span class="n">sp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through all layers</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">conv</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">)</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Output layer</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">X</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Let’s train the model on the karate club network.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>

<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Load karate club network</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">karate_club_graph</span><span class="p">()</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_scipy_sparse_array</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">())</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
    <span class="p">[</span><span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;club&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Officer&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">()],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span>
<span class="p">)</span>

<span class="c1"># Initialize the model</span>
<span class="n">hidden_features</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">input_features</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">output_features</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_nodes</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">()</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChebNet</span><span class="p">(</span>
    <span class="n">input_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">,</span> <span class="n">output_features</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Train the model</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Split the data into training and testing sets</span>
<span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">()),</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>


<span class="n">n_train</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_train</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">adj</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">train_labels</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Evaluate the model</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">adj</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="n">test_idx</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">test_labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">n_train</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Let’s visualize the learned embeddings.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># Get embeddings from the last hidden layer</span>
    <span class="n">X_hidden</span> <span class="o">=</span> <span class="n">features</span>
    <span class="k">for</span> <span class="n">conv</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">convs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">X_hidden</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">X_hidden</span><span class="p">,</span> <span class="n">adj</span><span class="p">)</span>
        <span class="n">X_hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">X_hidden</span><span class="p">)</span>

<span class="c1"># Reduce dimensionality for visualization</span>
<span class="n">xy</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_hidden</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">y</span><span class="o">=</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">hue</span><span class="o">=</span><span class="n">labels</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
    <span class="n">palette</span><span class="o">=</span><span class="s2">&quot;tab10&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Learned Node Embeddings&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<hr class="docutils" />
<section id="id140">
<h2>jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3<a class="headerlink" href="#id140" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="from-image-to-graph">
<h1>From Image to Graph<a class="headerlink" href="#from-image-to-graph" title="Link to this heading">#</a></h1>
<section id="analogy-between-image-and-graph-data">
<h2>Analogy between image and graph data<a class="headerlink" href="#analogy-between-image-and-graph-data" title="Link to this heading">#</a></h2>
<p>We can think of a convolution of an image from the perspective of networks.
In the convolution of an image, a pixel is convolved with its <em>neighbors</em>. We can regard each pixel as a node, and each node is connected to its neighboring nodes (pixels) that are involved in the convolution.</p>
<p><img alt="" src="https://av-eks-lekhak.s3.amazonaws.com/media/__sized__/article_images/conv_graph-thumbnail_webp-600x300.webp" /></p>
<p>Building on this analogy, we can extend the idea of convolution to general graph data.
Each node has a pixel value(s) (e.g., feature vector), which is convolved with the values of its neighbors in the graph.
This is the key idea of graph convolutional networks.
But, there is a key difference: while the number of neighbors for an image is homogeneous, the number of neighbors for a node in a graph can be heterogeneous. Each pixel has the same number of neighbors (except for the boundary pixels), but nodes in a graph can have very different numbers of neighbors. This makes it non-trivial to define the “kernel” for graph convolution.</p>
</section>
<section id="spectral-filter-on-graphs">
<h2>Spectral filter on graphs<a class="headerlink" href="#spectral-filter-on-graphs" title="Link to this heading">#</a></h2>
<p>Just like we can define a convolution on images in the frequency domain, we can also define a ‘‘frequency domain’’ for graphs.</p>
<p>Consider a network of <span class="math notranslate nohighlight">\(N\)</span> nodes, where each node has a feature variable <span class="math notranslate nohighlight">\({\mathbf x}_i \in \mathbb{R}\)</span>. We are interested in:</p>
<div class="math notranslate nohighlight">
\[
J = \frac{1}{2}\sum_{i=1}^N\sum_{j=1}^N A_{ij}(x_i - x_j)^2,
\]</div>
<p>where <span class="math notranslate nohighlight">\(A_{ij}\)</span> is the adjacency matrix of the graph. The quantity <span class="math notranslate nohighlight">\(J\)</span> represents <em>the total variation</em> of <span class="math notranslate nohighlight">\(x\)</span> between connected nodes; a small <span class="math notranslate nohighlight">\(J\)</span> means that connected nodes have similar <span class="math notranslate nohighlight">\(x\)</span> (low variation; low frequency), while a large <span class="math notranslate nohighlight">\(J\)</span> means that connected nodes have very different <span class="math notranslate nohighlight">\(x\)</span> (high variation; high frequency).</p>
<p>We can rewrite <span class="math notranslate nohighlight">\(J\)</span> as</p>
<div class="math notranslate nohighlight">
\[
J = \frac{1}{2}\sum_{i=1}^N\sum_{j=1}^N A_{ij}(x_i - x_j)^2 = {\bf x}^\top {\bf L} {\bf x},
\]</div>
<p>where <span class="math notranslate nohighlight">\({\bf L}\)</span> is the Laplacian matrix of the graph given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
L_{ij} = \begin{cases}
-1 &amp; \text{if } i \text{ and } j \text{ are connected} \\
k_i &amp; \text{if } i = j \\
0 &amp; \text{otherwise}
\end{cases}.
\end{split}\]</div>
<p>and <span class="math notranslate nohighlight">\({\bf x} = [x_1,x_2,\ldots, x_N]^\top\)</span> is a column vector of feature variables.</p>
<div class="dropdown admonition">
<p class="admonition-title">Detailed derivation</p>
<p>The above derivation shows that the total variation of <span class="math notranslate nohighlight">\(x\)</span> between connected nodes is proportional to <span class="math notranslate nohighlight">\({\bf x}^\top {\bf L} {\bf x}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
J &amp;= \frac{1}{2}\sum_{i=1}^N\sum_{j=1}^N A_{ij}(x_i - x_j)^2 \\
&amp;= \frac{1}{2}\sum_{i=1}^N\sum_{j=1}^N \underbrace{A_{ij}\left( x_i^2 +x_j^2\right)}_{\text{symmetric}} - \sum_{i=1}^N\sum_{j=1}^N A_{ij}x_ix_j \\
&amp;= \sum_{i=1}^Nx_i^2\underbrace{\sum_{j=1}^N A_{ij}}_{\text{degree of node } i, k_i} - \sum_{i=1}^N\sum_{j=1}^N A_{ij}x_ix_j \\
&amp;= \sum_{i=1}^Nx_i^2 k_i - \sum_{i=1}^N\sum_{j=1}^N A_{ij}x_ix_j \\
&amp;= \underbrace{[x_1,x_2,\ldots, x_N]}_{{\bf x}} \underbrace{\begin{bmatrix} k_1 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; k_2 &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; k_N \end{bmatrix}}_{{\bf D}} \underbrace{\begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_N \end{bmatrix}}_{{\bf x}} - 2\underbrace{\sum_{i=1}^N\sum_{j=1}^N A_{ij}}_{{\bf x}^\top {\mathbf A} {\bf x}} {\bf x} \\
&amp;= {\bf x}^\top {\bf D} {\bf x} - {\bf x}^\top {\mathbf A} {\bf x} \\
&amp;= {\bf x}^\top {\bf L} {\bf x},
\end{aligned}
\end{split}\]</div>
</div>
<p>Let us showcase the analogy between the Fourier transform and the Laplacian matrix.
In the Fourier transform, a signal is decomposed into sinusoidal basis functions. Similarly, for a graph, we can decompose the variation <span class="math notranslate nohighlight">\(J\)</span> into eigenvector bases.</p>
<div class="math notranslate nohighlight">
\[
J = \sum_{i=1}^N \lambda_i  {\bf x}^\top {\mathbf u}_i {\mathbf u}_i^\top {\bf x} = \sum_{i=1}^N \lambda_i  ||{\bf x}^\top {\mathbf u}_i||^2.
\]</div>
<p>where <span class="math notranslate nohighlight">\({\mathbf u}_i\)</span> is the eigenvector corresponding to the eigenvalue <span class="math notranslate nohighlight">\(\lambda_i\)</span>.</p>
<ul class="simple">
<li><p>The term <span class="math notranslate nohighlight">\(({\bf x}^\top {\mathbf u}_i)\)</span> is a dot-product between the feature vector <span class="math notranslate nohighlight">\({\bf x}\)</span> and the eigenvector <span class="math notranslate nohighlight">\({\mathbf u}_i\)</span>, which measures how much <span class="math notranslate nohighlight">\({\bf x}\)</span> <em>coheres</em> with eigenvector <span class="math notranslate nohighlight">\({\mathbf u}_i\)</span>, similar to how Fourier coefficients measure coherency with sinusoids.</p></li>
<li><p>Each <span class="math notranslate nohighlight">\(||{\bf x}^\top {\mathbf u}_i||^2\)</span> is the ‘‘strength’’ of <span class="math notranslate nohighlight">\({\bf x}\)</span> with respect to the eigenvector <span class="math notranslate nohighlight">\({\mathbf u}_i\)</span>, and the total variation <span class="math notranslate nohighlight">\(J\)</span> is a weighted sum of these strengths.</p></li>
</ul>
<p>Some eigenvectors correspond to low-frequency components, while others correspond to high-frequency components. For example, the total variation <span class="math notranslate nohighlight">\(J\)</span> for an eigenvector <span class="math notranslate nohighlight">\({\mathbf u}_i\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
J = \frac{1}{2} \sum_{j}\sum_{\ell} A_{j\ell}(u_{ij} - u_{i\ell})^2 = {\mathbf u}_i^\top {\mathbf L} {\mathbf u}_i = \lambda_i.
\]</div>
<p>This equation provides key insight into the meaning of eigenvalues:</p>
<ol class="arabic simple">
<li><p>For an eigenvector <span class="math notranslate nohighlight">\({\mathbf u}_i\)</span>, its eigenvalue <span class="math notranslate nohighlight">\(\lambda_i\)</span> measures the total variation for <span class="math notranslate nohighlight">\({\mathbf u}_i\)</span>.</p></li>
<li><p>Large eigenvalues mean large differences between neighbors (high frequency), while small eigenvalues mean small differences (low frequency).</p></li>
</ol>
<p>Thus, if <span class="math notranslate nohighlight">\({\bf x}\)</span> aligns well with <span class="math notranslate nohighlight">\({\mathbf u}_i\)</span> with a large <span class="math notranslate nohighlight">\(\lambda_i\)</span>, then <span class="math notranslate nohighlight">\({\bf x}\)</span> has a strong high-frequency component; if <span class="math notranslate nohighlight">\({\bf x}\)</span> aligns well with <span class="math notranslate nohighlight">\({\mathbf u}_i\)</span> with a small <span class="math notranslate nohighlight">\(\lambda_i\)</span>, then <span class="math notranslate nohighlight">\({\bf x}\)</span> has strong low-frequency component.</p>
<section id="spectral-filtering">
<h3>Spectral Filtering<a class="headerlink" href="#spectral-filtering" title="Link to this heading">#</a></h3>
<p>Eigenvalues <span class="math notranslate nohighlight">\(\lambda_i\)</span> can be thought of as a <em>filter</em> that controls which frequency components pass through. Instead of using the filter associated with the Laplacian matrix, we can design a filter <span class="math notranslate nohighlight">\(h(\lambda_i)\)</span> to control which frequency components pass through. This leads to the idea of <em>spectral filtering</em>. Two common filters are:</p>
<ol class="arabic simple">
<li><p><strong>Low-pass Filter</strong>:
$<span class="math notranslate nohighlight">\(h_{\text{low}}(\lambda) = \frac{1}{1 + \alpha\lambda}\)</span>$</p>
<ul class="simple">
<li><p>Preserves low frequencies (small λ)</p></li>
<li><p>Suppresses high frequencies (large λ)</p></li>
<li><p>Results in smoother signals</p></li>
</ul>
</li>
<li><p><strong>High-pass Filter</strong>:
$<span class="math notranslate nohighlight">\(h_{\text{high}}(\lambda) = \frac{\alpha\lambda}{1 + \alpha\lambda}\)</span>$</p>
<ul class="simple">
<li><p>Preserves high frequencies</p></li>
<li><p>Suppresses low frequencies</p></li>
<li><p>Emphasizes differences between neighbors</p></li>
</ul>
</li>
</ol>
<div class="cell tag_remove-input docutils container">
</div>
</section>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Link to this heading">#</a></h3>
<p>Let us showcase the idea of spectral filtering with a simple example with the karate club network.</p>
<div class="cell tag_remove-input docutils container">
</div>
<p>We will first compute the laplacian matrix and its eigendecomposition.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute Laplacian matrix</span>
<span class="n">deg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">diags</span><span class="p">(</span><span class="n">deg</span><span class="p">)</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">D</span> <span class="o">-</span> <span class="n">A</span>

<span class="c1"># Compute eigendecomposition</span>
<span class="n">evals</span><span class="p">,</span> <span class="n">evecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>

<span class="c1"># Sort eigenvalues and eigenvectors</span>
<span class="n">order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span>
<span class="n">evals</span> <span class="o">=</span> <span class="n">evals</span><span class="p">[</span><span class="n">order</span><span class="p">]</span>
<span class="n">evecs</span> <span class="o">=</span> <span class="n">evecs</span><span class="p">[:,</span> <span class="n">order</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Now, let’s create a low-pass and high-pass filter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">L_low</span> <span class="o">=</span> <span class="n">evecs</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">evals</span><span class="p">))</span> <span class="o">@</span> <span class="n">evecs</span><span class="o">.</span><span class="n">T</span>
<span class="n">L_high</span> <span class="o">=</span> <span class="n">evecs</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">evals</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">evals</span><span class="p">))</span> <span class="o">@</span> <span class="n">evecs</span><span class="o">.</span><span class="n">T</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Size of low-pass filter:&quot;</span><span class="p">,</span> <span class="n">L_low</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Size of high-pass filter:&quot;</span><span class="p">,</span> <span class="n">L_high</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that the high-pass filter and low-pass filter are matrices of the same size as the adjacency matrix <span class="math notranslate nohighlight">\(A\)</span>, which defines a ‘convolution’ on the graph as follows:</p>
<div class="math notranslate nohighlight">
\[
{\bf x}' = {\bf L}_{\text{low}} {\bf x} \quad \text{or} \quad {\bf x}' = {\bf L}_{\text{high}} {\bf x}.
\]</div>
<p>where <span class="math notranslate nohighlight">\({\bf L}_{\text{low}}\)</span> and <span class="math notranslate nohighlight">\({\bf L}_{\text{high}}\)</span> are the low-pass and high-pass filters, respectively, and <span class="math notranslate nohighlight">\({\bf x}'\)</span> is the convolved feature vector.</p>
<p>Now, let’s see how these filters work. Our first example is a random feature vector.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Random feature vector</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Convolve with low-pass filter</span>
<span class="n">x_low</span> <span class="o">=</span> <span class="n">L_low</span> <span class="o">@</span> <span class="n">x</span>

<span class="c1"># Convolve with high-pass filter</span>
<span class="n">x_high</span> <span class="o">=</span> <span class="n">L_high</span> <span class="o">@</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<p>Let us visualize the results.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">palette</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">norm</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">vmin</span><span class="o">=-</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># Original</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">values</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
<span class="n">ig</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">palette</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">values</span><span class="p">],</span> <span class="n">bbox</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span> <span class="n">vertex_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Original&quot;</span><span class="p">)</span>

<span class="c1"># Low-pass filter applied</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">L_low</span> <span class="o">@</span> <span class="n">x</span>
<span class="n">values</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ig</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">palette</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">values</span><span class="p">],</span> <span class="n">bbox</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span> <span class="n">vertex_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Low-pass filter&quot;</span><span class="p">)</span>

<span class="c1"># High-pass filter applied</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">L_high</span> <span class="o">@</span> <span class="n">x</span>
<span class="n">values</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ig</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">palette</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">values</span><span class="p">],</span> <span class="n">bbox</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span> <span class="n">vertex_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;High-pass filter&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>We observe that the low-pass filter results in smoother <span class="math notranslate nohighlight">\({\bf x}\)</span> between connected nodes (i.e., neighboring nodes have similar <span class="math notranslate nohighlight">\({\bf x}\)</span>).
The original <span class="math notranslate nohighlight">\({\bf x}\)</span> and <span class="math notranslate nohighlight">\({\bf x}'_{\text{low}}\)</span> are very similar because random variables are high-frequency components. In contrast, when we apply the high-pass filter, <span class="math notranslate nohighlight">\({\bf x}'_{\text{high}}\)</span> is similar to <span class="math notranslate nohighlight">\({\bf x}\)</span> because the high-frequency components are not filtered.</p>
<p>Let’s now use an eigenvector as our feature vector <span class="math notranslate nohighlight">\({\bf x}\)</span>.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eigen_centrality</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">eigenvector_centrality</span><span class="p">())</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">low_pass_eigen</span> <span class="o">=</span> <span class="n">L_low</span> <span class="o">@</span> <span class="n">eigen_centrality</span>
<span class="n">high_pass_eigen</span> <span class="o">=</span> <span class="n">L_high</span> <span class="o">@</span> <span class="n">eigen_centrality</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">palette</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">norm</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">vmin</span><span class="o">=-</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">eigen_centrality</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="c1"># high_pass_random.reshape(-1)</span>
<span class="n">values</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ig</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">palette</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">values</span><span class="p">],</span> <span class="n">bbox</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span> <span class="n">vertex_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Original&quot;</span><span class="p">)</span>

<span class="n">values</span> <span class="o">=</span> <span class="n">low_pass_eigen</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">values</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ig</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">palette</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">values</span><span class="p">],</span> <span class="n">bbox</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span> <span class="n">vertex_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Low-pass filter&quot;</span><span class="p">)</span>

<span class="n">values</span> <span class="o">=</span> <span class="n">high_pass_eigen</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">values</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
<span class="n">ig</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">palette</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">values</span><span class="p">],</span> <span class="n">bbox</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span> <span class="n">vertex_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;High-pass filter&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="the-high-pass-filter-increases-the-contrast-of-the-eigenvector-centrality-emphasizing-the-differences-between-nodes-on-the-other-hand-the-low-pass-filter-smooths-out-the-eigenvector-centrality">
<h2>The high-pass filter increases the contrast of the eigenvector centrality, emphasizing the differences between nodes. On the other hand, the low-pass filter smooths out the eigenvector centrality.<a class="headerlink" href="#the-high-pass-filter-increases-the-contrast-of-the-eigenvector-centrality-emphasizing-the-differences-between-nodes-on-the-other-hand-the-low-pass-filter-smooths-out-the-eigenvector-centrality" title="Link to this heading">#</a></h2>
</section>
<section id="id141">
<h2>jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3<a class="headerlink" href="#id141" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="graph-convolutional-networks">
<h1>Graph Convolutional Networks<a class="headerlink" href="#graph-convolutional-networks" title="Link to this heading">#</a></h1>
<p>We have seen that spectral filters give us a principled way to think about “convolution” on irregular graph structures, and controlling the frequency components brings out different aspects of the data. We now go one step further: instead of designing filters by hand, we can learn them from data for specific tasks.</p>
<section id="spectral-graph-convolutional-networks">
<h2>Spectral Graph Convolutional Networks<a class="headerlink" href="#spectral-graph-convolutional-networks" title="Link to this heading">#</a></h2>
<p>A simplest form of learnable spectral filter is given by</p>
<div class="math notranslate nohighlight">
\[
{\bf L}_{\text{learn}} = \sum_{k=1}^K \theta_k {\mathbf u}_k {\mathbf u}_k^\top,
\]</div>
<p>where <span class="math notranslate nohighlight">\({\mathbf u}_k\)</span> are the eigenvectors and <span class="math notranslate nohighlight">\(\theta_k\)</span> are the learnable parameters. The variable <span class="math notranslate nohighlight">\(K\)</span> is the number of eigenvectors used (i.e., the rank of the filter). The weight <span class="math notranslate nohighlight">\(\theta_k\)</span> is learned to maximize the performance of the task at hand.</p>
<p>Building on this idea, <a class="footnote-reference brackets" href="#footcite-bruna2014spectral" id="id142" role="doc-noteref"><span class="fn-bracket">[</span>42<span class="fn-bracket">]</span></a> added a nonlinearity to the filter and proposed a spectral convolutional neural network (GCN) by</p>
<div class="math notranslate nohighlight">
\[
{\bf x}^{(\ell+1)} = h\left( L_{\text{learn}} {\bf x}^{(\ell)}\right),
\]</div>
<p>where <span class="math notranslate nohighlight">\(h\)</span> is an activation function, and <span class="math notranslate nohighlight">\({\bf x}^{(\ell)}\)</span> is the feature vector of the <span class="math notranslate nohighlight">\(\ell\)</span>-th convolution. They further extend this idea to convolve on multidimensional feature vectors, <span class="math notranslate nohighlight">\({\bf X} \in \mathbb{R}^{N \times f_{\text{in}}}\)</span> to produce new feature vectors of different dimensionality, <span class="math notranslate nohighlight">\({\bf X}' \in \mathbb{R}^{N \times f_{\text{out}}}\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
{\bf X}^{(\ell+1)}_i &amp;= h\left( \sum_j L_{\text{learn}}^{(i,j)} {\bf X}^{(\ell)}_j\right),\quad \text{where} \quad L^{(i,j)}_{\text{learn}} = \sum_{k=1}^K \theta_{k, (i,j)} {\mathbf u}_k {\mathbf u}_k^\top,
\end{aligned}
\]</div>
<p>Notice that the learnable filter <span class="math notranslate nohighlight">\(L_{\text{learn}}^{(i,j)}\)</span> is defined for each pair of input <span class="math notranslate nohighlight">\(i\)</span> and output <span class="math notranslate nohighlight">\(j\)</span> dimensions.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Many GCNs simple when it comes to implementation despite the complicated formula. And this is one of my ways to learn GNNs. Check out the <a class="reference internal" href="#appendix.md"><span class="xref myst">Appendix for the Python implementation</span></a>.</p>
</div>
</section>
<section id="from-spectral-to-spatial">
<h2>From Spectral to Spatial<a class="headerlink" href="#from-spectral-to-spatial" title="Link to this heading">#</a></h2>
<p>Spectral GCNs are mathematically elegant but have two main limitations:</p>
<ol class="arabic simple">
<li><p><strong>Computational Limitation</strong>: Computing the spectra of the Laplacian is expensive <span class="math notranslate nohighlight">\({\cal O}(N^3)\)</span> and prohibitive for large graphs</p></li>
<li><p><strong>Spatial Locality</strong>: The learned filters are not spatially localized. A node can be influenced by all other nodes in the graph.</p></li>
</ol>
<p>These two limitations motivate the development of spatial GCNs.</p>
<section id="id143">
<h3>ChebNet<a class="headerlink" href="#id143" title="Link to this heading">#</a></h3>
<p>ChebNet <a class="footnote-reference brackets" href="#footcite-defferrard2016convolutional" id="id144" role="doc-noteref"><span class="fn-bracket">[</span>43<span class="fn-bracket">]</span></a> is one of the earliest spatial GCNs that bridges the gap between spectral and spatial domains.
The key idea is to leverage Chebyshev polynomials to approximate <span class="math notranslate nohighlight">\({\bf L}_{\text{learn}}\)</span> by</p>
<div class="math notranslate nohighlight">
\[
{\bf L}_{\text{learn}} \approx \sum_{k=0}^{K-1} \theta_k T_k(\tilde{{\bf L}}), \quad \text{where} \quad \tilde{{\bf L}} = \frac{2}{\lambda_{\text{max}}}{\bf L} - {\bf I},
\]</div>
<p>where <span class="math notranslate nohighlight">\(\tilde{{\bf L}}\)</span> is the scaled and normalized Laplacian matrix in order to have eigenvalues in the range of <span class="math notranslate nohighlight">\([-1,1]\)</span>. The Chebyshev polynomials <span class="math notranslate nohighlight">\(T_k(\tilde{{\bf L}})\)</span> transforms the eigenvalues <span class="math notranslate nohighlight">\(\tilde{{\bf L}}\)</span> to the following recursively:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
T_0(\tilde{{\bf L}}) &amp;= {\bf I} \\
T_1(\tilde{{\bf L}}) &amp;= \tilde{{\bf L}} \\
T_k(\tilde{{\bf L}}) &amp;= 2\tilde{{\bf L}} T_{k-1}(\tilde{{\bf L}}) - T_{k-2}(\tilde{{\bf L}})
\end{aligned}
\end{split}\]</div>
<p>We then replace <span class="math notranslate nohighlight">\({\bf L}_{\text{learn}}\)</span> in the original spectral GCN with the Chebyshev polynomial approximation:</p>
<div class="math notranslate nohighlight">
\[
{\bf x}^{(\ell+1)} = h\left( \sum_{k=0}^{K-1} \theta_k T_k(\tilde{{\bf L}}){\bf x}^{(\ell)}\right),
\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(T_k(\tilde{{\bf L}})\)</span> applies the k-th Chebyshev polynomial to the scaled Laplacian matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\theta_k\)</span> are the learnable parameters</p></li>
<li><p>K is the order of the polynomial (typically small, e.g., K=3)</p></li>
</ul>
</section>
<section id="graph-convolutional-networks-by-kipf-and-welling">
<h3>Graph Convolutional Networks by Kipf and Welling<a class="headerlink" href="#graph-convolutional-networks-by-kipf-and-welling" title="Link to this heading">#</a></h3>
<p>While ChebNet offers a principled way to approximate spectral convolutions, Kipf and Welling (2017) <a class="footnote-reference brackets" href="#footcite-kipf2017semi" id="id145" role="doc-noteref"><span class="fn-bracket">[</span>44<span class="fn-bracket">]</span></a> proposed an even simpler and highly effective variant called <strong>Graph Convolutional Networks (GCN)</strong>.</p>
<section id="first-order-approximation">
<h4>First-order Approximation<a class="headerlink" href="#first-order-approximation" title="Link to this heading">#</a></h4>
<p>The key departure is to use the first-order approximation of the Chebyshev polynomials.</p>
<div class="math notranslate nohighlight">
\[
g_{\theta'} * x \approx \theta'_0x + \theta'_1(L - I_N)x = \theta'_0x - \theta'_1D^{-\frac{1}{2}}AD^{-\frac{1}{2}}x
\]</div>
<p>This is crude approximation but it leads to a much simpler form, leaving only two learnable parameters, instead of <span class="math notranslate nohighlight">\(K\)</span> parameters in the original ChebNet.</p>
<p>Additionally, they further simplify the formula by using the same <span class="math notranslate nohighlight">\(\theta\)</span> for both remaining parameters (i.e., <span class="math notranslate nohighlight">\(\theta_0 = \theta\)</span> and <span class="math notranslate nohighlight">\(\theta_1 = -\theta\)</span>). The result is the following convolutional filter:</p>
<div class="math notranslate nohighlight">
\[
g_{\theta} * x \approx \theta(I_N + D^{-\frac{1}{2}}AD^{-\frac{1}{2}})x
\]</div>
<p>While this is a very simple filter, one can stack multiple layers of convolutions to perform high-order graph convolutions.</p>
</section>
<section id="deep-gcns-can-suffer-from-over-smoothing">
<h4>Deep GCNs can suffer from over-smoothing<a class="headerlink" href="#deep-gcns-can-suffer-from-over-smoothing" title="Link to this heading">#</a></h4>
<p>GCN models can be deep, and when they are too deep, they start suffering from an ill-posed problem called <em>gradient vanishing/exploding</em>, where the gradients of the loss function becomes too small or too large to update the model parameters. It is a common problem in deep learning.</p>
<p>To facilitate the training of deep GCNs, the authors introduce a very simple trick called <em>renormalization</em>. The idea is to add self-connections to the graph:</p>
<div class="math notranslate nohighlight">
\[
\tilde{A} = A + I_N, \quad \text{and} \quad \tilde{D}_{ii} = \sum_j \tilde{A}_{ij}
\]</div>
<p>And use <span class="math notranslate nohighlight">\(\tilde{A}\)</span> and <span class="math notranslate nohighlight">\(\tilde{D}\)</span> to form the convolutional filter.</p>
<p>Altogether, this leads to the following layer-wise propagation rule:</p>
<div class="math notranslate nohighlight">
\[X^{(\ell+1)} = \sigma(\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}X^{(\ell)}W^{(\ell)})\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X^{(\ell)}\)</span> is the matrix of node features at layer <span class="math notranslate nohighlight">\(\ell\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(W^{(\ell)}\)</span> is the layer’s trainable weight matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma\)</span> is a nonlinear activation function (e.g., ReLU)</p></li>
</ul>
<p>These simplifications offer several advantages:</p>
<ul class="simple">
<li><p><strong>Efficiency</strong>: Linear complexity in number of edges</p></li>
<li><p><strong>Localization</strong>: Each layer only aggregates information from immediate neighbors</p></li>
<li><p><strong>Depth</strong>: Fewer parameters allow building deeper models</p></li>
<li><p><strong>Performance</strong>: Despite (or perhaps due to) its simplicity, it often outperforms more complex models</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title">Exercise</p>
<p>Let’s implement a simple GCN model for node classification.
<span class="xref myst">Coding Exercise</span></p>
</div>
<div class="docutils container" id="id146">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-bruna2014spectral" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id142">42</a><span class="fn-bracket">]</span></span>
<p>Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. Spectral networks and locally connected networks on graphs. In Yoshua Bengio and Yann LeCun, editors, <em>2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings</em>. 2014. URL: <a class="reference external" href="http://arxiv.org/abs/1312.6203">http://arxiv.org/abs/1312.6203</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-defferrard2016convolutional" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id144">43</a><span class="fn-bracket">]</span></span>
<p>Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. <em>Advances in neural information processing systems</em>, 2016.</p>
</aside>
<aside class="footnote brackets" id="footcite-kipf2017semi" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id145">44</a><span class="fn-bracket">]</span></span>
<p>Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In <em>International Conference on Learning Representations (ICLR)</em>. 2017.</p>
</aside>
</aside>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>In the previous example, we used a <span class="math notranslate nohighlight">\(3 \times 3\)</span> kernels called the Prewitt operator, which in terms of <span class="math notranslate nohighlight">\(K\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
K_h = \begin{bmatrix}
-1 &amp; 0 &amp; 1 \\
-1 &amp; 0 &amp; 1 \\
-1 &amp; 0 &amp; 1
\end{bmatrix}
\quad \text{or} \quad
K_v = \begin{bmatrix}
-1 &amp; -1 &amp; -1 \\
0 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 1
\end{bmatrix}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(K_h\)</span> is the horizontal Prewitt operator and <span class="math notranslate nohighlight">\(K_v\)</span> is the vertical Prewitt operator.</p>
</div>
<p>A kernel represents a local pattern we want to detect. The new pixel value after the convolution is maximized when the pattern is most similar to the kernel in terms of the inner product. This can be confirmed by:</p>
<div class="math notranslate nohighlight">
\[
\nabla Z_{22} = \sum_{i=-1}^1 \sum_{j=-1}^1 K_{h-(i+1),w-(j+1)} Z_{2+i, 2+j} = \langle \hat K, Z \rangle
\]</div>
<p>where <span class="math notranslate nohighlight">\(\langle \cdot, \cdot \rangle\)</span> is the inner product, and <span class="math notranslate nohighlight">\(\hat K\)</span> is the order-reversed kernel.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Check out this awesome interactive demo to see how different kernels work: <a class="reference external" href="https://setosa.io/ev/image-kernels/">Demo</a></p>
</div>
</section>
</section>
</section>
<section id="fourier-transform">
<h2>Fourier Transform<a class="headerlink" href="#fourier-transform" title="Link to this heading">#</a></h2>
<p><img alt="" src="https://miro.medium.com/v2/resize:fit:1400/1*D6iRfzDkz-sEzyjYoVZ73w.gif" /></p>
<p>Convolution computes the new pixel values by sliding a kernel over an image. How is the resulting image related to the original image?</p>
<p>To answer this question, let us consider a row of an image and convolve it with a kernel <span class="math notranslate nohighlight">\(K\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
X &amp;= \begin{bmatrix}
X_1 &amp; X_2 &amp; X_3 &amp; X_4 &amp; X_5 &amp; X_6
\end{bmatrix} \\
K &amp;= \begin{bmatrix}
K_1 &amp; K_2 &amp; K_3
\end{bmatrix}
\end{aligned}
\end{split}\]</div>
<p>The convolution of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(K\)</span> is</p>
<div class="math notranslate nohighlight">
\[
X * K = \begin{bmatrix}
X_1 K_3 + X_2 K_2 + X_3 K_1 &amp; X_2 K_3 + X_3 K_2 + X_4 K_1 &amp; X_3 K_3 + X_4 K_2 + X_5 K_1 &amp; X_4 K_3 + X_5 K_2 + X_6 K_1
\end{bmatrix}
\]</div>
<p>…which is complicated, right? 😅 So let’s make it simple by using a useful theorem called <strong>the convolution theorem</strong>.</p>
<p>The convolution theorem gives us a simpler way to think about convolution. Instead of doing the complex sliding window operation in the original domain (like pixel values), we can:</p>
<ol class="arabic simple">
<li><p>Transform both signals to the frequency domain using Fourier transform</p></li>
<li><p>Multiply them together (much simpler!)</p></li>
<li><p>Transform back to get the same result</p></li>
</ol>
<p>Mathematically, the above steps can be written as:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal{F}(X), \mathcal{F}(K)\)</span> - Transform both signals to frequency domain (Fourier transform)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{F}(X) \cdot \mathcal{F}(K)\)</span> - Multiply the transformed signals</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{F}^{-1}(\mathcal{F}(X) \cdot \mathcal{F}(K))\)</span> - Transform back to get <span class="math notranslate nohighlight">\(X * K\)</span></p></li>
</ol>
<p>where <span class="math notranslate nohighlight">\(\mathcal{F}^{-1}\)</span> is the inverse Fourier transform that brings us back to the original domain. This is much easier than computing the convolution directly!</p>
<p>For a discrete signal <span class="math notranslate nohighlight">\(x[n]\)</span> with <span class="math notranslate nohighlight">\(N\)</span> points, the Fourier transform <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{F}(x)[k] = \sum_{n=0}^{N-1} x[n] \cdot e^{-2\pi i \frac{nk}{N}}
\]</div>
<p>where <span class="math notranslate nohighlight">\(i\)</span> is the imaginary unit. Or equivalently,</p>
<div class="math notranslate nohighlight">
\[
\mathcal{F}(x)[k] = \sum_{n=0}^{N-1} x[n] \cdot \left[ \cos\left(2\pi \frac{nk}{N}\right) - i \sin\left(2\pi \frac{nk}{N}\right) \right]
\]</div>
<p>using Euler’s formula <span class="math notranslate nohighlight">\(e^{ix} = \cos(x) + i\sin(x)\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Complex number can be thought of as a way to represent a 2D vector using a single value (which is a computer science perspective; mathematically, it is a bit more subtle). For example, <span class="math notranslate nohighlight">\(e^{i\pi/2} = \cos(\pi/2) + i\sin(\pi/2)\)</span> represents the 2D vector <span class="math notranslate nohighlight">\((\cos(\pi/2), \sin(\pi/2))\)</span>. In the context of Fourier transform, we interpret <span class="math notranslate nohighlight">\(e^{-2\pi i \frac{nk}{N}}\)</span> as two <em>base waves</em>, i.e., sine and cosine, with phase <span class="math notranslate nohighlight">\(\frac{2\pi k}{N}\)</span>.</p>
<p><img alt="" src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Euler%27s_formula.svg/360px-Euler%27s_formula.svg.png" /></p>
</div>
<p>In simple terms, <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> takes a signal (like our row of pixel values) and breaks it down into sine and cosine waves of different frequencies. Each frequency component <span class="math notranslate nohighlight">\(k\)</span> tells us “how much” of that frequency exists in our original signal.
Don’t worry too much about the complex math. The key idea is that <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> represents a signal as a sum of multiple waves with different frequencies, so we can understand the signal in terms of its frequencies rather than its original values.</p>
<p><img alt="" src="https://devincody.github.io/Blog/post/an_intuitive_interpretation_of_the_fourier_transform/img/FFT-Time-Frequency-View_hu24c1c8fe894ecd0dad24174b2bed08c9_99850_800x0_resize_lanczos_2.png" /></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>3Blue1Brown makes a beautiful video explaining Fourier transform: <a class="reference external" href="https://www.youtube.com/watch?v=spUNpyF58BY">Video</a>. Here is a great interactive demo on Fourier transform by Jez Swanson: <a class="reference external" href="https://www.jezzamon.com/fourier/">Demo</a>.</p>
</div>
<section id="an-example-for-the-fourier-transform">
<h3>An example for the Fourier transform<a class="headerlink" href="#an-example-for-the-fourier-transform" title="Link to this heading">#</a></h3>
<p>Now, let’s perform the convolution using the Fourier transform using an example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Let us first perform the convolution directly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pad X with zeros on both sides to handle boundary</span>
<span class="n">n_conv</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">K</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Now we get full length output</span>
<span class="n">XKconv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_conv</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_conv</span><span class="p">):</span>
    <span class="n">XKconv</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">K</span><span class="p">))]</span> <span class="o">*</span> <span class="n">K</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># Reverse the kernel and take element-wise product and sum up</span>
<span class="n">XKconv</span>
</pre></div>
</div>
</div>
</div>
<p>Let us now perform the convolution using the Fourier transform. We compute the Fourier transform of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(K\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Step 1: Transform X and K to frequency domain</span>
<span class="n">FX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># Pad K with zeros to match the length of X before FFT</span>
<span class="n">K_padded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">K</span><span class="p">)),</span> <span class="s1">&#39;constant&#39;</span><span class="p">)</span> <span class="c1"># [-1  0  1  0  0  0]</span>
<span class="n">FK</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">(</span><span class="n">K_padded</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FX:&quot;</span><span class="p">,</span> <span class="n">FX</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We add zeros to <span class="math notranslate nohighlight">\(K\)</span> to make it the same length as <span class="math notranslate nohighlight">\(X\)</span> before applying the Fourier transform. This is necessary because the convolution theorem requires the signals to have the same length.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FX</span></code> is the Fourier transform of <span class="math notranslate nohighlight">\(X\)</span>, which is a complex number. Each entry <span class="math notranslate nohighlight">\(FX[k]\)</span> represents the weight of the cosine wave in its real part and the weight of the sine wave in its imaginary part, with phase <span class="math notranslate nohighlight">\(2\pi k / N\)</span>. Similarly for <code class="docutils literal notranslate"><span class="pre">FK</span></code>.</p></li>
</ul>
<p>Next, we multiply the transformed signals.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">FXKconv</span> <span class="o">=</span> <span class="n">FX</span> <span class="o">*</span> <span class="n">FK</span>
</pre></div>
</div>
</div>
</div>
<p>This is the convolution in the frequency domain. Finally, we transform back to get the convolution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">XKconv_ft</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifft</span><span class="p">(</span><span class="n">FXKconv</span><span class="p">))</span>
<span class="n">XKconv_ft</span>
</pre></div>
</div>
</div>
</div>
<ul>
<li><p>We take the real part. The imaginary part is due to numerical artifacts that do not matter in practice.</p></li>
<li><p>The Fourier transform convolution produces a longer output than direct convolution because it includes partial overlaps between K and X at the boundaries. Since we only want the full overlaps, we need to truncate the first two elements of <code class="docutils literal notranslate"><span class="pre">XKconv_ft</span></code> (as K has length 3) to match the length of the direct convolution result.</p></li>
<li><p>For example, let’s look at what happens at the beginning of the convolution:</p>
<ul class="simple">
<li><p>At position -2: Only the last element of K overlaps with X: <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">0,</span> <span class="pre">10]</span> <span class="pre">*</span> <span class="pre">[-1,</span> <span class="pre">0,</span> <span class="pre">1]</span> <span class="pre">=</span> <span class="pre">10</span></code></p></li>
<li><p>At position -1: Two elements of K overlap with X: <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">10,</span> <span class="pre">10]</span> <span class="pre">*</span> <span class="pre">[-1,</span> <span class="pre">0,</span> <span class="pre">1]</span> <span class="pre">=</span> <span class="pre">10</span></code></p></li>
<li><p>At position 0: Full overlap begins: <code class="docutils literal notranslate"><span class="pre">[10,</span> <span class="pre">10,</span> <span class="pre">80]</span> <span class="pre">*</span> <span class="pre">[-1,</span> <span class="pre">0,</span> <span class="pre">1]</span> <span class="pre">=</span> <span class="pre">70</span></code></p></li>
</ul>
<p>The Fourier transform method gives us all these positions (-2, -1, 0, …), but we only want the full overlaps starting from position 0, which is why we truncate the first two elements.</p>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">XKconv_ft</span> <span class="o">=</span> <span class="n">XKconv_ft</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
<span class="n">XKconv_ft</span>
</pre></div>
</div>
</div>
</div>
<p>This gives us the same result as the direct convolution up to numerical errors.</p>
</section>
</section>
<section id="fourier-transform-of-images">
<h2>Fourier Transform of Images<a class="headerlink" href="#fourier-transform-of-images" title="Link to this heading">#</a></h2>
<p>Let’s extend the above example to an image which is a 2D matrix.
The idea is the same: we take the Fourier transform of each row and column of the image, and then multiply them together to get the convolution in the frequency domain.
More specifically, for an image <span class="math notranslate nohighlight">\(X\)</span> with size <span class="math notranslate nohighlight">\(H \times W\)</span>, the Fourier transform of <span class="math notranslate nohighlight">\(X\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{F}(X)[h, w] &amp;= \sum_{k=0}^{H-1} \sum_{\ell=0}^{W-1} X[k, \ell] \cdot e^{-2\pi i \frac{hk}{H}} \cdot e^{-2\pi i \frac{w\ell}{W}} \\
&amp;= \sum_{k=0}^{H-1} \sum_{\ell=0}^{W-1} X[k, \ell] e^{-2\pi i \left(\frac{hk}{H} + \frac{w\ell}{W}\right)}
\end{aligned}
\end{split}\]</div>
<p>Comparing with the 1D case, we see that the 2D Fourier transform is <em>functionally</em> the same as the 1D Fourier transform, except that we now have two indices <span class="math notranslate nohighlight">\(h\)</span> and <span class="math notranslate nohighlight">\(w\)</span> to represent the frequency in both dimensions.
The basis waves are 2D waves as shown below.</p>
<p><strong>Cosine waves</strong></p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">basis_function</span><span class="p">(</span><span class="n">img_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">  img_size : square size of image f(x,y)</span>
<span class="sd">  u,v : spatial space indice</span>
<span class="sd">  &#39;&#39;&#39;</span>
  <span class="n">N</span> <span class="o">=</span> <span class="n">img_size</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
  <span class="n">x_</span><span class="p">,</span> <span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">bf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">u</span><span class="o">*</span><span class="n">x_</span><span class="o">/</span><span class="n">N</span><span class="o">+</span><span class="n">v</span><span class="o">*</span><span class="n">y_</span><span class="o">/</span><span class="n">N</span><span class="p">))</span>
  <span class="k">if</span> <span class="n">u</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">v</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">bf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">bf</span><span class="p">)</span>
  <span class="n">real</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">bf</span><span class="p">)</span> <span class="c1"># The cosine part</span>
  <span class="n">imag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">imag</span><span class="p">(</span><span class="n">bf</span><span class="p">)</span> <span class="c1"># The sine part</span>
  <span class="k">return</span> <span class="n">real</span><span class="p">,</span> <span class="n">imag</span>

<span class="n">size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">bf_arr_real</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">size</span><span class="o">*</span><span class="n">size</span><span class="p">,</span><span class="n">size</span><span class="p">,</span><span class="n">size</span><span class="p">))</span>
<span class="n">bf_arr_imag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">size</span><span class="o">*</span><span class="n">size</span><span class="p">,</span><span class="n">size</span><span class="p">,</span><span class="n">size</span><span class="p">))</span>
<span class="n">ind</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
    <span class="n">re</span><span class="p">,</span><span class="n">imag</span> <span class="o">=</span> <span class="n">basis_function</span><span class="p">(</span><span class="n">img_size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="n">row</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">col</span><span class="p">)</span>
    <span class="n">bf_arr_real</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="n">re</span>
    <span class="n">bf_arr_imag</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="n">imag</span>
    <span class="n">ind</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># real part</span>
<span class="n">_</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">img</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bf_arr_real</span><span class="p">,</span> <span class="n">axs</span><span class="p">):</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p><strong>Sine waves</strong></p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># imaginary part</span>
<span class="n">_</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">img</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bf_arr_imag</span><span class="p">,</span> <span class="n">axs</span><span class="p">):</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>The Fourier transform of an image is a decomposition of an image into the sum of these basis waves.</p>
<section id="an-example-of-fourier-transform">
<h3>An example of Fourier transform<a class="headerlink" href="#an-example-of-fourier-transform" title="Link to this heading">#</a></h3>
<p>Let us apply the Fourier transform to an image.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Read image from URL</span>
<span class="k">def</span> <span class="nf">read_jpeg_from_url</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">))</span>
    <span class="c1"># Convert to RGB mode if needed (in case it&#39;s RGBA)</span>
    <span class="k">if</span> <span class="n">img</span><span class="o">.</span><span class="n">mode</span> <span class="o">!=</span> <span class="s1">&#39;RGB&#39;</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">img</span>

<span class="k">def</span> <span class="nf">image_to_numpy</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">to_gray_scale</span><span class="p">(</span><span class="n">img_np</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">img_np</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># URL of the image</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://www.binghamton.edu/news/images/uploads/features/20180815_peacequad02_jwc.jpg&quot;</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">read_jpeg_from_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">img_np</span> <span class="o">=</span> <span class="n">image_to_numpy</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">img_gray</span> <span class="o">=</span> <span class="n">to_gray_scale</span><span class="p">(</span><span class="n">img_np</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img_gray</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Take the Fourier transform of the image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ft_img_gray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft2</span><span class="p">(</span><span class="n">img_gray</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This decomposes the image into a sum of basis waves. Let’s see the weights of the basis waves.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span>

<span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">ft_img_gray</span><span class="p">)</span>

<span class="c1"># real part</span>
<span class="n">fig1</span><span class="p">,</span> <span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">LogNorm</span><span class="p">(),</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">fig1</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">ax1</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;horizontal&#39;</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">&#39;Fourier transform magnitude&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>The corresponding basis waves look like this:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">bf_arr_real</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">size</span><span class="o">*</span><span class="n">size</span><span class="p">,</span><span class="n">size</span><span class="p">,</span><span class="n">size</span><span class="p">))</span>
<span class="n">bf_arr_imag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">size</span><span class="o">*</span><span class="n">size</span><span class="p">,</span><span class="n">size</span><span class="p">,</span><span class="n">size</span><span class="p">))</span>
<span class="n">ind</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">size</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">//</span><span class="mi">2</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">size</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">//</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">re</span><span class="p">,</span><span class="n">imag</span> <span class="o">=</span> <span class="n">basis_function</span><span class="p">(</span><span class="n">img_size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="n">row</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">col</span><span class="p">)</span>
    <span class="n">bf_arr_real</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="n">re</span>
    <span class="n">bf_arr_imag</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="n">imag</span>
    <span class="n">ind</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># real part</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">img</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bf_arr_real</span><span class="p">,</span> <span class="n">axs</span><span class="p">):</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Real Part of Basis Functions&#39;</span><span class="p">)</span>


<span class="c1"># imaginary part</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">img</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bf_arr_imag</span><span class="p">,</span> <span class="n">axs</span><span class="p">):</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Imaginary Part of Basis Functions&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Now, let’s see the convolution of the image with a Prewitt operator.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span> <span class="c1"># Prewitt operator</span>

<span class="n">K_padd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">img_gray</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">img_gray</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">K_padd</span><span class="p">[:</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">K</span>

<span class="c1"># convolution</span>
<span class="n">FK</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft2</span><span class="p">(</span><span class="n">K_padd</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The Fourier transform of the Prewitt operator looks like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">FK</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We can think of the frequency domain of the kernel as a <strong>filter</strong> that suppresses some frequencies and allows others to pass through. In the example of the Prewitt operator, the kernel <code class="docutils literal notranslate"><span class="pre">FK</span></code> has a low value around the center of the image. The product <span class="math notranslate nohighlight">\(FX \cdot FK\)</span> then suppresses the low-frequency components of the image, and we are left with the high-frequency components that correspond to the horizontal edges. We can think of this as a high-pass filter that only allows high-frequency components to pass through.</p>
<p>Let’s see the convolution result.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">FX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft2</span><span class="p">(</span><span class="n">img_gray</span><span class="p">)</span>
<span class="n">conv_img_gray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifft2</span><span class="p">(</span><span class="n">FX</span> <span class="o">*</span> <span class="n">FK</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">conv_img_gray</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>We observe that the horizontal edges are highlighted.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A widespread application of the 2D Fourier transform is JPEG format. Here’s how it works:</p>
<p>(1) It first breaks the image into small 8x8 squares.
(2) It converts each square into frequencies using the Discrete Cosine Transform. The sine part is discarded for compression.
(3) It keeps the important low frequencies that our eyes can see well.
(4) It throws away most of the high frequencies that our eyes don’t notice much.</p>
<p>These steps make the file much smaller while still looking good to us.</p>
</div>
</section>
</section>
<section id="a-key-lesson-from-image-processing">
<h2>A key lesson from image processing<a class="headerlink" href="#a-key-lesson-from-image-processing" title="Link to this heading">#</a></h2>
<p>We have seen an equivalence between convolution in the pixel (spatial) domain and multiplication in the frequency domain.
Using the Fourier transform, an image is decomposed into a sum of basis waves.
The <em>kernel</em> can be thought of as <em>a filter</em> that suppresses some basis waves and allows others to pass through.</p>
<p>This idea is the key to understand graph convolutional networks we will see in the next page.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id147">
<h1>Pen and paper exercises<a class="headerlink" href="#id147" title="Link to this heading">#</a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="#pen-and-paper/exercise.pdf"><span class="xref myst">✍️ Pen and paper exercises</span></a></p></li>
</ul>
<hr class="docutils" />
<section id="id148">
<h2>jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3<a class="headerlink" href="#id148" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="popular-graph-neural-networks">
<h1>Popular Graph Neural Networks<a class="headerlink" href="#popular-graph-neural-networks" title="Link to this heading">#</a></h1>
<p>In this note, we will introduce three popular GNNs: GraphSAGE, Graph Attention Networks (GAT), and Graph Isomorphism Network (GIN).</p>
<section id="graphsage-sample-and-aggregate">
<h2>GraphSAGE: Sample and Aggregate<a class="headerlink" href="#graphsage-sample-and-aggregate" title="Link to this heading">#</a></h2>
<p>GraphSAGE <a class="footnote-reference brackets" href="#footcite-hamilton2017graphsage" id="id149" role="doc-noteref"><span class="fn-bracket">[</span>45<span class="fn-bracket">]</span></a> introduced a different GCN that can be <em><strong>generalized to unseen nodes</strong></em> (they called it “inductive”). While previous approaches like ChebNet and GCN operate on the entire graph, GraphSAGE proposes an inductive framework that generates embeddings by sampling and aggregating features from a node’s neighborhood.</p>
<p><img alt="" src="https://theaisummer.com/static/02e23adc75fe68e5dd249a94f3c1e8cc/c483d/graphsage.png" /></p>
<section id="key-ideas">
<h3>Key Ideas<a class="headerlink" href="#key-ideas" title="Link to this heading">#</a></h3>
<p>GraphSAGE involves two key ideas: (1) sampling and (2) aggregation.</p>
<section id="neighborhood-sampling">
<h4>Neighborhood Sampling<a class="headerlink" href="#neighborhood-sampling" title="Link to this heading">#</a></h4>
<p>The key idea is the <em>neighborhood sampling</em>. Instead of using all neighbors, GraphSAGE samples a fixed-size set of neighbors for each node. This controls memory complexity, a key limitation of the previous GNNs.</p>
<p>Another key advantage of neighborhood sampling is that it enables GraphSAGE to handle dynamic, growing networks. Consider a citation network where new papers (nodes) are continuously added. Traditional GCNs would need to recompute filters for the entire network with each new addition. In contrast, GraphSAGE can immediately generate embeddings for new nodes by simply sampling their neighbors, without any retraining or recomputation.</p>
</section>
<section id="aggregation">
<h4>Aggregation<a class="headerlink" href="#aggregation" title="Link to this heading">#</a></h4>
<p>Another key idea is the <em>aggregation</em>. GraphSAGE makes a distinction between self-information and neighborhood information. While previous GNNs treat them equally and aggregate them, GraphSAGE treats them differently. Specifically, GraphSAGE introduces an additional step: it concatenates the self-information and the neighborhood information as the input of the convolution.</p>
<div class="math notranslate nohighlight">
\[
Z_v = \text{CONCAT}(X_v, X_{\mathcal{N}(v)})
\]</div>
<p>where <span class="math notranslate nohighlight">\(X_v\)</span> is the feature of the node itself and <span class="math notranslate nohighlight">\(X_{\mathcal{N}(v)}\)</span> is the aggregation of the features of its neighbors. GraphSAGE introduces different ways to aggregate information from neighbors:</p>
<div class="math notranslate nohighlight">
\[X_{\mathcal{N}(v)} = \text{AGGREGATE}_k(\{X_u, \forall u \in \mathcal{N}(v)\})\]</div>
<p>Common aggregation functions include:</p>
<ul class="simple">
<li><p>Mean aggregator: <span class="math notranslate nohighlight">\(\text{AGGREGATE} = \text{mean}(\{h_u, \forall u \in \mathcal{N}(v)\})\)</span></p></li>
<li><p>Max-pooling: <span class="math notranslate nohighlight">\(\text{AGGREGATE} = \max(\{\sigma(W_{\text{pool}}h_u + b), \forall u \in \mathcal{N}(v)\})\)</span></p></li>
<li><p>LSTM aggregator: Apply LSTM to randomly permuted neighbors</p></li>
</ul>
<p>The concatenated feature <span class="math notranslate nohighlight">\(Z_v\)</span> is normalized by the L2 norm.</p>
<div class="math notranslate nohighlight">
\[
\hat{Z}_v = \frac{Z_v}{\|Z_v\|_2}
\]</div>
<p>and then fed into the convolution.</p>
<div class="math notranslate nohighlight">
\[
X_v^k = \sigma(W^k \hat{Z}_v + b^k)
\]</div>
</section>
</section>
</section>
<section id="graph-attention-networks-gat-differentiate-individual-neighbors">
<h2>Graph Attention Networks (GAT): Differentiate Individual Neighbors<a class="headerlink" href="#graph-attention-networks-gat-differentiate-individual-neighbors" title="Link to this heading">#</a></h2>
<p>A key innovation of GraphSAGE is to treat the self and neighborhood information differently. But should all neighbors be treated equally? Graph Attention Networks (GAT) address this by letting the model learn which neighbors to pay attention to.</p>
<section id="attention-mechanism">
<h3>Attention Mechanism<a class="headerlink" href="#attention-mechanism" title="Link to this heading">#</a></h3>
<p><img alt="" src="https://production-media.paperswithcode.com/methods/Screen_Shot_2020-07-08_at_7.55.32_PM_vkdDcDx.png" /></p>
<p>The core idea is beautifully simple: instead of using fixed weights like GCN, let’s learn attention weights <span class="math notranslate nohighlight">\(\alpha_{ij}\)</span> that determine how much node <span class="math notranslate nohighlight">\(i\)</span> should attend to node <span class="math notranslate nohighlight">\(j\)</span>. These weights are computed dynamically based on node features:</p>
<div class="math notranslate nohighlight">
\[
\alpha_{ij} = \frac{\exp(e_{ij})}{\sum_{k \in \mathcal{N}(i)} \exp(e_{ik})}
\]</div>
<p>where <span class="math notranslate nohighlight">\(e_{ij}\)</span> represents the importance of the edge between node <span class="math notranslate nohighlight">\(i\)</span> and node <span class="math notranslate nohighlight">\(j\)</span>. Variable <span class="math notranslate nohighlight">\(e_{ij}\)</span> is a <em>learnable</em> parameter and can be negative, and the exponential function is applied to transform it to a non-negative value, with the normalization term <span class="math notranslate nohighlight">\(\sum_{k \in \mathcal{N}(i)} \exp(e_{ik})\)</span> to ensure the weights sum to 1.</p>
<p>How to compute <span class="math notranslate nohighlight">\(e_{ij}\)</span>? One simple choice is to use a neural network with a shared weight matrix <span class="math notranslate nohighlight">\(W\)</span> and a LeakyReLU activation function. Specifically:</p>
<ol class="arabic simple">
<li><p>Let’s focus on computing <span class="math notranslate nohighlight">\(e_{ij}\)</span> for node <span class="math notranslate nohighlight">\(i\)</span> and its neighbor <span class="math notranslate nohighlight">\(j\)</span>.</p></li>
<li><p>We use a shared weight matrix <span class="math notranslate nohighlight">\(W\)</span> to transform the features of node <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>.
$<span class="math notranslate nohighlight">\(
\mathbf{\tilde h}_i  = \mathbf{h}_i, \quad \mathbf{\tilde h}_j  = W\mathbf{h}_j
\)</span>$</p></li>
<li><p>We concatenate the transformed features and apply a LeakyReLU activation function.</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
e_{ij} = \text{LeakyReLU}(\mathbf{a}^T[\mathbf{\tilde h}_i, \mathbf{\tilde h}_j])
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{a}\)</span> is a trainable parameter vector that sums the two transformed features.</p>
<p>Once we have these attention weights, the node update is straightforward - just a weighted sum of neighbor features:</p>
<div class="math notranslate nohighlight">
\[\mathbf{h}'_i = \sigma\left(\sum_{j \in \mathcal{N}(i) \cup \{i\}} \alpha_{ij}{\bf W}_{\text{feature}}\mathbf{h}_j\right)\]</div>
<p>where <span class="math notranslate nohighlight">\({\bf W}_{\text{feature}}\)</span> is a trainable weight matrix. To stabilize training, GAT uses multiple attention heads and concatenates their outputs:</p>
<div class="math notranslate nohighlight">
\[\mathbf{h}'_i = \parallel_{k=1}^K \sigma\left(\sum_{j \in \mathcal{N}(i) \cup \{i\}} \alpha_{ij}^k{\bf W}^k_{\text{feature}}\mathbf{h}_j\right)\]</div>
</section>
</section>
<section id="graph-isomorphism-network-gin-differentiate-the-aggregation">
<h2>Graph Isomorphism Network (GIN): Differentiate the Aggregation<a class="headerlink" href="#graph-isomorphism-network-gin-differentiate-the-aggregation" title="Link to this heading">#</a></h2>
<p>Graph Isomorphism Networks (GIN) is another popular GNN that born out of a question: what is the maximum discriminative power achievable by Graph Neural Networks? The answer lies in its theoretical connection to <strong>the Weisfeiler-Lehman (WL) test</strong>, a powerful algorithm for graph isomorphism testing.</p>
<section id="weisfeiler-lehman-test">
<h3>Weisfeiler-Lehman Test<a class="headerlink" href="#weisfeiler-lehman-test" title="Link to this heading">#</a></h3>
<p>Are two graphs structurally identical? Graph isomorphism testing determines if two graphs are structurally identical, with applications in graph classification, clustering, and other tasks.</p>
<p><img alt="" src="https://i.sstatic.net/j5sGu.png" /></p>
<p>While the general problem has no known polynomial-time solution, the WL test is an efficient heuristic that works well in practice. The WL test iteratively refines node labels by hashing the multiset of neighboring labels</p>
<p><img alt="" src="../_images/weisfeiler-lehman-test.jpg" /></p>
<p>The WL test works as follows:</p>
<ol class="arabic simple">
<li><p>Assign all nodes the same initial label.</p></li>
<li><p>For each node, collect the labels of all its neighbors and <em>aggregate them</em> into a hash (e.g., new label). For example, the top node gets {0} from its neighbors, resulting in a collection {0,0}. A new label is created via a hash function <span class="math notranslate nohighlight">\(h\)</span> that maps {0, {0, 0}} to a new label 1.</p></li>
<li><p>Repeat the process for a fixed number of iterations or until convergence.</p></li>
</ol>
<p>Here is the implementation of the WL test in Python:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">sparse</span>

<span class="k">def</span> <span class="nf">weisfeiler_lehman_test</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">):</span>
    <span class="n">n_nodes</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">color_map</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">hash_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">color_map</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">color_map</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>

        <span class="c1"># Go through each node</span>
        <span class="n">labels_old</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>

            <span class="c1"># Collect the labels of all neighbors</span>
            <span class="n">neighbors</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">neighbor_labels</span> <span class="o">=</span> <span class="n">labels_old</span><span class="p">[</span><span class="n">neighbors</span><span class="p">]</span>

            <span class="c1"># Count the frequency of each label</span>
            <span class="n">unique</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">neighbor_labels</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># Create a hash key by converting the frequency dictionary to a string</span>
            <span class="n">hash_key</span> <span class="o">=</span> <span class="nb">str</span><span class="p">({</span><span class="n">unique</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span> <span class="n">counts</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique</span><span class="p">))})</span>

            <span class="c1"># Create a new label by hashing the frequency dictionary</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">hash_fn</span><span class="p">(</span><span class="n">hash_key</span><span class="p">)</span>
            <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">label</span>

        <span class="c1"># Check convergence</span>
        <span class="n">unique</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">unique_old</span><span class="p">,</span> <span class="n">counts_old</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels_old</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">counts</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">counts_old</span><span class="p">)):</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">labels</span>


<span class="n">edge_list</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)]</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">(</span>
    <span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">edge_list</span><span class="p">),</span> <span class="p">([</span><span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">edge_list</span><span class="p">],</span> <span class="p">[</span><span class="n">e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">edge_list</span><span class="p">])),</span>
    <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">A</span> <span class="o">+</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span>
<span class="n">A</span><span class="o">.</span><span class="n">sort_indices</span><span class="p">()</span>

<span class="n">weisfeiler_lehman_test</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>After these iterations:</p>
<ul class="simple">
<li><p>Nodes with the same label are structurally identical, meaning that they are indistinguishable unless we label them differently.</p></li>
<li><p>Two graphs are structurally identical if and only if they have the same node labels after the WL test.</p></li>
</ul>
<p>The WL test is a heuristic and can fail on some graphs. For example, it cannot distinguish regular graphs with the same number of nodes and edges.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The WL test above is called the 1-WL test. There are higher-order WL tests that can distinguish more graphs, which are the basis of advanced GNNs.
Check out <a class="reference external" href="https://www.moldesk.net/blog/weisfeiler-lehman-isomorphism-test/">this note</a></p>
</div>
</section>
<section id="gin">
<h3>GIN<a class="headerlink" href="#gin" title="Link to this heading">#</a></h3>
<p>GIN <a class="footnote-reference brackets" href="#footcite-xu2018how" id="id150" role="doc-noteref"><span class="fn-bracket">[</span>46<span class="fn-bracket">]</span></a> is a GNN that is based on the WL test.
The key idea is to focus on the parallel between the WL test and the GNN update rule.</p>
<ul class="simple">
<li><p>In the WL test, we iteratively collect the labels of neighbors and aggregate them through a <em>hash function</em>.</p></li>
<li><p>In the GraphSAGE and GAT, the labels are the nodes’ features, and the aggregation is some arithmetic operations such as mean or max.</p></li>
</ul>
<p>The key difference is that the hash function in the WL test always distinguishes different sets of neighbors’ labels, while the aggregation in GraphSAGE and GAT does not always do so. For example, if all nodes have the same feature (e.g., all 1), the aggregation by the mean or max will result in the same value for all nodes, whereas the hash function in the WL test can still distinguish different sets of neighbors’ labels by <em>the count of each label</em>.</p>
<p>The resulting convolution update rule is:</p>
<div class="math notranslate nohighlight">
\[
h_v^{(k+1)} = \text{MLP}^{(k)}\left((1 + \epsilon^{(k)}) \cdot h_v^{(k)} + \sum_{u \in \mathcal{N}(v)} h_u^{(k)}\right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\text{MLP}^{(k)}\)</span> is a multi-layer perceptron (MLP) with <span class="math notranslate nohighlight">\(k\)</span> layers, and <span class="math notranslate nohighlight">\(\epsilon^{(k)}\)</span> is a fixed or trainable parameter.</p>
<div class="docutils container" id="id151">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-hamilton2017graphsage" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id149">45</a><span class="fn-bracket">]</span></span>
<p>William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. In <em>Proceedings of the 31st International Conference on Neural Information Processing Systems</em>, NIPS’17, 1025–1035. Red Hook, NY, USA, 2017. Curran Associates Inc.</p>
</aside>
<aside class="footnote brackets" id="footcite-xu2018how" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id150">46</a><span class="fn-bracket">]</span></span>
<p>Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In <em>International Conference on Learning Representations</em>. 2019. URL: <a class="reference external" href="https://openreview.net/forum?id=ryGs6iA5Km">https://openreview.net/forum?id=ryGs6iA5Km</a>.</p>
</aside>
</aside>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="module-9-graph-neural-networks">
<h1>Module 9: Graph Neural Networks<a class="headerlink" href="#module-9-graph-neural-networks" title="Link to this heading">#</a></h1>
<section id="id152">
<h2>What to learn in this module<a class="headerlink" href="#id152" title="Link to this heading">#</a></h2>
<p>In this module, we will learn how to use neural networks to learn representations of graphs. We will learn:</p>
<ul class="simple">
<li><p>Fourier transform on image</p></li>
<li><p>Fourier transform on graph</p></li>
<li><p>Spectral filters</p></li>
<li><p>Graph convolutional networks</p></li>
<li><p>Popular GNNs (GCN, GAT, GraphSAGE, and GIN)</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "skojaku/adv-net-sci",
            ref: "gh-pages",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tmp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Exercise</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-01">Exercise 01</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-02">Exercise 02</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#edge-counting">Edge counting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pen-and-paper-worksheet">Pen-and-paper worksheet</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-generate-csr-format-from-an-adjacency-matrix">How to generate CSR format from an adjacency matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-use-csr-format-for-efficient-computations">How to use CSR format for efficient computations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#assignment">Assignment</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where-src-trg-and-values-are-lists-of-the-source-nodes-target-nodes-and-edge-weights-respectively">where <code class="docutils literal notranslate"><span class="pre">src</span></code>, <code class="docutils literal notranslate"><span class="pre">trg</span></code>, and <code class="docutils literal notranslate"><span class="pre">values</span></code> are lists of the source nodes, target nodes, and edge weights, respectively.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jupytext-cell-metadata-filter-all-formats-md-myst-text-representation-extension-rmd-format-name-myst-format-version-0-13-jupytext-version-1-16-3-kernelspec-display-name-python-3-ipykernel-language-python-name-python3">jupytext:
cell_metadata_filter: -all
formats: md:myst
text_representation:
extension: .Rmd
format_name: myst
format_version: 0.13
jupytext_version: 1.16.3
kernelspec:
display_name: Python 3 (ipykernel)
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-the-shortest-paths-and-connected-components">Computing the Shortest Paths and Connected Components</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#igraph">igraph</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#create-a-graph">Create a graph</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shortest-paths">Shortest Paths</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#connected-components">Connected Components</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id59">Exercise 01 🏋️‍♀️💪🧠</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#directed-networks">Directed networks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scipy">Scipy</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id60">Create a graph</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id61">Shortest Paths</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id62">Connected Components</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id63">Exercise 02 🏋️‍♀️💪🧠</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hint-finding-all-shortest-paths-is-a-qubic-time-operation-with-respect-to-the-number-of-nodes-or-simply-put-it-takes-a-long-time-to-compute-so-compute-the-estimate-by-sampling-many-pairs-of-nodes-uniformly-at-random-and-computing-the-average-path-length-jupytext-cell-metadata-filter-all-formats-md-myst-text-representation-extension-rmd-format-name-myst-format-version-0-13-jupytext-version-1-16-3-kernelspec-display-name-python-3-ipykernel-language-python-name-python3"><strong>Hint:</strong> Finding all shortest paths is a qubic time operation with respect to the number of nodes, or simply put, it takes a long time to compute. So compute the “estimate” by sampling many pairs of nodes uniformly at random and computing the average path length.—
jupytext:
cell_metadata_filter: -all
formats: md:myst
text_representation:
extension: .Rmd
format_name: myst
format_version: 0.13
jupytext_version: 1.16.3
kernelspec:
display_name: Python 3 (ipykernel)
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#walks-trails-paths-and-connectedness">Walks, Trails, Paths, and Connectedness</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#walks-trails-paths">Walks, Trails, Paths</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#connectedness">Connectedness</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#connectedness-in-directed-networks">Connectedness in directed networks</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#why-is-our-social-network-small-world">Why is our social network small world?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id67">jupytext:
cell_metadata_filter: -all
formats: md:myst
text_representation:
extension: .Rmd
format_name: myst
format_version: 0.13
jupytext_version: 1.16.3
kernelspec:
display_name: Python 3 (ipykernel)
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#small-world-experiment">Small-world experiment</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-criterion-for-the-giant-component">A criterion for the giant component</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-many-nodes-are-needed-to-break-a-network">How many nodes are needed to break a network?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-study-airport-network">Case study: Airport network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#targeted-attacks">Targeted attacks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-design-a-robust-network">How to design a robust network?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#hands-on-robustness-random-attack">Hands-on: Robustness (Random attack)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#robustness-against-random-failures">Robustness against random failures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#targeted-attack">Targeted attack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#while-the-network-is-robust-against-the-random-attacks-it-is-vulnerable-to-the-degree-based-targeted-attack-jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">While the network is robust against the random attacks, it is vulnerable to the degree-based targeted attack.—
jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#network-robustness">Network Robustness</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-node-failures">Random node failures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id74">Targeted attack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#whats-next">What’s next?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#module-3-robustness">Module 3: Robustness</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-to-learn-in-this-module">What to learn in this module</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#degree-distribution">Degree distribution</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization-basics">Visualization basics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coding-exercise">Coding exercise</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plotting-degree-distribution">Plotting degree distribution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#degree-distribution-of-a-friend">Degree distribution of a friend</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plotting-degree-distribution-of-a-friend">Plotting degree distribution of a friend</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modularity-maximization">Modularity maximization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id85">Exercise 01 🏋️‍♀️💪🧠</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stochstic-block-model">Stochstic Block Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id88">Exercise 02 🏋️‍♀️💪🧠</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modularity-demo">Modularity Demo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitation-of-modularity">Limitation of Modularity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#resolution-limit">Resolution limit</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spurious-communities">Spurious communities</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#so-should-we-avoid-modularity">So should we avoid modularity?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-full-modularity-formula-is-on-the-next-page-jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">The full modularity formula is on the next page 😉.—
jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#community-detection-pattern-matching">Community detection (pattern matching)</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pen-and-paper">Pen and Paper</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pen-and-paper-exercise">✍️ <span class="xref myst">Pen and Paper Exercise</span> 🚢</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#balanced-cut">Balanced cut</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ratio-cut">Ratio Cut</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normalized-cut">Normalized cut</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cut-into-more-than-two-communities">Cut into more than two communities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithms-to-find-the-best-cut">Algorithms to find the best cut</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#issue-of-ratio-cut-and-normalized-cut">Issue of Ratio cut and Normalized cut</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#characterizing-network-structures-with-the-sbm">Characterizing network structures with the SBM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-networks-with-sbm">Generating networks with SBM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#detecting-communities-with-sbm">Detecting communities with SBM</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#module-5-clustering">Module 5: Clustering</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id109">What to learn in this module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#harmonic-centrality">Harmonic centrality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eccentricity-centrality">Eccentricity centrality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id111">Eccentricity centrality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#betweenness-centrality">Betweenness centrality</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#katz-centrality">Katz centrality</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pagerank">PageRank</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-katz-centrality">Computing Katz centrality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-optional">Exercise (Optional)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#network-of-ancient-roman-roads">Network of ancient Roman roads</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-data-construct-the-network">Load the data &amp; construct the network</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id113">Exercise 🏛️</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id114">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pen-and-paper-exercises">Pen and paper exercises</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#module-6-centrality">Module 6: Centrality</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id115">What to learn in this module</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ladder-lottery">Ladder Lottery</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id116">Exercise 01</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expected-behavior-of-random-walks">Expected behavior of random walks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id117">Exercise 02</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-03">Exercise 03</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-structure">Community structure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-04">Exercise 04</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id118">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#characteristics-of-random-walks">Characteristics of Random Walks</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stationary-state">Stationary State</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment">Experiment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-to-reach-the-stationary-state">Time to reach the stationary state</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-the-mixing-time">Compute the mixing time</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#normalized-adjacency-matrix">Normalized Adjacency Matrix</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-step-transition-probability">Multi-step Transition Probability</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#relaxation-time-and-mixing-time">Relaxation Time and Mixing Time</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id119">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#random-walks-unify-centrality-and-communities">Random walks unify centrality and communities</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modularity-interpretation-from-random-walk-perspective">Modularity: Interpretation from random walk perspective</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pagerank-interpretation-from-random-walk-perspective">PageRank: Interpretation from random walk perspective</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-generate-random-walks">Step 2: Generate random walks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-train-the-word2vec-model">Step 3: Train the word2vec model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-clustering">Step 4: Clustering</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#node2vec">node2vec</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-02-implement-node2vec">Exercise 02: Implement node2vec</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#line">LINE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modularity-embedding">Modularity embedding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laplacian-eigenmap">Laplacian Eigenmap</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#an-example-for-the-laplacian-eigenmap">An example for the Laplacian Eigenmap</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id130">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-vs-neural-embedding">Spectral vs Neural Embedding</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#module-8-embedding">Module 8: Embedding</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id136">What to learn in this module</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#word2vec">word2vec</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-it-works">How it works</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#whats-special-about-word2vec">What’s special about word2vec?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id139">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">Appendix</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#brunas-spectral-gcn">Bruna’s Spectral GCN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chebnet">ChebNet</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id140">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#from-image-to-graph">From Image to Graph</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analogy-between-image-and-graph-data">Analogy between image and graph data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-filter-on-graphs">Spectral filter on graphs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-filtering">Spectral Filtering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-high-pass-filter-increases-the-contrast-of-the-eigenvector-centrality-emphasizing-the-differences-between-nodes-on-the-other-hand-the-low-pass-filter-smooths-out-the-eigenvector-centrality">The high-pass filter increases the contrast of the eigenvector centrality, emphasizing the differences between nodes. On the other hand, the low-pass filter smooths out the eigenvector centrality.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id141">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-convolutional-networks">Graph Convolutional Networks</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-graph-convolutional-networks">Spectral Graph Convolutional Networks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-spectral-to-spatial">From Spectral to Spatial</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id143">ChebNet</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-convolutional-networks-by-kipf-and-welling">Graph Convolutional Networks by Kipf and Welling</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#first-order-approximation">First-order Approximation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-gcns-can-suffer-from-over-smoothing">Deep GCNs can suffer from over-smoothing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fourier-transform">Fourier Transform</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#an-example-for-the-fourier-transform">An example for the Fourier transform</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fourier-transform-of-images">Fourier Transform of Images</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#an-example-of-fourier-transform">An example of Fourier transform</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-key-lesson-from-image-processing">A key lesson from image processing</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id147">Pen and paper exercises</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id148">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#popular-graph-neural-networks">Popular Graph Neural Networks</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graphsage-sample-and-aggregate">GraphSAGE: Sample and Aggregate</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-ideas">Key Ideas</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#neighborhood-sampling">Neighborhood Sampling</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#aggregation">Aggregation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-attention-networks-gat-differentiate-individual-neighbors">Graph Attention Networks (GAT): Differentiate Individual Neighbors</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#attention-mechanism">Attention Mechanism</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-isomorphism-network-gin-differentiate-the-aggregation">Graph Isomorphism Network (GIN): Differentiate the Aggregation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weisfeiler-lehman-test">Weisfeiler-Lehman Test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gin">GIN</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#module-9-graph-neural-networks">Module 9: Graph Neural Networks</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id152">What to learn in this module</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Sadamori Kojaku
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>