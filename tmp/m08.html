
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Appendix &#8212; Advanced Topics in Network Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tmp/m08';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../home.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.jpg" class="logo__image only-light" alt="Advanced Topics in Network Science - Home"/>
    <script>document.write(`<img src="../_static/logo.jpg" class="logo__image only-dark" alt="Advanced Topics in Network Science - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../home.html">
                    Welcome to SSIE 641 Advanced Topics on Network Science
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Intro</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../intro/why-networks.html">Why should we care networks?</a></li>

<li class="toctree-l1"><a class="reference internal" href="../intro/zoo-of-networks.html">Zoo of networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/setup.html">Trouble shooting</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M01: Euler Tour</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m01-euler_tour/what-to-learn.html">Module 1: Euler Tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-euler_tour/puzzle.html">A puzzle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-euler_tour/euler-path.html">Euler’s solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-euler_tour/how-to-code-network.html">Compute with networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m01-euler_tour/coding-exercise.html">Exercise</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M02: Small World</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/what-to-learn.html">Module 2: Small-world</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/small-world-experiment.html">Small-world experiment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/wikirace.html">Wikirace</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/pen-and-paper.html">Why is our social network small world?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/connectedness.html">Walks, Trails, Paths, and Connectedness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/which-tools.html">Toolbox for network analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/compressed-sparse-row.html">Efficient representation for large sparse networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/connectedness-hands-on.html">Computing the Shortest Paths and Connected Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/assignment.html">Assignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m02-small-world/appendix.html">Appendix</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M03: Robustness</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/what-to-learn.html">Module 3: Robustness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/exercise-power-grid.html">Building a cost-effective power grid network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/minimum-spanning-tree.html">Minimum spanning tree</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/robustness.html">Network Robustness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/robustness-hands-on.html">Hands-on: Robustness (Random attack)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/percolation.html">Percolation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m03-robustness/appendix.html">Appendix</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M04: Friendship Paradox</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m04-friendship-paradox/what-to-learn.html">Module 4: Friendship Paradox</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-friendship-paradox/experiment.html">In-class experiment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-friendship-paradox/friendship-paradox.html">Friendship Paradox</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-friendship-paradox/vaccination-game.html">Vaccination Game</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m04-friendship-paradox/degree-distribution.html">Degree distribution</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M05: Clustering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/what-to-learn.html">Module 5: Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/what-is-community.html">What is community?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/pen-and-paper.html">Pen and Paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/pattern-matching.html">Community detection (pattern matching)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/graph-cut.html">Graph cut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/ratio-normalized-cut.html">Balanced cut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/modularity.html">Modularity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/modularity-02.html">Modularity (Cont.)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/stochastic-block-model.html">Stochastic Block Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m05-clustering/exercise-clustering.html">Hands-on: Clustering</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M06: Centrality</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m06-centrality/what-to-learn.html">Module 6: Centrality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m06-centrality/pen-and-paper.html">Pen and paper exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m06-centrality/degree-distance-based-centrality.html">What is centrality?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m06-centrality/eigencentrality.html">Centralities based on centralities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m06-centrality/hands-on.html">Computing centrality with Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m06-centrality/assignment.html">Assignment</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M07: Random Walks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/what-to-learn.html">Module 7: Random Walks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/amida-kuji.html">Ladder Lottery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/random-walks.html">Random Walks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/pen-and-paper.html">Pen and paper exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/random-walks-code.html">Random Walks in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/random-walks-math.html">Characteristics of Random Walks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m07-random-walks/unifying-centrality-and-communities.html">Random walks unify centrality and communities</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M08: Embedding</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/what-to-learn.html">Module 8: Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/pen-and-paper.html">Pen and paper exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/spectral-embedding.html">Spectral Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/word2vec.html">word2vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/graph-embedding-w-word2vec.html">Graph embedding with word2vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/spectral-vs-neural-embedding.html">Spectral vs Neural Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/software.html">Software for Network Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m08-embedding/appendix.html">Appendix</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">M09: Graph Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/what-to-learn.html">Module 9: Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/pen-and-paper.html">Pen and paper exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/image-processing.html">Preliminaries: Image Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/from-image-to-graph.html">From Image to Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/graph-convolutional-network.html">Graph Convolutional Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/popular-gnn.html">Popular Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../m09-graph-neural-networks/appendix.html">Appendix</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/skojaku/adv-net-sci/gh-pages?urlpath=tree/docs/lecture-note/tmp/m08.md" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/skojaku/adv-net-sci" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/skojaku/adv-net-sci/issues/new?title=Issue%20on%20page%20%2Ftmp/m08.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/tmp/m08.ipynb" target="_blank"
   class="btn btn-sm btn-download-notebook-button dropdown-item"
   title="Download notebook file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li><a href="../_sources/tmp/m08.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Appendix</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Appendix</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-embedding-with-the-adjacency-matrix">Spectral Embedding with the Adjacency Matrix</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-proof-of-the-laplacian-eigenmap">The proof of the Laplacian Eigenmap</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#this-final-form-expresses-our-objective-function-in-terms-of-matrix-operations-which-allows-us-to-use-matrix-calculus-to-find-the-optimal-solution-the-trace-representation-is-a-useful-technique-to-leverage-matrix-calculus-jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">This final form expresses our objective function in terms of matrix operations, which allows us to use matrix calculus to find the optimal solution. The trace representation is a useful technique to leverage matrix calculus.—
jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-embedding-with-word2vec">Graph embedding with word2vec</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deepwalk">DeepWalk</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-01-implement-deepwalk">Exercise 01: Implement DeepWalk</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-data-preparation">Step 1: Data preparation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-generate-random-walks">Step 2: Generate random walks</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-train-the-word2vec-model">Step 3: Train the word2vec model</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-clustering">Step 4: Clustering</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#node2vec">node2vec</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-02-implement-node2vec">Exercise 02: Implement node2vec</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#line">LINE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modularity-embedding">Modularity embedding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laplacian-eigenmap">Laplacian Eigenmap</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#an-example-for-the-laplacian-eigenmap">An example for the Laplacian Eigenmap</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-vs-neural-embedding">Spectral vs Neural Embedding</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#module-8-embedding">Module 8: Embedding</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-to-learn-in-this-module">What to learn in this module</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#word2vec">word2vec</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-it-works">How it works</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#whats-special-about-word2vec">What’s special about word2vec?</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="appendix">
<h1>Appendix<a class="headerlink" href="#appendix" title="Link to this heading">#</a></h1>
<section id="spectral-embedding-with-the-adjacency-matrix">
<h2>Spectral Embedding with the Adjacency Matrix<a class="headerlink" href="#spectral-embedding-with-the-adjacency-matrix" title="Link to this heading">#</a></h2>
<p>The spectral embedding with the adjacency matrix is given by the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[
\min_{\mathbf{U}} J(\mathbf{U}),\quad J(\mathbf{U}) = \| \mathbf{A} - \mathbf{U}\mathbf{U}^\top \|_F^2
\]</div>
<p>We will approach the solution step by step based on the following steps:</p>
<ol class="arabic">
<li><p>We start taking a derivative of <span class="math notranslate nohighlight">\(J(\mathbf{U})\)</span>  with respect to <span class="math notranslate nohighlight">\(\mathbf{U}\)</span>.</p></li>
<li><p>We then set the derivative to zero (i.e., <span class="math notranslate nohighlight">\(\nabla J(\mathbf{U}) = 0\)</span>) and solve for <span class="math notranslate nohighlight">\(\mathbf{U}\)</span>.</p></li>
<li><p>Expand the Frobenius norm:</p>
<p>The Frobenius norm for any matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is defined as:</p>
<p><span class="math notranslate nohighlight">\(\|\mathbf{M}\|_F^2 = \sum_{i,j} M_{ij}^2 = \text{Tr}(\mathbf{M}\mathbf{M}^\top)\)</span></p>
<p>Applying this to our problem:</p>
<p><span class="math notranslate nohighlight">\(J(\mathbf{U}) = \|\mathbf{A} - \mathbf{U}\mathbf{U}^\top\|_F^2 = \text{Tr}[(\mathbf{A} - \mathbf{U}\mathbf{U}^\top)(\mathbf{A} - \mathbf{U}\mathbf{U}^\top)^\top]\)</span></p>
<p>Expanding this:</p>
<p><span class="math notranslate nohighlight">\(= \text{Tr}(\mathbf{A}\mathbf{A}^\top - 2\mathbf{A}\mathbf{U}\mathbf{U}^\top + \mathbf{U}\mathbf{U}^\top\mathbf{U}\mathbf{U}^\top)\)</span></p>
</li>
<li><p>Take the derivative with respect to <span class="math notranslate nohighlight">\(\mathbf{U}\)</span>:</p>
<p>Using matrix calculus rules:</p>
<p><span class="math notranslate nohighlight">\(\frac{\partial \text{Tr}(\mathbf{A}\mathbf{A}^\top)}{\partial \mathbf{U}} = 0\)</span></p>
<p><span class="math notranslate nohighlight">\(\frac{\partial \text{Tr}(\mathbf{A}\mathbf{U}\mathbf{U}^\top)}{\partial \mathbf{U}} = 2\mathbf{A}\mathbf{U}\)</span></p>
<p><span class="math notranslate nohighlight">\(\frac{\partial \text{Tr}(\mathbf{U}\mathbf{U}^\top\mathbf{U}\mathbf{U}^\top)}{\partial \mathbf{U}} = 4\mathbf{U}\mathbf{U}^\top\mathbf{U}\)</span></p>
<p>Combining these:</p>
<p><span class="math notranslate nohighlight">\(\frac{\partial J}{\partial \mathbf{U}} = -4\mathbf{A}\mathbf{U} + 4\mathbf{U}\mathbf{U}^\top\mathbf{U}\)</span></p>
<p>Simplifying:</p>
<p><span class="math notranslate nohighlight">\(\frac{\partial J}{\partial \mathbf{U}} = -2\mathbf{A}\mathbf{U} + 2\mathbf{U}\mathbf{U}^\top\mathbf{U}\)</span></p>
</li>
<li><p>Set the derivative to zero and solve:</p>
<p><span class="math notranslate nohighlight">\(-2\mathbf{A}\mathbf{U} + 2\mathbf{U}\mathbf{U}^\top\mathbf{U} = 0\)</span></p>
<p><span class="math notranslate nohighlight">\(\mathbf{A}\mathbf{U} = \mathbf{U}\mathbf{U}^\top\mathbf{U}\)</span></p>
</li>
<li><p>This equation is satisfied when <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> consists of eigenvectors of <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>:</p>
<p>Assume <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> consists of eigenvectors of <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\mathbf{A}\mathbf{U} = \mathbf{U}\mathbf{\Lambda}\)</span></p>
<p>where <span class="math notranslate nohighlight">\(\mathbf{\Lambda}\)</span> is a diagonal matrix of eigenvalues.</p>
<p>Since eigenvectors are orthonormal:</p>
<p><span class="math notranslate nohighlight">\(\mathbf{U}^\top\mathbf{U} = \mathbf{I}\)</span></p>
<p>Therefore:</p>
<p><span class="math notranslate nohighlight">\(\mathbf{U}\mathbf{U}^\top\mathbf{U} = \mathbf{U}\)</span></p>
<p>This shows our equation is satisfied when <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> consists of eigenvectors of <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>.</p>
</li>
<li><p>To minimize <span class="math notranslate nohighlight">\(J(\mathbf{U})\)</span>, choose the eigenvectors corresponding to the <span class="math notranslate nohighlight">\(d\)</span> largest eigenvalues.</p>
<p>To understand why, consider the trace of our objective function:</p>
<p><span class="math notranslate nohighlight">\(J(\mathbf{U}) = \text{Tr}(\mathbf{A}\mathbf{A}^\top) - 2\text{Tr}(\mathbf{A}\mathbf{U}\mathbf{U}^\top) + \text{Tr}(\mathbf{U}\mathbf{U}^\top\mathbf{U}\mathbf{U}^\top)\)</span></p>
<p>Since <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> is orthogonal (<span class="math notranslate nohighlight">\(\mathbf{U}^\top\mathbf{U} = \mathbf{I}\)</span>), and trace is invariant under cyclic permutations, we can simplify:</p>
<p><span class="math notranslate nohighlight">\(J(\mathbf{U}) = \text{Tr}(\mathbf{A}\mathbf{A}^\top) - \text{Tr}(\mathbf{U}^\top\mathbf{A}\mathbf{U})\)</span></p>
<p>Let <span class="math notranslate nohighlight">\(\mathbf{U} = [\mathbf{u}_1, ..., \mathbf{u}_d]\)</span> be the eigenvectors of <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> with corresponding eigenvalues <span class="math notranslate nohighlight">\(\lambda_1 \geq ... \geq \lambda_d\)</span>. Then:</p>
<p><span class="math notranslate nohighlight">\(\text{Tr}(\mathbf{U}^\top\mathbf{A}\mathbf{U}) = \sum_{i=1}^d \lambda_i\)</span></p>
<p>To minimize <span class="math notranslate nohighlight">\(J(\mathbf{U})\)</span>, maximize <span class="math notranslate nohighlight">\(\sum_{i=1}^d \lambda_i\)</span> by selecting the eigenvectors corresponding to the <span class="math notranslate nohighlight">\(d\)</span> largest eigenvalues.</p>
</li>
</ol>
<p>The result is the collection of the <span class="math notranslate nohighlight">\(d\)</span> eigenvectors corresponding to the <span class="math notranslate nohighlight">\(d\)</span> largest eigenvalues, and it is one form of the spectral embedding.</p>
</section>
<section id="the-proof-of-the-laplacian-eigenmap">
<h2>The proof of the Laplacian Eigenmap<a class="headerlink" href="#the-proof-of-the-laplacian-eigenmap" title="Link to this heading">#</a></h2>
<p>The Laplacian Eigenmap is given by the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[
J_{LE}(\mathbf{U}) = \text{Tr}(\mathbf{U}^\top \mathbf{L} \mathbf{U})
\]</div>
<p>The step where we rewrite <span class="math notranslate nohighlight">\(J_{LE}(\mathbf{U})\)</span> as <span class="math notranslate nohighlight">\(\text{Tr}(\mathbf{U}^\top \mathbf{L} \mathbf{U})\)</span> is crucial for leveraging matrix derivatives. Let’s break down this transformation step by step:</p>
<ol class="arabic">
<li><p>First, we rewrite <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> by column vectors:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
   \mathbf{U} =
   \begin{bmatrix}
   \vert &amp; \vert &amp; &amp; \vert \\
   \mathbf{x}_1 &amp; \mathbf{x}_2 &amp; \cdots &amp; \mathbf{x}_d \\
   \vert &amp; \vert &amp; &amp; \vert
   \end{bmatrix}
   \end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> is the <span class="math notranslate nohighlight">\(i\)</span>-th column of <span class="math notranslate nohighlight">\(\mathbf{U}\)</span>.</p>
</li>
<li><p>We can expand the loss function <span class="math notranslate nohighlight">\(J_{LE}(\mathbf{U})\)</span>:</p>
<div class="math notranslate nohighlight">
\[
   J_{LE}(\mathbf{U}) = \sum_{i} \sum_{j} L_{ij} u_i^\top u_j = \sum_{i} \sum_{j} \sum_{d'} L_{ij} u_{i,d'} u_{j,d'}
   \]</div>
</li>
<li><p>Rearranging the order of summation:</p>
<div class="math notranslate nohighlight">
\[
   J_{LE}(\mathbf{U}) = \sum_{d'} \sum_{i} \sum_{j} L_{ij} u_{i,d'} u_{j,d'}
   \]</div>
</li>
<li><p>We can rewrite this as a matrix multiplication for each <span class="math notranslate nohighlight">\(d'\)</span>:</p>
<div class="math notranslate nohighlight">
\[
   J_{LE}(\mathbf{U}) = \sum_{d'} \mathbf{x}_{d'}^\top \mathbf{L} \mathbf{x}_{d'}
   \]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{x}_{d'}\)</span> is the <span class="math notranslate nohighlight">\(d'\)</span>-th column of <span class="math notranslate nohighlight">\(\mathbf{U}\)</span>.</p>
</li>
<li><p>Finally, we can express this as a trace:</p>
<div class="math notranslate nohighlight">
\[
   J_{LE}(\mathbf{U}) = \text{Tr}(\mathbf{U}^\top \mathbf{L} \mathbf{U})
   \]</div>
</li>
</ol>
</section>
<section id="this-final-form-expresses-our-objective-function-in-terms-of-matrix-operations-which-allows-us-to-use-matrix-calculus-to-find-the-optimal-solution-the-trace-representation-is-a-useful-technique-to-leverage-matrix-calculus-jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">
<h2>This final form expresses our objective function in terms of matrix operations, which allows us to use matrix calculus to find the optimal solution. The trace representation is a useful technique to leverage matrix calculus.—
jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3<a class="headerlink" href="#this-final-form-expresses-our-objective-function-in-terms-of-matrix-operations-which-allows-us-to-use-matrix-calculus-to-find-the-optimal-solution-the-trace-representation-is-a-useful-technique-to-leverage-matrix-calculus-jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="graph-embedding-with-word2vec">
<h1>Graph embedding with word2vec<a class="headerlink" href="#graph-embedding-with-word2vec" title="Link to this heading">#</a></h1>
<p>How can we apply word2vec to graph data? There is a critical challenge: word2vec takes sequence of words as input, while graph data are discrete and unordered. A solution to fill this gap is <em>random walk</em>, which transforms graph data into a sequence of nodes. Once we have a sequence of nodes, we can treat it as a sequence of words and apply word2vec.</p>
<section id="deepwalk">
<h2>DeepWalk<a class="headerlink" href="#deepwalk" title="Link to this heading">#</a></h2>
<p><img alt="" src="https://dt5vp8kor0orz.cloudfront.net/7c56c256b9fbf06693da47737ac57fae803a5a4f/1-Figure1-1.png" /></p>
<p>DeepWalk is one of the pioneering works to apply word2vec to graph data <a class="footnote-reference brackets" href="#footcite-perozzi2014deepwalk" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>. It views the nodes as words and the nodes random walks on the graph as sentences, and applies word2vec to learn the node embeddings.</p>
<p>More specifically, the method contains the following steps:</p>
<ol class="arabic simple">
<li><p>Sample multiple random walks from the graph.</p></li>
<li><p>Treat the random walks as sentences and feed them to word2vev to learn the node embeddings.</p></li>
</ol>
<p>There are some technical details that we need to be aware of, which we will learn by implementing DeepWalk in the following exercise.</p>
<section id="exercise-01-implement-deepwalk">
<h3>Exercise 01: Implement DeepWalk<a class="headerlink" href="#exercise-01-implement-deepwalk" title="Link to this heading">#</a></h3>
<p>In this exercise, we implement DeepWalk step by step.</p>
<section id="step-1-data-preparation">
<h4>Step 1: Data preparation<a class="headerlink" href="#step-1-data-preparation" title="Link to this heading">#</a></h4>
<p>We will use the karate club network as an example.</p>
<p><strong>Load the data</strong></p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">igraph</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">igraph</span><span class="o">.</span><span class="n">Graph</span><span class="o">.</span><span class="n">Famous</span><span class="p">(</span><span class="s2">&quot;Zachary&quot;</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_adjacency_sparse</span><span class="p">()</span>

<span class="c1"># Add the community labels to the nodes for visualization</span>
<span class="n">g</span><span class="o">.</span><span class="n">vs</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;club&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">nx</span><span class="o">.</span><span class="n">karate_club_graph</span><span class="p">()</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">)],</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">palette</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()</span><span class="o">.</span><span class="n">as_hex</span><span class="p">()</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">palette</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">vs</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]],</span> <span class="n">bbox</span><span class="o">=</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">300</span><span class="p">))</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/12eecbf6cebc306afa44a48e5fa2cbcf4b036bfef7a43db6642686bc5ca7b458.svg" src="../_images/12eecbf6cebc306afa44a48e5fa2cbcf4b036bfef7a43db6642686bc5ca7b458.svg" /></div>
</div>
</section>
<section id="step-2-generate-random-walks">
<h4>Step 2: Generate random walks<a class="headerlink" href="#step-2-generate-random-walks" title="Link to this heading">#</a></h4>
<p>Next, we generate the training data for the word2vec model by generating multiple random walks starting from each node in the network.
Let us first implement a function to sample random walks from a given network.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">random_walk</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">start_node</span><span class="p">,</span> <span class="n">walk_length</span><span class="p">):</span>
    <span class="c1"># Initialize the walk with the starting node</span>
    <span class="n">walk</span> <span class="o">=</span> <span class="p">[</span><span class="n">start_node</span><span class="p">]</span>

    <span class="c1"># Continue the walk until the desired length is reached</span>
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">walk</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">walk_length</span><span class="p">:</span>
        <span class="c1"># Get the current node (the last node in the walk)</span>
        <span class="n">cur</span> <span class="o">=</span> <span class="n">walk</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Get the neighbors of the current node</span>
        <span class="n">cur_nbrs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="n">cur</span><span class="p">]</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>

        <span class="c1"># If the current node has neighbors, randomly choose one and add it to the walk</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cur_nbrs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">walk</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">cur_nbrs</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If the current node has no neighbors, terminate the walk</span>
            <span class="k">break</span>

    <span class="c1"># Return the generated walk</span>
    <span class="k">return</span> <span class="n">walk</span>
</pre></div>
</div>
</div>
</div>
<p>Generate 10 random walks of length 50 starting from each node.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">vcount</span><span class="p">()</span>
<span class="n">n_walkers_per_node</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">walk_length</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">walks</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_walkers_per_node</span><span class="p">):</span>
        <span class="n">walks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random_walk</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">walk_length</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-3-train-the-word2vec-model">
<h4>Step 3: Train the word2vec model<a class="headerlink" href="#step-3-train-the-word2vec-model" title="Link to this heading">#</a></h4>
<p>Then, we feed the random walks to the word2vec model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">walks</span><span class="p">,</span> <span class="n">vector_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sg</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hs</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">vector_size</span></code> is the dimension of the embedding vectors.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">window</span></code> indicates the maximum distance between a word and its context words. For example, in the random walk <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">4,</span> <span class="pre">5,</span> <span class="pre">6,</span> <span class="pre">7]</span></code>, the context words of node 2 are <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">3,</span> <span class="pre">4,</span> <span class="pre">5]</span></code> when <code class="docutils literal notranslate"><span class="pre">window=3</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_count</span></code> is the minimum number of times a word must appear in the training data to be included in the vocabulary.</p></li>
</ul>
<p>Two parameters <code class="docutils literal notranslate"><span class="pre">sg=1</span></code> and <code class="docutils literal notranslate"><span class="pre">hs=1</span></code> indicate that we are using the skip-gram model with negative sampling. Let us understand what they mean in detail as follows.</p>
<ul>
<li><p><strong>Skip-gram model</strong>: it trains word2vec by predicting context words given a target word. For example, given the sentence “The quick brown fox jumps over the lazy dog”, in the skip-gram model, given the target word “fox”, the model will try to predict the context words “quick”, “brown”, “jumps”, and “over”. If <code class="docutils literal notranslate"><span class="pre">sg=0</span></code>, the input and output are swapped: the model will predict the target word from the context words, e.g., given the context words “quick”, “brown”, “jumps”, and “over”, the model will predict the target word “fox”.</p></li>
<li><p><strong>Hierarchical softmax</strong>: To understand hierarchical softmax better, let’s break down how the word2vec model works. The goal of word2vec is to predict context words given a target word. For example, if our target word is <span class="math notranslate nohighlight">\(w_t\)</span> and our context word is <span class="math notranslate nohighlight">\(w_c\)</span>, we want to find the probability of <span class="math notranslate nohighlight">\(w_c\)</span> given <span class="math notranslate nohighlight">\(w_t\)</span>. This probability is calculated using the softmax function:</p>
<div class="math notranslate nohighlight">
\[
    P(w_c | w_t) = \frac{\exp(\mathbf{v}_{w_c} \cdot \mathbf{v}_{w_t})}{\sum_{w \in V} \exp(\mathbf{v}_w \cdot \mathbf{u}_{w_t})}
   \]</div>
<p>Here, <span class="math notranslate nohighlight">\(\mathbf{v}_w\)</span> and <span class="math notranslate nohighlight">\(\mathbf{u}_w\)</span> represent the vector for word <span class="math notranslate nohighlight">\(w\)</span> as context and target respectively, and <span class="math notranslate nohighlight">\(V\)</span> is the entire vocabulary. The tricky part is the denominator, which requires summing over all words in the vocabulary. If we have a large vocabulary, this can be very computationally expensive. Imagine having to compute 100,000 exponentials and their sum for each training example if our vocabulary size is 100,000!</p>
<p>Hierarchical softmax helps us solve this problem. Instead of calculating the probability directly, it organizes the vocabulary into a binary tree, where each word is a leaf node. To find the probability of a word, we calculate the product of probabilities along the path from the root to the leaf node. This method significantly reduces the computational complexity. Instead of being proportional to the vocabulary size, it becomes proportional to the logarithm of the vocabulary size. This makes it much more efficient, especially for large vocabularies.</p>
<p><img alt="" src="https://lh5.googleusercontent.com/proxy/_omrC8G6quTl2SGarwFe57qzbIs-PtGkEA5yODFE5I0Ny2IHGiJwsUhMrcuUqg5o-R2nD9hkgMuZsQJKoCggP29zXtj-Vz-X8BE" /></p>
</li>
</ul>
<p>By using the skip-gram model with hierarchical softmax, we can efficiently learn high-quality word embeddings even when dealing with large vocabularies.</p>
<p>Now, we extract the node embeddings from the word2vec model. In the word2vec model, the embeddings are stored in the <code class="docutils literal notranslate"><span class="pre">wv</span></code> attribute. The embedding of node <span class="math notranslate nohighlight">\(i\)</span> is given by <code class="docutils literal notranslate"><span class="pre">model.wv[i]</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedding</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>
    <span class="n">embedding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">embedding</span></code> is the matrix of node embeddings. It has the same number of rows as the number of nodes in the network, and the number of columns is the embedding dimension.</p>
<p><strong>Print the first 3 nodes</strong></p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedding</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 0.01678497, -0.5239678 ,  0.32023966,  0.21805006,  0.2164143 ,
        -0.27861813, -0.02879594,  0.02040694, -0.09389409,  0.14902991,
        -0.16408958, -0.03617975,  0.4401793 , -0.35043442, -0.45231742,
         0.04291442, -0.00438697,  0.48689452, -0.07693247,  0.32646155,
         0.05509297,  0.21733624,  0.4174972 , -0.2016101 , -0.03195512,
         0.1926492 , -0.07621937,  0.4659356 , -0.01767966,  0.17211835,
        -0.15726405,  0.05359379],
       [ 0.14436427, -0.26983833,  0.2742269 ,  0.30298975,  0.14139743,
        -0.17432429,  0.08383631,  0.20290798, -0.01213051,  0.2400155 ,
         0.14109647, -0.13901742,  0.3383556 , -0.09652037, -0.44932622,
         0.11788123,  0.03643087,  0.51094425, -0.15395895,  0.3956297 ,
         0.18070522,  0.24323633,  0.4457064 , -0.12430469, -0.02718285,
         0.19830531,  0.06656086,  0.29218495, -0.20320219,  0.04566523,
        -0.20156367, -0.17775823],
       [-0.02482166, -0.2890486 ,  0.2247368 ,  0.20726605,  0.05092304,
        -0.12687826,  0.12855919,  0.02552663, -0.04155348,  0.10190812,
         0.04597047, -0.12262525,  0.12649862,  0.02535425, -0.31643322,
        -0.10590257, -0.24508078,  0.4951263 , -0.06227927,  0.26300848,
         0.29320967,  0.40486252,  0.5075003 , -0.14288379,  0.08734894,
         0.08722952, -0.02904344,  0.03688772, -0.21114765, -0.11351263,
        -0.38147125, -0.23384489]], dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>Let’s visualize the node embeddings using UMAP.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">umap</span>
<span class="kn">from</span> <span class="nn">bokeh.plotting</span> <span class="kn">import</span> <span class="n">figure</span><span class="p">,</span> <span class="n">show</span>
<span class="kn">from</span> <span class="nn">bokeh.io</span> <span class="kn">import</span> <span class="n">output_notebook</span>
<span class="kn">from</span> <span class="nn">bokeh.models</span> <span class="kn">import</span> <span class="n">ColumnDataSource</span><span class="p">,</span> <span class="n">HoverTool</span>


<span class="n">reducer</span> <span class="o">=</span> <span class="n">umap</span><span class="o">.</span><span class="n">UMAP</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">)</span>
<span class="n">xy</span> <span class="o">=</span> <span class="n">reducer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

<span class="n">output_notebook</span><span class="p">()</span>

<span class="c1"># Calculate the degree of each node</span>
<span class="n">degrees</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">A1</span>

<span class="n">source</span> <span class="o">=</span> <span class="n">ColumnDataSource</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">size</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">degrees</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">degrees</span><span class="p">))</span> <span class="o">*</span> <span class="mi">30</span><span class="p">,</span>
    <span class="n">community</span><span class="o">=</span><span class="p">[</span><span class="n">palette</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">vs</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]]</span>
<span class="p">))</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">figure</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Node Embeddings from Word2Vec&quot;</span><span class="p">,</span> <span class="n">x_axis_label</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">y_axis_label</span><span class="o">=</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>

<span class="n">p</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span> <span class="n">line_color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;community&quot;</span><span class="p">)</span>

<span class="n">show</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/skojaku-admin/miniforge3/envs/advnetsci/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/skojaku-admin/miniforge3/envs/advnetsci/lib/python3.11/site-packages/umap/umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(f&quot;n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.&quot;)
</pre></div>
</div>
<div class="output text_html">    <style>
        .bk-notebook-logo {
            display: block;
            width: 20px;
            height: 20px;
            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);
        }
    </style>
    <div>
        <a href="https://bokeh.org" target="_blank" class="bk-notebook-logo"></a>
        <span id="c34a37a9-41af-4c9c-983d-baf3d7f3edb7">Loading BokehJS ...</span>
    </div>
</div><script type="application/javascript">'use strict';
(function(root) {
  function now() {
    return new Date();
  }

  const force = true;

  if (typeof root._bokeh_onload_callbacks === "undefined" || force === true) {
    root._bokeh_onload_callbacks = [];
    root._bokeh_is_loading = undefined;
  }

const JS_MIME_TYPE = 'application/javascript';
  const HTML_MIME_TYPE = 'text/html';
  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';
  const CLASS_NAME = 'output_bokeh rendered_html';

  /**
   * Render data to the DOM node
   */
  function render(props, node) {
    const script = document.createElement("script");
    node.appendChild(script);
  }

  /**
   * Handle when an output is cleared or removed
   */
  function handleClearOutput(event, handle) {
    function drop(id) {
      const view = Bokeh.index.get_by_id(id)
      if (view != null) {
        view.model.document.clear()
        Bokeh.index.delete(view)
      }
    }

    const cell = handle.cell;

    const id = cell.output_area._bokeh_element_id;
    const server_id = cell.output_area._bokeh_server_id;

    // Clean up Bokeh references
    if (id != null) {
      drop(id)
    }

    if (server_id !== undefined) {
      // Clean up Bokeh references
      const cmd_clean = "from bokeh.io.state import curstate; print(curstate().uuid_to_server['" + server_id + "'].get_sessions()[0].document.roots[0]._id)";
      cell.notebook.kernel.execute(cmd_clean, {
        iopub: {
          output: function(msg) {
            const id = msg.content.text.trim()
            drop(id)
          }
        }
      });
      // Destroy server and session
      const cmd_destroy = "import bokeh.io.notebook as ion; ion.destroy_server('" + server_id + "')";
      cell.notebook.kernel.execute(cmd_destroy);
    }
  }

  /**
   * Handle when a new output is added
   */
  function handleAddOutput(event, handle) {
    const output_area = handle.output_area;
    const output = handle.output;

    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only
    if ((output.output_type != "display_data") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {
      return
    }

    const toinsert = output_area.element.find("." + CLASS_NAME.split(' ')[0]);

    if (output.metadata[EXEC_MIME_TYPE]["id"] !== undefined) {
      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];
      // store reference to embed id on output_area
      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE]["id"];
    }
    if (output.metadata[EXEC_MIME_TYPE]["server_id"] !== undefined) {
      const bk_div = document.createElement("div");
      bk_div.innerHTML = output.data[HTML_MIME_TYPE];
      const script_attrs = bk_div.children[0].attributes;
      for (let i = 0; i < script_attrs.length; i++) {
        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);
        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent
      }
      // store reference to server id on output_area
      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE]["server_id"];
    }
  }

  function register_renderer(events, OutputArea) {

    function append_mime(data, metadata, element) {
      // create a DOM node to render to
      const toinsert = this.create_output_subarea(
        metadata,
        CLASS_NAME,
        EXEC_MIME_TYPE
      );
      this.keyboard_manager.register_events(toinsert);
      // Render to node
      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};
      render(props, toinsert[toinsert.length - 1]);
      element.append(toinsert);
      return toinsert
    }

    /* Handle when an output is cleared or removed */
    events.on('clear_output.CodeCell', handleClearOutput);
    events.on('delete.Cell', handleClearOutput);

    /* Handle when a new output is added */
    events.on('output_added.OutputArea', handleAddOutput);

    /**
     * Register the mime type and append_mime function with output_area
     */
    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {
      /* Is output safe? */
      safe: true,
      /* Index of renderer in `output_area.display_order` */
      index: 0
    });
  }

  // register the mime type if in Jupyter Notebook environment and previously unregistered
  if (root.Jupyter !== undefined) {
    const events = require('base/js/events');
    const OutputArea = require('notebook/js/outputarea').OutputArea;

    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {
      register_renderer(events, OutputArea);
    }
  }
  if (typeof (root._bokeh_timeout) === "undefined" || force === true) {
    root._bokeh_timeout = Date.now() + 5000;
    root._bokeh_failed_load = false;
  }

  const NB_LOAD_WARNING = {'data': {'text/html':
     "<div style='background-color: #fdd'>\n"+
     "<p>\n"+
     "BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \n"+
     "may be due to a slow or bad network connection. Possible fixes:\n"+
     "</p>\n"+
     "<ul>\n"+
     "<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\n"+
     "<li>use INLINE resources instead, as so:</li>\n"+
     "</ul>\n"+
     "<code>\n"+
     "from bokeh.resources import INLINE\n"+
     "output_notebook(resources=INLINE)\n"+
     "</code>\n"+
     "</div>"}};

  function display_loaded(error = null) {
    const el = document.getElementById("c34a37a9-41af-4c9c-983d-baf3d7f3edb7");
    if (el != null) {
      const html = (() => {
        if (typeof root.Bokeh === "undefined") {
          if (error == null) {
            return "BokehJS is loading ...";
          } else {
            return "BokehJS failed to load.";
          }
        } else {
          const prefix = `BokehJS ${root.Bokeh.version}`;
          if (error == null) {
            return `${prefix} successfully loaded.`;
          } else {
            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;
          }
        }
      })();
      el.innerHTML = html;

      if (error != null) {
        const wrapper = document.createElement("div");
        wrapper.style.overflow = "auto";
        wrapper.style.height = "5em";
        wrapper.style.resize = "vertical";
        const content = document.createElement("div");
        content.style.fontFamily = "monospace";
        content.style.whiteSpace = "pre-wrap";
        content.style.backgroundColor = "rgb(255, 221, 221)";
        content.textContent = error.stack ?? error.toString();
        wrapper.append(content);
        el.append(wrapper);
      }
    } else if (Date.now() < root._bokeh_timeout) {
      setTimeout(() => display_loaded(error), 100);
    }
  }

  function run_callbacks() {
    try {
      root._bokeh_onload_callbacks.forEach(function(callback) {
        if (callback != null)
          callback();
      });
    } finally {
      delete root._bokeh_onload_callbacks
    }
    console.debug("Bokeh: all callbacks have finished");
  }

  function load_libs(css_urls, js_urls, callback) {
    if (css_urls == null) css_urls = [];
    if (js_urls == null) js_urls = [];

    root._bokeh_onload_callbacks.push(callback);
    if (root._bokeh_is_loading > 0) {
      console.debug("Bokeh: BokehJS is being loaded, scheduling callback at", now());
      return null;
    }
    if (js_urls == null || js_urls.length === 0) {
      run_callbacks();
      return null;
    }
    console.debug("Bokeh: BokehJS not loaded, scheduling load and callback at", now());
    root._bokeh_is_loading = css_urls.length + js_urls.length;

    function on_load() {
      root._bokeh_is_loading--;
      if (root._bokeh_is_loading === 0) {
        console.debug("Bokeh: all BokehJS libraries/stylesheets loaded");
        run_callbacks()
      }
    }

    function on_error(url) {
      console.error("failed to load " + url);
    }

    for (let i = 0; i < css_urls.length; i++) {
      const url = css_urls[i];
      const element = document.createElement("link");
      element.onload = on_load;
      element.onerror = on_error.bind(null, url);
      element.rel = "stylesheet";
      element.type = "text/css";
      element.href = url;
      console.debug("Bokeh: injecting link tag for BokehJS stylesheet: ", url);
      document.body.appendChild(element);
    }

    for (let i = 0; i < js_urls.length; i++) {
      const url = js_urls[i];
      const element = document.createElement('script');
      element.onload = on_load;
      element.onerror = on_error.bind(null, url);
      element.async = false;
      element.src = url;
      console.debug("Bokeh: injecting script tag for BokehJS library: ", url);
      document.head.appendChild(element);
    }
  };

  function inject_raw_css(css) {
    const element = document.createElement("style");
    element.appendChild(document.createTextNode(css));
    document.body.appendChild(element);
  }

  const js_urls = ["https://cdn.bokeh.org/bokeh/release/bokeh-3.6.0.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.0.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.0.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.0.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.6.0.min.js"];
  const css_urls = [];

  const inline_js = [    function(Bokeh) {
      Bokeh.set_log_level("info");
    },
function(Bokeh) {
    }
  ];

  function run_inline_js() {
    if (root.Bokeh !== undefined || force === true) {
      try {
            for (let i = 0; i < inline_js.length; i++) {
      inline_js[i].call(root, root.Bokeh);
    }

      } catch (error) {display_loaded(error);throw error;
      }if (force === true) {
        display_loaded();
      }} else if (Date.now() < root._bokeh_timeout) {
      setTimeout(run_inline_js, 100);
    } else if (!root._bokeh_failed_load) {
      console.log("Bokeh: BokehJS failed to load within specified timeout.");
      root._bokeh_failed_load = true;
    } else if (force !== true) {
      const cell = $(document.getElementById("c34a37a9-41af-4c9c-983d-baf3d7f3edb7")).parents('.cell').data().cell;
      cell.output_area.append_execute_result(NB_LOAD_WARNING)
    }
  }

  if (root._bokeh_is_loading === 0) {
    console.debug("Bokeh: BokehJS loaded, going straight to plotting");
    run_inline_js();
  } else {
    load_libs(css_urls, js_urls, function() {
      console.debug("Bokeh: BokehJS plotting callback run at", now());
      run_inline_js();
    });
  }
}(window));</script><div class="output text_html">
  <div id="f42e0746-78da-4e2f-bf81-d23f5c5f2c86" data-root-id="p1004" style="display: contents;"></div>
</div><script type="application/javascript">(function(root) {
  function embed_document(root) {
  const docs_json = {"f81c9bc5-e4d4-4f5e-9864-0f2a84673741":{"version":"3.6.0","title":"Bokeh Application","roots":[{"type":"object","name":"Figure","id":"p1004","attributes":{"x_range":{"type":"object","name":"DataRange1d","id":"p1005"},"y_range":{"type":"object","name":"DataRange1d","id":"p1006"},"x_scale":{"type":"object","name":"LinearScale","id":"p1014"},"y_scale":{"type":"object","name":"LinearScale","id":"p1015"},"title":{"type":"object","name":"Title","id":"p1007","attributes":{"text":"Node Embeddings from Word2Vec"}},"renderers":[{"type":"object","name":"GlyphRenderer","id":"p1045","attributes":{"data_source":{"type":"object","name":"ColumnDataSource","id":"p1001","attributes":{"selected":{"type":"object","name":"Selection","id":"p1002","attributes":{"indices":[],"line_indices":[]}},"selection_policy":{"type":"object","name":"UnionRenderers","id":"p1003"},"data":{"type":"map","entries":[["x",{"type":"ndarray","array":{"type":"bytes","data":"lOrBP1QWNUBb9kJAtAIpQOhpwcDtYLzAZ7a6wD3lGUDYlLFAOsTAQKqZycAG5+s/dswEQP+JJUCFUY5A7xWVQAwMzcCmsRVApumFQLrHJ0AwqaRA25AAQL3un0DsyfVAFJz/QAdWAUHi3oxAi9T3QNIn7UCK4ZZAA/iiQEW0A0Fdv4tAkiqTQA=="},"shape":[34],"dtype":"float32","order":"little"}],["y",{"type":"ndarray","array":{"type":"bytes","data":"A5DOwA3nzsBLQrrAOsPAwMeWt7+kUdu/PBj6vxq2xcDPblVB3NBXQbZy8b/LQ8rApoa8wGdetsCj+1tBkbpeQQmS2r9w9NrAMu9gQR1t18As4V5BrO3TwMeSWUEdnWJBObBeQULGZkHdYGdBPURmQeC5XkHmrWVBEZRQQeRZYkFRxlVByv9QQQ=="},"shape":[34],"dtype":"float32","order":"little"}],["size",{"type":"ndarray","array":{"type":"bytes","data":"KoRFxLEaPUAgIzRTBdQ1QDhLeIZKAjdAbGSbkZnSMUAfh76ZfTQpQCqERcSxGi1AKoRFxLEaLUAqhEXEsRotQMTOFZYQRTBAgK7LwG+UJEAfh76ZfTQpQCqERcSxGh1AgK7LwG+UJEDEzhWWEEUwQICuy8BvlCRAgK7LwG+UJECArsvAb5QkQICuy8BvlCRAgK7LwG+UJEAfh76ZfTQpQICuy8BvlCRAgK7LwG+UJECArsvAb5QkQMTOFZYQRTBAH4e+mX00KUAfh76ZfTQpQICuy8BvlCRAKoRFxLEaLUAfh76ZfTQpQCqERcSxGi1AKoRFxLEaLUBsZJuRmdIxQB+Hvpl9NDlAAAAAAAAAPkA="},"shape":[34],"dtype":"float64","order":"little"}],["community",["#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#ff7f0e","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#ff7f0e","#1f77b4","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e"]]]}}},"view":{"type":"object","name":"CDSView","id":"p1046","attributes":{"filter":{"type":"object","name":"AllIndices","id":"p1047"}}},"glyph":{"type":"object","name":"Scatter","id":"p1042","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"field","field":"size"},"fill_color":{"type":"field","field":"community"},"hatch_color":{"type":"field","field":"community"}}},"nonselection_glyph":{"type":"object","name":"Scatter","id":"p1043","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"field","field":"size"},"line_alpha":{"type":"value","value":0.1},"fill_color":{"type":"field","field":"community"},"fill_alpha":{"type":"value","value":0.1},"hatch_color":{"type":"field","field":"community"},"hatch_alpha":{"type":"value","value":0.1}}},"muted_glyph":{"type":"object","name":"Scatter","id":"p1044","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"field","field":"size"},"line_alpha":{"type":"value","value":0.2},"fill_color":{"type":"field","field":"community"},"fill_alpha":{"type":"value","value":0.2},"hatch_color":{"type":"field","field":"community"},"hatch_alpha":{"type":"value","value":0.2}}}}}],"toolbar":{"type":"object","name":"Toolbar","id":"p1013","attributes":{"tools":[{"type":"object","name":"PanTool","id":"p1026"},{"type":"object","name":"WheelZoomTool","id":"p1027","attributes":{"renderers":"auto"}},{"type":"object","name":"BoxZoomTool","id":"p1028","attributes":{"overlay":{"type":"object","name":"BoxAnnotation","id":"p1029","attributes":{"syncable":false,"line_color":"black","line_alpha":1.0,"line_width":2,"line_dash":[4,4],"fill_color":"lightgrey","fill_alpha":0.5,"level":"overlay","visible":false,"left":{"type":"number","value":"nan"},"right":{"type":"number","value":"nan"},"top":{"type":"number","value":"nan"},"bottom":{"type":"number","value":"nan"},"left_units":"canvas","right_units":"canvas","top_units":"canvas","bottom_units":"canvas","handles":{"type":"object","name":"BoxInteractionHandles","id":"p1035","attributes":{"all":{"type":"object","name":"AreaVisuals","id":"p1034","attributes":{"fill_color":"white","hover_fill_color":"lightgray"}}}}}}}},{"type":"object","name":"SaveTool","id":"p1036"},{"type":"object","name":"ResetTool","id":"p1037"},{"type":"object","name":"HelpTool","id":"p1038"}]}},"left":[{"type":"object","name":"LinearAxis","id":"p1021","attributes":{"ticker":{"type":"object","name":"BasicTicker","id":"p1022","attributes":{"mantissas":[1,2,5]}},"formatter":{"type":"object","name":"BasicTickFormatter","id":"p1023"},"axis_label":"Y","major_label_policy":{"type":"object","name":"AllLabels","id":"p1024"}}}],"below":[{"type":"object","name":"LinearAxis","id":"p1016","attributes":{"ticker":{"type":"object","name":"BasicTicker","id":"p1017","attributes":{"mantissas":[1,2,5]}},"formatter":{"type":"object","name":"BasicTickFormatter","id":"p1018"},"axis_label":"X","major_label_policy":{"type":"object","name":"AllLabels","id":"p1019"}}}],"center":[{"type":"object","name":"Grid","id":"p1020","attributes":{"axis":{"id":"p1016"}}},{"type":"object","name":"Grid","id":"p1025","attributes":{"dimension":1,"axis":{"id":"p1021"}}}]}}]}};
  const render_items = [{"docid":"f81c9bc5-e4d4-4f5e-9864-0f2a84673741","roots":{"p1004":"f42e0746-78da-4e2f-bf81-d23f5c5f2c86"},"root_ids":["p1004"]}];
  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);
  }
  if (root.Bokeh !== undefined) {
    embed_document(root);
  } else {
    let attempts = 0;
    const timer = setInterval(function(root) {
      if (root.Bokeh !== undefined) {
        clearInterval(timer);
        embed_document(root);
      } else {
        attempts++;
        if (attempts > 100) {
          clearInterval(timer);
          console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
        }
      }
    }, 10, root)
  }
})(window);</script></div>
</div>
</section>
<section id="step-4-clustering">
<h4>Step 4: Clustering<a class="headerlink" href="#step-4-clustering" title="Link to this heading">#</a></h4>
<p>One of the interesting applications with node embeddings is clustering. While we have good community detection methods, like the modularity maximization and stochastic block model, we can use clustering methods from machine learning, such as <span class="math notranslate nohighlight">\(K\)</span>-means and Gaussian mixture model. Let’s see what we can get from the node embeddings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>

<span class="c1"># Determine the optimal number of clusters using the silhouette score</span>
<span class="k">def</span> <span class="nf">Kmeans_with_silhouette</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">n_clusters_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)):</span>
    <span class="n">silhouette_scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Iterate over a range of cluster numbers from 2 to 9</span>
    <span class="k">for</span> <span class="n">n_clusters</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">*</span><span class="n">n_clusters_range</span><span class="p">):</span>
        <span class="c1"># Create a KMeans object with the current number of clusters</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">)</span>

        <span class="c1"># Fit the KMeans model to the embedding data</span>
        <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

        <span class="c1"># Calculate the silhouette score for the current clustering</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>

        <span class="c1"># Append the number of clusters and its corresponding silhouette score to the list</span>
        <span class="n">silhouette_scores</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>

    <span class="c1"># Find the number of clusters that has the highest silhouette score</span>
    <span class="n">optimal_n_clusters</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">silhouette_scores</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Create a KMeans object with the optimal number of clusters</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">optimal_n_clusters</span><span class="p">)</span>

    <span class="c1"># Fit the KMeans model to the embedding data with the optimal number of clusters</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

    <span class="c1"># Return the labels (cluster assignments) for each data point</span>
    <span class="k">return</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">Kmeans_with_silhouette</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()</span><span class="o">.</span><span class="n">as_hex</span><span class="p">()</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">cmap</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">],</span> <span class="n">bbox</span><span class="o">=</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/693839d942541cfded20a0a37b78d2abf9641329f2cb606df31e39e988218a3b.svg" src="../_images/693839d942541cfded20a0a37b78d2abf9641329f2cb606df31e39e988218a3b.svg" /></div>
</div>
</section>
</section>
</section>
<section id="node2vec">
<h2>node2vec<a class="headerlink" href="#node2vec" title="Link to this heading">#</a></h2>
<p>node2vec is a sibling of DeepWalk proposed by <a class="footnote-reference brackets" href="#footcite-grover2016node2vec" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>. Both use word2vec trained on random walks on networks. So, it appears that they are very similar. However, the following two components make them very different.</p>
<ul>
<li><p><strong>Biased random walk</strong>: node2vec uses biased random walks that can move in different directions. The bias walk is parameterized by two parameters, <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(q\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    P(v_{t+1} = x | v_t = v, v_{t-1} = t) \propto
    \begin{cases}
    \frac{1}{p} &amp; \text{if } d(v,t) = 0 \\
    1 &amp; \text{if } d(v,t) = 1 \\
    \frac{1}{q} &amp; \text{if } d(v,t) = 2 \\
    \end{cases}
    \end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(d(v,x)\)</span> is the shortest path distance between node <span class="math notranslate nohighlight">\(v\)</span> and <span class="math notranslate nohighlight">\(x\)</span>. A smaller <span class="math notranslate nohighlight">\(p\)</span> leads to more biased towards the previous node, <span class="math notranslate nohighlight">\(v_{t-1} = t\)</span>. A smaller <span class="math notranslate nohighlight">\(q\)</span> leads to more biased towards the nodes that are further away from the previous node, <span class="math notranslate nohighlight">\(v_{t-1} = t\)</span>.</p>
<p>By adjusting the parameters <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(q\)</span>, we can influence the random walk to behave more like either breadth-first sampling (BFS) or depth-first sampling (DFS).</p>
<ul class="simple">
<li><p><strong>Breadth-First Sampling (BFS)</strong>: This type of sampling explores all the neighbors of a node before moving on to the next level of neighbors. It is useful for capturing community structures within the graph. When we set the parameters to favor BFS, the resulting embeddings will reflect these community structures.</p></li>
<li><p><strong>Depth-First Sampling (DFS)</strong>: This type of sampling goes deep into the graph, exploring as far as possible along each branch before backtracking. It is useful for capturing structural equivalence, where nodes that have similar roles in the graph (even if they are not directly connected) are represented similarly. When we set the parameters to favor DFS, the resulting embeddings will reflect these structural equivalences.</p></li>
</ul>
<p><img alt="" src="https://www.researchgate.net/publication/354654762/figure/fig3/AS:1069013035655173&#64;1631883977008/A-biased-random-walk-procedure-of-node2vec-B-BFS-and-DFS-search-strategies-from-node-u.png" /></p>
<p>The embeddings generated by node2vec can capture different aspects of the graph depending on the sampling strategy used. With BFS, we capture community structures, and with DFS, we capture structural equivalence.</p>
<p><img alt="" src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*nCyF5jFSU5uJVdAPdf-0HA.png" /></p>
</li>
<li><p><strong>Negative sampling</strong>: node2vec uses negative sampling, instead of hierarchical softmax. This difference appears to be minor, but it has significant consequences on the characteristics of the embeddings. This is beyond the scope of this lecture, but you can refer to <a class="footnote-reference brackets" href="#footcite-kojaku2021neurips" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a> and <a class="footnote-reference brackets" href="#footcite-dyer2014notes" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a> for more details.</p></li>
</ul>
<section id="exercise-02-implement-node2vec">
<h3>Exercise 02: Implement node2vec<a class="headerlink" href="#exercise-02-implement-node2vec" title="Link to this heading">#</a></h3>
<p>Let’s implement the biased random walk for node2vec</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">node2vec_random_walk</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">start_node</span><span class="p">,</span> <span class="n">walk_length</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample a random walk starting from start_node.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Initialize the walk with the start_node</span>
    <span class="n">walk</span> <span class="o">=</span> <span class="p">[</span><span class="n">start_node</span><span class="p">]</span>

    <span class="c1"># Continue the walk until it reaches the desired length</span>
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">walk</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">walk_length</span><span class="p">:</span>
        <span class="c1"># Get the current node in the walk</span>
        <span class="n">cur</span> <span class="o">=</span> <span class="n">walk</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Get the neighbors of the current node</span>
        <span class="n">cur_nbrs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="n">cur</span><span class="p">]</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
        <span class="c1"># Check if the current node has any neighbors</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cur_nbrs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># If the walk has just started, randomly choose the next node from the neighbors</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">walk</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">walk</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">cur_nbrs</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Get the previous node in the walk</span>
                <span class="n">prev</span> <span class="o">=</span> <span class="n">walk</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
                <span class="c1"># Use the alias sampling method to choose the next node based on the bias parameters p and q</span>
                <span class="n">next_node</span> <span class="o">=</span> <span class="n">alias_sample</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">cur_nbrs</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
                <span class="c1"># Append the chosen next node to the walk</span>
                <span class="n">walk</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_node</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If the current node has no neighbors, terminate the walk</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">walk</span>

<span class="k">def</span> <span class="nf">alias_sample</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">neighbors</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to sample the next node in the walk.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Implement the logic to sample the next node based on the bias parameters p and q</span>
    <span class="c1"># You can use the formula provided in the instructions to calculate the probabilities</span>
    <span class="c1"># and then sample the next node accordingly.</span>
    <span class="c1"># Initialize an empty list to store the unnormalized probabilities for each neighbor</span>
    <span class="n">unnormalized_probs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Iterate over each neighbor of the current node</span>
    <span class="k">for</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">:</span>
        <span class="c1"># If the neighbor is the same as the previous node in the walk</span>
        <span class="k">if</span> <span class="n">neighbor</span> <span class="o">==</span> <span class="n">prev</span><span class="p">:</span>
            <span class="c1"># Append the probability 1/p to the unnormalized probabilities list</span>
            <span class="n">unnormalized_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">p</span><span class="p">)</span>
        <span class="c1"># If the neighbor is connected to the previous node in the walk</span>
        <span class="k">elif</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="n">net</span><span class="p">[</span><span class="n">prev</span><span class="p">]</span><span class="o">.</span><span class="n">indices</span><span class="p">:</span>
            <span class="c1"># Append the probability 1 to the unnormalized probabilities list</span>
            <span class="n">unnormalized_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># If the neighbor is not connected to the previous node in the walk</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Append the probability 1/q to the unnormalized probabilities list</span>
            <span class="n">unnormalized_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">q</span><span class="p">)</span>

    <span class="c1"># Calculate the normalization constant by summing all unnormalized probabilities</span>
    <span class="n">norm_const</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">unnormalized_probs</span><span class="p">)</span>

    <span class="c1"># Normalize the probabilities by dividing each unnormalized probability by the normalization constant</span>
    <span class="n">normalized_probs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span> <span class="o">/</span> <span class="n">norm_const</span> <span class="k">for</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">unnormalized_probs</span><span class="p">]</span>

    <span class="c1"># Randomly choose the next node from the neighbors based on the normalized probabilities</span>
    <span class="n">next_node</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">normalized_probs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Return the chosen next node</span>
    <span class="k">return</span> <span class="n">next_node</span>
</pre></div>
</div>
</div>
</div>
<p>Now, let’s set up the word2vec model for node2vec.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">walks</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">q</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_walkers_per_node</span><span class="p">):</span>
        <span class="n">walks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node2vec_random_walk</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">walk_length</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">))</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">walks</span><span class="p">,</span> <span class="n">vector_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sg</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hs</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">hs=0</span></code> indicates that we are using negative sampling.
Notice that we set <code class="docutils literal notranslate"><span class="pre">sg=1</span></code> and <code class="docutils literal notranslate"><span class="pre">hs=1</span></code> instead of <code class="docutils literal notranslate"><span class="pre">sg=1</span></code> and <code class="docutils literal notranslate"><span class="pre">hs=0</span></code> in DeepWalk. This is because node2vec uses the skip-gram model with negative sampling.</p>
<p>Now, we extract the node embeddings from the word2vec model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedding</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>
    <span class="n">embedding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s visualize the node embeddings from node2vec.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reducer</span> <span class="o">=</span> <span class="n">umap</span><span class="o">.</span><span class="n">UMAP</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">)</span>
<span class="n">xy</span> <span class="o">=</span> <span class="n">reducer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

<span class="n">output_notebook</span><span class="p">()</span>

<span class="c1"># Calculate the degree of each node</span>
<span class="n">degrees</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">A1</span>

<span class="n">source</span> <span class="o">=</span> <span class="n">ColumnDataSource</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">size</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">degrees</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">degrees</span><span class="p">))</span> <span class="o">*</span> <span class="mi">30</span><span class="p">,</span>
    <span class="n">community</span><span class="o">=</span><span class="p">[</span><span class="n">palette</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">vs</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]],</span>
    <span class="n">name</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">)]</span>
<span class="p">))</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">figure</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Node Embeddings from Word2Vec&quot;</span><span class="p">,</span> <span class="n">x_axis_label</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">y_axis_label</span><span class="o">=</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>

<span class="n">p</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span> <span class="n">line_color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;community&quot;</span><span class="p">)</span>

<span class="n">hover</span> <span class="o">=</span> <span class="n">HoverTool</span><span class="p">()</span>
<span class="n">hover</span><span class="o">.</span><span class="n">tooltips</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;Name&quot;</span><span class="p">,</span> <span class="s2">&quot;@name&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Community&quot;</span><span class="p">,</span> <span class="s2">&quot;@community&quot;</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">p</span><span class="o">.</span><span class="n">add_tools</span><span class="p">(</span><span class="n">hover</span><span class="p">)</span>

<span class="n">show</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/skojaku-admin/miniforge3/envs/advnetsci/lib/python3.11/site-packages/umap/umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(f&quot;n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.&quot;)
</pre></div>
</div>
<div class="output text_html">    <style>
        .bk-notebook-logo {
            display: block;
            width: 20px;
            height: 20px;
            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);
        }
    </style>
    <div>
        <a href="https://bokeh.org" target="_blank" class="bk-notebook-logo"></a>
        <span id="eb8815e8-9a59-4406-96b5-67e52c7c574d">Loading BokehJS ...</span>
    </div>
</div><script type="application/javascript">'use strict';
(function(root) {
  function now() {
    return new Date();
  }

  const force = true;

  if (typeof root._bokeh_onload_callbacks === "undefined" || force === true) {
    root._bokeh_onload_callbacks = [];
    root._bokeh_is_loading = undefined;
  }

const JS_MIME_TYPE = 'application/javascript';
  const HTML_MIME_TYPE = 'text/html';
  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';
  const CLASS_NAME = 'output_bokeh rendered_html';

  /**
   * Render data to the DOM node
   */
  function render(props, node) {
    const script = document.createElement("script");
    node.appendChild(script);
  }

  /**
   * Handle when an output is cleared or removed
   */
  function handleClearOutput(event, handle) {
    function drop(id) {
      const view = Bokeh.index.get_by_id(id)
      if (view != null) {
        view.model.document.clear()
        Bokeh.index.delete(view)
      }
    }

    const cell = handle.cell;

    const id = cell.output_area._bokeh_element_id;
    const server_id = cell.output_area._bokeh_server_id;

    // Clean up Bokeh references
    if (id != null) {
      drop(id)
    }

    if (server_id !== undefined) {
      // Clean up Bokeh references
      const cmd_clean = "from bokeh.io.state import curstate; print(curstate().uuid_to_server['" + server_id + "'].get_sessions()[0].document.roots[0]._id)";
      cell.notebook.kernel.execute(cmd_clean, {
        iopub: {
          output: function(msg) {
            const id = msg.content.text.trim()
            drop(id)
          }
        }
      });
      // Destroy server and session
      const cmd_destroy = "import bokeh.io.notebook as ion; ion.destroy_server('" + server_id + "')";
      cell.notebook.kernel.execute(cmd_destroy);
    }
  }

  /**
   * Handle when a new output is added
   */
  function handleAddOutput(event, handle) {
    const output_area = handle.output_area;
    const output = handle.output;

    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only
    if ((output.output_type != "display_data") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {
      return
    }

    const toinsert = output_area.element.find("." + CLASS_NAME.split(' ')[0]);

    if (output.metadata[EXEC_MIME_TYPE]["id"] !== undefined) {
      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];
      // store reference to embed id on output_area
      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE]["id"];
    }
    if (output.metadata[EXEC_MIME_TYPE]["server_id"] !== undefined) {
      const bk_div = document.createElement("div");
      bk_div.innerHTML = output.data[HTML_MIME_TYPE];
      const script_attrs = bk_div.children[0].attributes;
      for (let i = 0; i < script_attrs.length; i++) {
        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);
        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent
      }
      // store reference to server id on output_area
      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE]["server_id"];
    }
  }

  function register_renderer(events, OutputArea) {

    function append_mime(data, metadata, element) {
      // create a DOM node to render to
      const toinsert = this.create_output_subarea(
        metadata,
        CLASS_NAME,
        EXEC_MIME_TYPE
      );
      this.keyboard_manager.register_events(toinsert);
      // Render to node
      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};
      render(props, toinsert[toinsert.length - 1]);
      element.append(toinsert);
      return toinsert
    }

    /* Handle when an output is cleared or removed */
    events.on('clear_output.CodeCell', handleClearOutput);
    events.on('delete.Cell', handleClearOutput);

    /* Handle when a new output is added */
    events.on('output_added.OutputArea', handleAddOutput);

    /**
     * Register the mime type and append_mime function with output_area
     */
    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {
      /* Is output safe? */
      safe: true,
      /* Index of renderer in `output_area.display_order` */
      index: 0
    });
  }

  // register the mime type if in Jupyter Notebook environment and previously unregistered
  if (root.Jupyter !== undefined) {
    const events = require('base/js/events');
    const OutputArea = require('notebook/js/outputarea').OutputArea;

    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {
      register_renderer(events, OutputArea);
    }
  }
  if (typeof (root._bokeh_timeout) === "undefined" || force === true) {
    root._bokeh_timeout = Date.now() + 5000;
    root._bokeh_failed_load = false;
  }

  const NB_LOAD_WARNING = {'data': {'text/html':
     "<div style='background-color: #fdd'>\n"+
     "<p>\n"+
     "BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \n"+
     "may be due to a slow or bad network connection. Possible fixes:\n"+
     "</p>\n"+
     "<ul>\n"+
     "<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\n"+
     "<li>use INLINE resources instead, as so:</li>\n"+
     "</ul>\n"+
     "<code>\n"+
     "from bokeh.resources import INLINE\n"+
     "output_notebook(resources=INLINE)\n"+
     "</code>\n"+
     "</div>"}};

  function display_loaded(error = null) {
    const el = document.getElementById("eb8815e8-9a59-4406-96b5-67e52c7c574d");
    if (el != null) {
      const html = (() => {
        if (typeof root.Bokeh === "undefined") {
          if (error == null) {
            return "BokehJS is loading ...";
          } else {
            return "BokehJS failed to load.";
          }
        } else {
          const prefix = `BokehJS ${root.Bokeh.version}`;
          if (error == null) {
            return `${prefix} successfully loaded.`;
          } else {
            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;
          }
        }
      })();
      el.innerHTML = html;

      if (error != null) {
        const wrapper = document.createElement("div");
        wrapper.style.overflow = "auto";
        wrapper.style.height = "5em";
        wrapper.style.resize = "vertical";
        const content = document.createElement("div");
        content.style.fontFamily = "monospace";
        content.style.whiteSpace = "pre-wrap";
        content.style.backgroundColor = "rgb(255, 221, 221)";
        content.textContent = error.stack ?? error.toString();
        wrapper.append(content);
        el.append(wrapper);
      }
    } else if (Date.now() < root._bokeh_timeout) {
      setTimeout(() => display_loaded(error), 100);
    }
  }

  function run_callbacks() {
    try {
      root._bokeh_onload_callbacks.forEach(function(callback) {
        if (callback != null)
          callback();
      });
    } finally {
      delete root._bokeh_onload_callbacks
    }
    console.debug("Bokeh: all callbacks have finished");
  }

  function load_libs(css_urls, js_urls, callback) {
    if (css_urls == null) css_urls = [];
    if (js_urls == null) js_urls = [];

    root._bokeh_onload_callbacks.push(callback);
    if (root._bokeh_is_loading > 0) {
      console.debug("Bokeh: BokehJS is being loaded, scheduling callback at", now());
      return null;
    }
    if (js_urls == null || js_urls.length === 0) {
      run_callbacks();
      return null;
    }
    console.debug("Bokeh: BokehJS not loaded, scheduling load and callback at", now());
    root._bokeh_is_loading = css_urls.length + js_urls.length;

    function on_load() {
      root._bokeh_is_loading--;
      if (root._bokeh_is_loading === 0) {
        console.debug("Bokeh: all BokehJS libraries/stylesheets loaded");
        run_callbacks()
      }
    }

    function on_error(url) {
      console.error("failed to load " + url);
    }

    for (let i = 0; i < css_urls.length; i++) {
      const url = css_urls[i];
      const element = document.createElement("link");
      element.onload = on_load;
      element.onerror = on_error.bind(null, url);
      element.rel = "stylesheet";
      element.type = "text/css";
      element.href = url;
      console.debug("Bokeh: injecting link tag for BokehJS stylesheet: ", url);
      document.body.appendChild(element);
    }

    for (let i = 0; i < js_urls.length; i++) {
      const url = js_urls[i];
      const element = document.createElement('script');
      element.onload = on_load;
      element.onerror = on_error.bind(null, url);
      element.async = false;
      element.src = url;
      console.debug("Bokeh: injecting script tag for BokehJS library: ", url);
      document.head.appendChild(element);
    }
  };

  function inject_raw_css(css) {
    const element = document.createElement("style");
    element.appendChild(document.createTextNode(css));
    document.body.appendChild(element);
  }

  const js_urls = ["https://cdn.bokeh.org/bokeh/release/bokeh-3.6.0.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.0.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.0.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.0.min.js", "https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.6.0.min.js"];
  const css_urls = [];

  const inline_js = [    function(Bokeh) {
      Bokeh.set_log_level("info");
    },
function(Bokeh) {
    }
  ];

  function run_inline_js() {
    if (root.Bokeh !== undefined || force === true) {
      try {
            for (let i = 0; i < inline_js.length; i++) {
      inline_js[i].call(root, root.Bokeh);
    }

      } catch (error) {display_loaded(error);throw error;
      }if (force === true) {
        display_loaded();
      }} else if (Date.now() < root._bokeh_timeout) {
      setTimeout(run_inline_js, 100);
    } else if (!root._bokeh_failed_load) {
      console.log("Bokeh: BokehJS failed to load within specified timeout.");
      root._bokeh_failed_load = true;
    } else if (force !== true) {
      const cell = $(document.getElementById("eb8815e8-9a59-4406-96b5-67e52c7c574d")).parents('.cell').data().cell;
      cell.output_area.append_execute_result(NB_LOAD_WARNING)
    }
  }

  if (root._bokeh_is_loading === 0) {
    console.debug("Bokeh: BokehJS loaded, going straight to plotting");
    run_inline_js();
  } else {
    load_libs(css_urls, js_urls, function() {
      console.debug("Bokeh: BokehJS plotting callback run at", now());
      run_inline_js();
    });
  }
}(window));</script><div class="output text_html">
  <div id="ee8b3342-0881-4386-9715-e4da0419b0bc" data-root-id="p1054" style="display: contents;"></div>
</div><script type="application/javascript">(function(root) {
  function embed_document(root) {
  const docs_json = {"13d586c1-de61-4acb-a688-fdf1dcaf2f35":{"version":"3.6.0","title":"Bokeh Application","roots":[{"type":"object","name":"Figure","id":"p1054","attributes":{"x_range":{"type":"object","name":"DataRange1d","id":"p1055"},"y_range":{"type":"object","name":"DataRange1d","id":"p1056"},"x_scale":{"type":"object","name":"LinearScale","id":"p1064"},"y_scale":{"type":"object","name":"LinearScale","id":"p1065"},"title":{"type":"object","name":"Title","id":"p1057","attributes":{"text":"Node Embeddings from Word2Vec"}},"renderers":[{"type":"object","name":"GlyphRenderer","id":"p1095","attributes":{"data_source":{"type":"object","name":"ColumnDataSource","id":"p1051","attributes":{"selected":{"type":"object","name":"Selection","id":"p1052","attributes":{"indices":[],"line_indices":[]}},"selection_policy":{"type":"object","name":"UnionRenderers","id":"p1053"},"data":{"type":"map","entries":[["x",{"type":"ndarray","array":{"type":"bytes","data":"+TbDQM4k2EBvPLhAOcrRQAIPgUDmsXlApFppQLsl5ECm5sNAN9XAQLV4dEAadL9AIxjiQFg1yUAXutVA/ObbQFGqg0AIXtRA+fvHQKKuwUC/qtxA+RzWQI8o0UCM5IJA6vpxQML+aUD8OdVALrNfQGwPo0CoQXpAHvnSQMXpiEDiKcZARVi+QA=="},"shape":[34],"dtype":"float32","order":"little"}],["y",{"type":"ndarray","array":{"type":"bytes","data":"ieRaQHRdi0BIittAP7J0QIHuhb3Ej0e+i8HmvuOmg0CkcqxAM4PjQOQ8jb5xqFFAMMxrQM5MnkAUgQZBgqMAQZz0jjwuY1hAeVUKQUHrjEAH/AhBC4uAQEg++kAGpfhAqyrvQCKF/kDYNw5BTp34QNvO70BelQJBLaKgQGI+7kD0sARBK78AQQ=="},"shape":[34],"dtype":"float32","order":"little"}],["size",{"type":"ndarray","array":{"type":"bytes","data":"KoRFxLEaPUAgIzRTBdQ1QDhLeIZKAjdAbGSbkZnSMUAfh76ZfTQpQCqERcSxGi1AKoRFxLEaLUAqhEXEsRotQMTOFZYQRTBAgK7LwG+UJEAfh76ZfTQpQCqERcSxGh1AgK7LwG+UJEDEzhWWEEUwQICuy8BvlCRAgK7LwG+UJECArsvAb5QkQICuy8BvlCRAgK7LwG+UJEAfh76ZfTQpQICuy8BvlCRAgK7LwG+UJECArsvAb5QkQMTOFZYQRTBAH4e+mX00KUAfh76ZfTQpQICuy8BvlCRAKoRFxLEaLUAfh76ZfTQpQCqERcSxGi1AKoRFxLEaLUBsZJuRmdIxQB+Hvpl9NDlAAAAAAAAAPkA="},"shape":[34],"dtype":"float64","order":"little"}],["community",["#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#1f77b4","#1f77b4","#1f77b4","#ff7f0e","#ff7f0e","#1f77b4","#1f77b4","#ff7f0e","#1f77b4","#ff7f0e","#1f77b4","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e","#ff7f0e"]],["name",["0","1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33"]]]}}},"view":{"type":"object","name":"CDSView","id":"p1096","attributes":{"filter":{"type":"object","name":"AllIndices","id":"p1097"}}},"glyph":{"type":"object","name":"Scatter","id":"p1092","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"field","field":"size"},"fill_color":{"type":"field","field":"community"},"hatch_color":{"type":"field","field":"community"}}},"nonselection_glyph":{"type":"object","name":"Scatter","id":"p1093","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"field","field":"size"},"line_alpha":{"type":"value","value":0.1},"fill_color":{"type":"field","field":"community"},"fill_alpha":{"type":"value","value":0.1},"hatch_color":{"type":"field","field":"community"},"hatch_alpha":{"type":"value","value":0.1}}},"muted_glyph":{"type":"object","name":"Scatter","id":"p1094","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"field","field":"size"},"line_alpha":{"type":"value","value":0.2},"fill_color":{"type":"field","field":"community"},"fill_alpha":{"type":"value","value":0.2},"hatch_color":{"type":"field","field":"community"},"hatch_alpha":{"type":"value","value":0.2}}}}}],"toolbar":{"type":"object","name":"Toolbar","id":"p1063","attributes":{"tools":[{"type":"object","name":"PanTool","id":"p1076"},{"type":"object","name":"WheelZoomTool","id":"p1077","attributes":{"renderers":"auto"}},{"type":"object","name":"BoxZoomTool","id":"p1078","attributes":{"overlay":{"type":"object","name":"BoxAnnotation","id":"p1079","attributes":{"syncable":false,"line_color":"black","line_alpha":1.0,"line_width":2,"line_dash":[4,4],"fill_color":"lightgrey","fill_alpha":0.5,"level":"overlay","visible":false,"left":{"type":"number","value":"nan"},"right":{"type":"number","value":"nan"},"top":{"type":"number","value":"nan"},"bottom":{"type":"number","value":"nan"},"left_units":"canvas","right_units":"canvas","top_units":"canvas","bottom_units":"canvas","handles":{"type":"object","name":"BoxInteractionHandles","id":"p1085","attributes":{"all":{"type":"object","name":"AreaVisuals","id":"p1084","attributes":{"fill_color":"white","hover_fill_color":"lightgray"}}}}}}}},{"type":"object","name":"SaveTool","id":"p1086"},{"type":"object","name":"ResetTool","id":"p1087"},{"type":"object","name":"HelpTool","id":"p1088"},{"type":"object","name":"HoverTool","id":"p1098","attributes":{"renderers":"auto","tooltips":[["Name","@name"],["Community","@community"]]}}]}},"left":[{"type":"object","name":"LinearAxis","id":"p1071","attributes":{"ticker":{"type":"object","name":"BasicTicker","id":"p1072","attributes":{"mantissas":[1,2,5]}},"formatter":{"type":"object","name":"BasicTickFormatter","id":"p1073"},"axis_label":"Y","major_label_policy":{"type":"object","name":"AllLabels","id":"p1074"}}}],"below":[{"type":"object","name":"LinearAxis","id":"p1066","attributes":{"ticker":{"type":"object","name":"BasicTicker","id":"p1067","attributes":{"mantissas":[1,2,5]}},"formatter":{"type":"object","name":"BasicTickFormatter","id":"p1068"},"axis_label":"X","major_label_policy":{"type":"object","name":"AllLabels","id":"p1069"}}}],"center":[{"type":"object","name":"Grid","id":"p1070","attributes":{"axis":{"id":"p1066"}}},{"type":"object","name":"Grid","id":"p1075","attributes":{"dimension":1,"axis":{"id":"p1071"}}}]}}]}};
  const render_items = [{"docid":"13d586c1-de61-4acb-a688-fdf1dcaf2f35","roots":{"p1054":"ee8b3342-0881-4386-9715-e4da0419b0bc"},"root_ids":["p1054"]}];
  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);
  }
  if (root.Bokeh !== undefined) {
    embed_document(root);
  } else {
    let attempts = 0;
    const timer = setInterval(function(root) {
      if (root.Bokeh !== undefined) {
        clearInterval(timer);
        embed_document(root);
      } else {
        attempts++;
        if (attempts > 100) {
          clearInterval(timer);
          console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
        }
      }
    }, 10, root)
  }
})(window);</script></div>
</div>
<p>The results for clustering are as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">labels</span> <span class="o">=</span> <span class="n">Kmeans_with_silhouette</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>


<span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()</span><span class="o">.</span><span class="n">as_hex</span><span class="p">()</span>
<span class="n">igraph</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vertex_color</span><span class="o">=</span><span class="p">[</span><span class="n">cmap</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">],</span> <span class="n">bbox</span><span class="o">=</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span> <span class="n">vertex_label</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span>  <span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span>  <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/5d5d590b381bbc13dbe7b45c6e85dfb0135f4b0c14b10e9b400c4bf4442c1d0c.svg" src="../_images/5d5d590b381bbc13dbe7b45c6e85dfb0135f4b0c14b10e9b400c4bf4442c1d0c.svg" /></div>
</div>
</section>
</section>
<section id="line">
<h2>LINE<a class="headerlink" href="#line" title="Link to this heading">#</a></h2>
<p>LINE <a class="footnote-reference brackets" href="#footcite-tang2015line" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a> is another pioneering work to learn node embeddings by directly optimizing the graph structure.
It is equivalent to node2vec with <span class="math notranslate nohighlight">\(p=1\)</span>, <span class="math notranslate nohighlight">\(q=1\)</span>, and window size 1.</p>
<div class="docutils container" id="id6">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-perozzi2014deepwalk" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: online learning of social representations. In <em>Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</em>, 701–710. 2014.</p>
</aside>
<aside class="footnote brackets" id="footcite-grover2016node2vec" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Aditya Grover and Jure Leskovec. Node2vec: scalable feature learning for networks. In <em>Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</em>, 855–864. 2016.</p>
</aside>
<aside class="footnote brackets" id="footcite-kojaku2021neurips" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>Sadamori Kojaku, Jisung Yoon, Isabel Constantino, and Yong-Yeol Ahn. Residual2vec: debiasing graph embedding using random graphs. In <em>Advances in Neural Information Processing Systems</em>, volume. Curran Associates, Inc., 2021.</p>
</aside>
<aside class="footnote brackets" id="footcite-dyer2014notes" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">4</a><span class="fn-bracket">]</span></span>
<p>Chris Dyer. Notes on noise contrastive estimation and negative sampling. <em>arXiv preprint arXiv:1410.8251</em>, 2014.</p>
</aside>
<aside class="footnote brackets" id="footcite-tang2015line" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">5</a><span class="fn-bracket">]</span></span>
<p>Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. Line: large-scale information network embedding. In <em>Proceedings of the 24th International Conference on World Wide Web</em>, WWW ‘15, 1067–1077. Republic and Canton of Geneva, CHE, 2015. International World Wide Web Conferences Steering Committee. URL: <a class="reference external" href="https://doi.org/10.1145/2736277.2741093">https://doi.org/10.1145/2736277.2741093</a>, <a class="reference external" href="https://doi.org/10.1145/2736277.2741093">doi:10.1145/2736277.2741093</a>.</p>
</aside>
</aside>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute the spectral decomposition</span>
<span class="n">eigvals</span><span class="p">,</span> <span class="n">eigvecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="c1"># Find the top d eigenvectors</span>
<span class="n">d</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">eigvals</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">d</span><span class="p">]</span>
<span class="n">eigvals</span> <span class="o">=</span> <span class="n">eigvals</span><span class="p">[</span><span class="n">sorted_indices</span><span class="p">]</span>
<span class="n">eigvecs</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="n">sorted_indices</span><span class="p">]</span>

<span class="c1"># Plot the results</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Spectral Embedding&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Eigenvector 1&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Eigenvector 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">LinAlgError</span><span class="g g-Whitespace">                               </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">15</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Compute the spectral decomposition</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">eigvals</span><span class="p">,</span> <span class="n">eigvecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="c1"># Find the top d eigenvectors</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">d</span> <span class="o">=</span> <span class="mi">2</span>

<span class="nn">File &lt;__array_function__ internals&gt;:180,</span> in <span class="ni">eig</span><span class="nt">(*args, **kwargs)</span>

<span class="nn">File ~/miniforge3/envs/advnetsci/lib/python3.11/site-packages/numpy/linalg/linalg.py:1310,</span> in <span class="ni">eig</span><span class="nt">(a)</span>
<span class="g g-Whitespace">   </span><span class="mi">1184</span><span class="w"> </span><span class="sd">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1185</span><span class="sd"> Compute the eigenvalues and right eigenvectors of a square array.</span>
<span class="g g-Whitespace">   </span><span class="mi">1186</span><span class="sd"> </span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">   </span><span class="mi">1307</span><span class="sd"> </span>
<span class="g g-Whitespace">   </span><span class="mi">1308</span><span class="sd"> &quot;&quot;&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1309</span> <span class="n">a</span><span class="p">,</span> <span class="n">wrap</span> <span class="o">=</span> <span class="n">_makearray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1310</span> <span class="n">_assert_stacked_2d</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1311</span> <span class="n">_assert_stacked_square</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1312</span> <span class="n">_assert_finite</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="nn">File ~/miniforge3/envs/advnetsci/lib/python3.11/site-packages/numpy/linalg/linalg.py:197,</span> in <span class="ni">_assert_stacked_2d</span><span class="nt">(*arrays)</span>
<span class="g g-Whitespace">    </span><span class="mi">195</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">arrays</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">196</span>     <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">197</span>         <span class="k">raise</span> <span class="n">LinAlgError</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%d</span><span class="s1">-dimensional array given. Array must be &#39;</span>
<span class="g g-Whitespace">    </span><span class="mi">198</span>                 <span class="s1">&#39;at least two-dimensional&#39;</span> <span class="o">%</span> <span class="n">a</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>

<span class="ne">LinAlgError</span>: 0-dimensional array given. Array must be at least two-dimensional
</pre></div>
</div>
</div>
</div>
<p>Interestingly, the first eigenvector corresponds to the eigen centrality of the network, representing the centrality of the nodes.
The second eigenvector captures the community structure of the network, clearly separating the two communities in the network.</p>
</section>
<section id="modularity-embedding">
<h2>Modularity embedding<a class="headerlink" href="#modularity-embedding" title="Link to this heading">#</a></h2>
<p>In a similar vein, we can use the modularity matrix to generate a low-dimensional embedding of the network.
Namely, let us define the modularity matrix <span class="math notranslate nohighlight">\(\mathbf{Q}\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[
Q_{ij} = \frac{1}{2m}A_{ij} - \frac{k_i k_j}{4m^2}
\]</div>
<p>where <span class="math notranslate nohighlight">\(k_i\)</span> is the degree of node <span class="math notranslate nohighlight">\(i\)</span>, and <span class="math notranslate nohighlight">\(m\)</span> is the number of edges in the network.</p>
<p>We then compute the eigenvectors of <span class="math notranslate nohighlight">\(\mathbf{Q}\)</span> and use them to embed the network into a low-dimensional space just as we did for the adjacency matrix.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">deg</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">A</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">deg</span><span class="p">,</span> <span class="n">deg</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span>
<span class="n">Q</span><span class="o">/=</span> <span class="mi">2</span><span class="o">*</span><span class="n">m</span>

<span class="n">eigvals</span><span class="p">,</span> <span class="n">eigvecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>

<span class="c1"># Sort the eigenvalues and eigenvectors</span>
<span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">eigvals</span><span class="p">)[:</span><span class="n">d</span><span class="p">]</span>  <span class="c1"># Exclude the first eigenvector</span>
<span class="n">eigvals</span> <span class="o">=</span> <span class="n">eigvals</span><span class="p">[</span><span class="n">sorted_indices</span><span class="p">]</span>
<span class="n">eigvecs</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="n">sorted_indices</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Modularity Embedding&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Eigenvector 1&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Eigenvector 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The modularity embedding can be used to bipartition the network into two communities using a simple algorithm: group nodes with the same sign of the second eigenvector <a class="footnote-reference brackets" href="#footcite-newman2006modularity" id="id7" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a>.</p>
</div>
</section>
<section id="laplacian-eigenmap">
<h2>Laplacian Eigenmap<a class="headerlink" href="#laplacian-eigenmap" title="Link to this heading">#</a></h2>
<p>Laplacian Eigenmap <a class="footnote-reference brackets" href="#footcite-belkin2003laplacian" id="id8" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a> is another approach to compress a network into a low-dimensional space. The fundamental idea behind this method is to position connected nodes close to each other in the low-dimensional space. This approach leads to the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[
\min_{\mathbf{U}} J_{LE}(\mathbf{U}),\quad J_{LE}(\mathbf{U}) = \frac{1}{2}\sum_{i,j} A_{ij} \| u_i - u_j \|^2
\]</div>
<p>In this equation, <span class="math notranslate nohighlight">\(\| u_i - u_j \|^2\)</span> represents the squared distance between nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> in the low-dimensional space. The goal is to minimize this distance for connected nodes (where <span class="math notranslate nohighlight">\(A_{ij} = 1\)</span>). The factor <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span> is included for mathematical convenience in later calculations.</p>
<p>To solve this optimization problem, we rewrite <span class="math notranslate nohighlight">\(J_{LE}(\mathbf{U})\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
J_{LE}(\mathbf{U}) &amp;= \frac{1}{2}\sum_{i}\sum_{j} A_{ij} \| u_i - u_j \|^2 \\
&amp;= \frac{1}{2}\sum_{i}\sum_{j} A_{ij} \left( \| u_i \|^2 - 2 u_i^\top u_j + \| u_j \|^2 \right) \\
&amp;= \sum_{i}\sum_{j} A_{ij} \| u_i \|^2 - \sum_{i}\sum_{j} A_{ij} u_i^\top u_j\\
&amp;= \sum_{i} k_i \| u_i \|^2 - \sum_{i,j} A_{ij} u_i^\top u_j\\
&amp;= \sum_{i,j} L_{ij} u_i^\top u_j
\end{aligned}
\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
L_{ij} = \begin{cases}
k_i &amp; \text{if } i = j \\
-A_{ij} &amp; \text{if } i \neq j
\end{cases}
\end{split}\]</div>
<p>Let us go through the derivation step by step.</p>
<ol class="arabic simple">
<li><p>In the first step (i.e., the second line), we expand the squared norm using the vector identity <span class="math notranslate nohighlight">\(\|a-b\|^2 = \|a\|^2 - 2a^\top b + \|b\|^2\)</span>.</p></li>
<li><p>In the second step (i.e., the third line), we distribute the sum and the factor <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span>.
The middle term gets a factor of 1 because it appears twice in the expansion (once for <span class="math notranslate nohighlight">\(i,j\)</span> and once for <span class="math notranslate nohighlight">\(j,i\)</span>), canceling out the <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span>. Note that the term <span class="math notranslate nohighlight">\(A_{ij}\)</span> is symmetric, i.e., <span class="math notranslate nohighlight">\(A_{ij} = A_{ji}\)</span>.</p></li>
<li><p>In the third step (i.e., the fourth line), we recognize that <span class="math notranslate nohighlight">\(\sum_j A_{ij}\)</span> is the degree of node <span class="math notranslate nohighlight">\(i\)</span>, which we denote as <span class="math notranslate nohighlight">\(k_i\)</span>.</p></li>
<li><p>Finally, we combine the terms by using the Laplacian matrix <span class="math notranslate nohighlight">\(\mathbf{L}\)</span>.</p></li>
</ol>
<p>The minimization problem can be rewritten as:</p>
<div class="math notranslate nohighlight">
\[
J_{LE}(\mathbf{U}) = \text{Tr}(\mathbf{U}^\top \mathbf{L} \mathbf{U})
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{U} =
\begin{bmatrix}
\mathbf{u}_1 ^\top \\
\mathbf{u}_2 ^\top \\
\vdots \\
\mathbf{u}_N ^\top \\
\end{bmatrix}
\end{split}\]</div>
<p>See the <a class="reference internal" href="#./appendix.md"><span class="xref myst">Appendix section</span></a> for the detailed derivation.</p>
<p>By taking the derivative of <span class="math notranslate nohighlight">\(J_{LE}(\mathbf{U})\)</span> with respect to <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> and set it to zero, we obtain the following equation:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial J_{LE}}{\partial \mathbf{U}} = 0 \implies \mathbf{L} \mathbf{U} = \lambda \mathbf{U}
\]</div>
<p>The solution is the <span class="math notranslate nohighlight">\(d\)</span> eigenvectors associated with the <span class="math notranslate nohighlight">\(d\)</span> smallest eigenvalues of <span class="math notranslate nohighlight">\(\mathbf{L}\)</span>.</p>
<p>It is important to note that the eigenvector corresponding to the smallest eigenvalue (which is always zero for connected graphs) is trivial - it’s the all-one vector. Therefore, in practice, we typically compute the <span class="math notranslate nohighlight">\(d+1\)</span> smallest eigenvectors and discard the one corresponding to the zero eigenvalue.</p>
<section id="an-example-for-the-laplacian-eigenmap">
<h3>An example for the Laplacian Eigenmap<a class="headerlink" href="#an-example-for-the-laplacian-eigenmap" title="Link to this heading">#</a></h3>
<p>Let us first compute the Laplacian matrix and its eigenvectors.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">D</span> <span class="o">-</span> <span class="n">A</span>

<span class="n">eigvals</span><span class="p">,</span> <span class="n">eigvecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>

<span class="c1"># Sort the eigenvalues and eigenvectors</span>
<span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">eigvals</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Exclude the first eigenvector</span>
<span class="n">eigvals</span> <span class="o">=</span> <span class="n">eigvals</span><span class="p">[</span><span class="n">sorted_indices</span><span class="p">]</span>
<span class="n">eigvecs</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="n">sorted_indices</span><span class="p">]</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>The eigenvectors corresponding to the <span class="math notranslate nohighlight">\(d\)</span> smallest eigenvalues are:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">eigvecs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Laplacian Eigenmap&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Eigenvector 2&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Eigenvector 3&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="docutils container" id="id9">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-newman2006modularity" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">6</a><span class="fn-bracket">]</span></span>
<p>M. E. J. Newman. Modularity and community structure in networks. <em>Proceedings of the National Academy of Sciences</em>, 103(23):8577–8582, 2006. URL: <a class="reference external" href="https://www.pnas.org/doi/abs/10.1073/pnas.0601602103">https://www.pnas.org/doi/abs/10.1073/pnas.0601602103</a>, <a class="reference external" href="https://arxiv.org/abs/https://www.pnas.org/doi/pdf/10.1073/pnas.0601602103">arXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.0601602103</a>, <a class="reference external" href="https://doi.org/10.1073/pnas.0601602103">doi:10.1073/pnas.0601602103</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-belkin2003laplacian" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">7</a><span class="fn-bracket">]</span></span>
<p>Mikhail Belkin and Partha Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. <em>Neural Computation</em>, 15(6):1373–1396, 2003. <a class="reference external" href="https://doi.org/10.1162/089976603321780317">doi:10.1162/089976603321780317</a>.</p>
</aside>
</aside>
</div>
</section>
</section>
<hr class="docutils" />
<section id="jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">
<h2>jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3<a class="headerlink" href="#jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3" title="Link to this heading">#</a></h2>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="spectral-vs-neural-embedding">
<h1>Spectral vs Neural Embedding<a class="headerlink" href="#spectral-vs-neural-embedding" title="Link to this heading">#</a></h1>
<p>We have learned two types of graph embedding methods: spectral methods and neural embedding methods. But which one is better than the other? We will compare the two types of methods from multiple aspects as follows.</p>
<ol class="arabic">
<li><p><strong>Analytical Tractability</strong>: Spectral methods are more analytically tractable and thus are easier to understand using linear algebra. It is even possible to derive the capability and limitation of the spectral methods. For example, spectral methods based on adjacency matrices and normalized laplacian matrices are shown to be optimal for detecting communities in the stochastic block model <a class="footnote-reference brackets" href="#footcite-nadakuditi2012graph" id="id10" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a>. Neural embedding methods are less analytically tractable. But still possible to analyze the theoretical properties by using an equivalence between a spectral embedding and a neural embedding under a very specific condition <a class="footnote-reference brackets" href="#footcite-qiu2018network" id="id11" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-kojaku2023network" id="id12" role="doc-noteref"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></a>. These theoretical results have demonstrated that DeepWalk, node2vec, and LINE are in fact an optimal embedding methods for community detection for the stochatic block model.</p></li>
<li><p><strong>Scalability</strong>: A key limitation of the spectral embedding is the computational cost. While efficient methods exist like randomized singular value decomposition (implemented in scikit learn package as <code class="docutils literal notranslate"><span class="pre">TruncatedSVD</span></code>), they might be unstable depending on the spectrum distribution of the matrix to be decomposed. Neural embedding methods are often more stable and scalable.</p></li>
<li><p><strong>Flexibility</strong>: Neural embeddings are more flexible than spectral embeddings. It is easy to change the objective functions of neural embeddings using the same training procedure. For example, the proximity of nodes in both embedding spaces are inherently dot similarity, but one can train neural embeddings to optimize for other metrics to embed the network in a non-Euclidean space. An interesting example of this is the Poincaré embeddings <a class="footnote-reference brackets" href="#footcite-nickel2017poincare" id="id13" role="doc-noteref"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></a> for embedding networks in hyperbolic space.</p>
<p><img alt="" src="https://pbs.twimg.com/media/DUUj0sxU8AACV50.jpg" /></p>
</li>
</ol>
<div class="docutils container" id="id14">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-nadakuditi2012graph" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id10">8</a><span class="fn-bracket">]</span></span>
<p>Raj Rao Nadakuditi and Mark EJ Newman. Graph spectra and the detectability of community structure in networks. <em>Physical review letters</em>, 108(18):188701, 2012.</p>
</aside>
<aside class="footnote brackets" id="footcite-qiu2018network" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id11">9</a><span class="fn-bracket">]</span></span>
<p>Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, and Jie Tang. Network embedding as matrix factorization: unifying deepwalk, line, pte, and node2vec. In <em>Proceedings of the eleventh ACM international conference on web search and data mining</em>, 459–467. 2018.</p>
</aside>
<aside class="footnote brackets" id="footcite-kojaku2023network" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id12">10</a><span class="fn-bracket">]</span></span>
<p>Sadamori Kojaku, Filippo Radicchi, Yong-Yeol Ahn, and Santo Fortunato. Network community detection via neural embeddings. <em>arXiv preprint arXiv:2306.13400</em>, 2023.</p>
</aside>
<aside class="footnote brackets" id="footcite-nickel2017poincare" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id13">11</a><span class="fn-bracket">]</span></span>
<p>Maximillian Nickel and Douwe Kiela. Poincaré embeddings for learning hierarchical representations. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, <em>Advances in Neural Information Processing Systems</em>, volume 30. Curran Associates, Inc., 2017. URL: <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/59dfa2df42d9e3d41f5b02bfc32229dd-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2017/file/59dfa2df42d9e3d41f5b02bfc32229dd-Paper.pdf</a>.</p>
</aside>
</aside>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="module-8-embedding">
<h1>Module 8: Embedding<a class="headerlink" href="#module-8-embedding" title="Link to this heading">#</a></h1>
<section id="what-to-learn-in-this-module">
<h2>What to learn in this module<a class="headerlink" href="#what-to-learn-in-this-module" title="Link to this heading">#</a></h2>
<p>In this module, we will learn how to embed networks into low-dimensional spaces. We will learn:</p>
<ul class="simple">
<li><p>Spectral embedding</p></li>
<li><p>Neural embedding</p></li>
<li><p><strong>Keywords</strong>: Laplacian EigenMap, Normalized Spectral Embedding, DeepWalk, Node2Vec—
jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="word2vec">
<h1>word2vec<a class="headerlink" href="#word2vec" title="Link to this heading">#</a></h1>
<p>In this section, we will introduce <em>word2vec</em>, a powerful technique for learning word embeddings. word2vec is a neural network model that learns words embeddings in a continuous vector space. It was introduced by Tomas Mikolov and his colleagues at Google in 2013 <a class="footnote-reference brackets" href="#footcite-mikolov2013distributed" id="id15" role="doc-noteref"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></a>.</p>
<section id="how-it-works">
<h2>How it works<a class="headerlink" href="#how-it-works" title="Link to this heading">#</a></h2>
<p>“You shall know a word by the company it keeps”  is a famous quote in linguistics. It means that you can understand the meaning of a word by looking at the words that appear in the same context.
word2vec operates on the same principle.
word2vec identifies a word’s context by examining the words within a fixed window around it. For example, in the sentence:</p>
<blockquote>
<div><p>The quick brown fox jumps over a lazy dog</p>
</div></blockquote>
<p>The context of the word <em>fox</em> includes <em>quick</em>, <em>brown</em>, <em>jumps</em>, <em>over</em>, and <em>lazy</em>. word2vec is trained to predict which words are likely to appear as the context of an input word.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There are two main architectures for word2vec:</p>
<ol class="arabic simple">
<li><p><strong>Continuous Bag of Words (CBOW)</strong>: Predicts the target word (center word) from the context words (surrounding words).</p></li>
<li><p><strong>Skip-gram</strong>: Predicts the context words (surrounding words) from the target word (center word).</p></li>
</ol>
</div>
<p>So how are word embeddings learned? word2vec is a neural network model that looks like a bow tie. It has two layers of the vocabulary size coupled with a much smaller hidden layer.</p>
<p><img alt="" src="../_images/word2vec.png" /></p>
<ul class="simple">
<li><p><strong>Input layer</strong>: The input layer consists of <span class="math notranslate nohighlight">\(N\)</span> neurons, where <span class="math notranslate nohighlight">\(N\)</span> is the size of the vocabulary (i.e., the number of unique words in the corpus). Each neuron corresponds to a unique word in the vocabulary. When a word is inputted, its corresponding neuron is activated and the other neurons are inhibited. Thus, the input layer is essentially a lookup mechanism that transforms the input word into a corresponding one-hot vector.</p></li>
<li><p><strong>Output layer</strong>: The output layer also consists of <span class="math notranslate nohighlight">\(N\)</span> neurons, each corresponding to a unique word in the vocabulary. Unlike the input layer, multiple neurons can be activated for a single input. The strength of the activation of each neuron (with a normalization by the softmax function) represents the probability of the corresponding word being the input word’s context.</p></li>
<li><p><strong>Hidden layer</strong>: The hidden layer is much smaller than the input and output layers. Multiple neurons in the hidden layer can be activated for a single input, and this activation pattern represents the word’s <em>embedding</em>.</p></li>
</ul>
<p>We can consider word2vec as a <em>dimensionality reduction</em> technique that reduces the dimensionality of the input layer to the hidden layer based on the co-occurrence of words within a short distance. The distance is named the <em>window size</em>, which is a user-defined hyperparameter.</p>
</section>
<section id="whats-special-about-word2vec">
<h2>What’s special about word2vec?<a class="headerlink" href="#whats-special-about-word2vec" title="Link to this heading">#</a></h2>
<p>With word2vec, words are represented as dense vectors, enabling us to explore their relationships using simple linear algebra. This is in contrast to traditional natural language processing (NLP) methods, such as bag-of-words and topic modeling, which represent words as discrete units or high-dimensional vectors.</p>
<p><img alt="" src="https://miro.medium.com/v2/resize:fit:678/1*5F4TXdFYwqi-BWTToQPIfg.jpeg" /></p>
<p>To showcase the effectiveness of word2vec, let’s walk through an example using the <code class="docutils literal notranslate"><span class="pre">gensim</span></code> library.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gensim</span>
<span class="kn">import</span> <span class="nn">gensim.downloader</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>

<span class="c1"># Load pre-trained word2vec model from Google News</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">downloader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;word2vec-google-news-300&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Our first example is to find the words most similar to <em>king</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Example usage</span>
<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;king&quot;</span>
<span class="n">similar_words</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Words most similar to &#39;</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2">&#39;:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">similar_word</span><span class="p">,</span> <span class="n">similarity</span> <span class="ow">in</span> <span class="n">similar_words</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">similar_word</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">similarity</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>A cool (yet controversial) application of word embeddings is analogy solving. Let us consider the following puzzle:</p>
<blockquote>
<div><p><em>man</em> is to <em>woman</em> as <em>king</em> is to ___ ?</p>
</div></blockquote>
<p>We can use word embeddings to solve this puzzle.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We solve the puzzle by</span>
<span class="c1">#</span>
<span class="c1">#  vec(king) - vec(man) + vec(woman)</span>
<span class="c1">#</span>
<span class="c1"># To solve this, we use the model.most_similar function, with positive words being &quot;king&quot; and &quot;woman&quot; (additive), and negative words being &quot;man&quot; (subtractive).</span>
<span class="c1">#</span>
<span class="n">model</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;woman&#39;</span><span class="p">,</span> <span class="s2">&quot;king&quot;</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;man&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The last example is to visualize the word embeddings.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="n">countries</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Germany&#39;</span><span class="p">,</span> <span class="s1">&#39;France&#39;</span><span class="p">,</span> <span class="s1">&#39;Italy&#39;</span><span class="p">,</span> <span class="s1">&#39;Spain&#39;</span><span class="p">,</span> <span class="s1">&#39;Portugal&#39;</span><span class="p">,</span> <span class="s1">&#39;Greece&#39;</span><span class="p">]</span>
<span class="n">capital_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Berlin&#39;</span><span class="p">,</span> <span class="s1">&#39;Paris&#39;</span><span class="p">,</span> <span class="s1">&#39;Rome&#39;</span><span class="p">,</span> <span class="s1">&#39;Madrid&#39;</span><span class="p">,</span> <span class="s1">&#39;Lisbon&#39;</span><span class="p">,</span> <span class="s1">&#39;Athens&#39;</span><span class="p">]</span>

<span class="c1"># Get the word embeddings for the countries and capitals</span>
<span class="n">country_embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">model</span><span class="p">[</span><span class="n">country</span><span class="p">]</span> <span class="k">for</span> <span class="n">country</span> <span class="ow">in</span> <span class="n">countries</span><span class="p">])</span>
<span class="n">capital_embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">model</span><span class="p">[</span><span class="n">capital</span><span class="p">]</span> <span class="k">for</span> <span class="n">capital</span> <span class="ow">in</span> <span class="n">capital_words</span><span class="p">])</span>

<span class="c1"># Compute the PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">country_embeddings</span><span class="p">,</span> <span class="n">capital_embeddings</span><span class="p">])</span>
<span class="n">embeddings_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

<span class="c1"># Create a DataFrame for seaborn</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">embeddings_pca</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;PC1&#39;</span><span class="p">,</span> <span class="s1">&#39;PC2&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">countries</span> <span class="o">+</span> <span class="n">capital_words</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Country&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">countries</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;Capital&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">capital_words</span><span class="p">)</span>

<span class="c1"># Plot the data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="c1"># Create a scatter plot with seaborn</span>
<span class="n">scatter_plot</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;PC1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;PC2&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;Type&#39;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">&#39;Type&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;deep&#39;</span><span class="p">,</span> <span class="n">markers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">])</span>

<span class="c1"># Annotate the points</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC1&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC2&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.08</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">,</span>
             <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">))</span>

<span class="c1"># Draw arrows between countries and capitals</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">countries</span><span class="p">)):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC1&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC2&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC1&#39;</span><span class="p">][</span><span class="n">i</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">countries</span><span class="p">)]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC1&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC2&#39;</span><span class="p">][</span><span class="n">i</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">countries</span><span class="p">)]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PC2&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span>
              <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">head_width</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">head_length</span><span class="o">=</span><span class="mf">0.03</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Type&#39;</span><span class="p">,</span> <span class="n">title_fontsize</span><span class="o">=</span><span class="s1">&#39;13&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;11&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;PCA of Country and Capital Word Embeddings&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 2&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>We can see that word2vec places the words representing countries close to each other and so do the words representing their capitals. The country-capital relationship is also roughly preserved, e.g., <em>Germany</em>-<em>Berlin</em> vector is roughly parallel to <em>France</em>-<em>Paris</em> vector.</p>
<div class="docutils container" id="id16">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-mikolov2013distributed" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id15">12</a><span class="fn-bracket">]</span></span>
<p>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations of words and phrases and their compositionality. <em>Advances in neural information processing systems</em>, 2013.</p>
</aside>
</aside>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "skojaku/adv-net-sci",
            ref: "gh-pages",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tmp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Appendix</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-embedding-with-the-adjacency-matrix">Spectral Embedding with the Adjacency Matrix</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-proof-of-the-laplacian-eigenmap">The proof of the Laplacian Eigenmap</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#this-final-form-expresses-our-objective-function-in-terms-of-matrix-operations-which-allows-us-to-use-matrix-calculus-to-find-the-optimal-solution-the-trace-representation-is-a-useful-technique-to-leverage-matrix-calculus-jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">This final form expresses our objective function in terms of matrix operations, which allows us to use matrix calculus to find the optimal solution. The trace representation is a useful technique to leverage matrix calculus.—
jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-embedding-with-word2vec">Graph embedding with word2vec</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deepwalk">DeepWalk</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-01-implement-deepwalk">Exercise 01: Implement DeepWalk</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-data-preparation">Step 1: Data preparation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-generate-random-walks">Step 2: Generate random walks</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-train-the-word2vec-model">Step 3: Train the word2vec model</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-clustering">Step 4: Clustering</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#node2vec">node2vec</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-02-implement-node2vec">Exercise 02: Implement node2vec</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#line">LINE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modularity-embedding">Modularity embedding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laplacian-eigenmap">Laplacian Eigenmap</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#an-example-for-the-laplacian-eigenmap">An example for the Laplacian Eigenmap</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jupytext-formats-md-myst-text-representation-extension-md-format-name-myst-kernelspec-display-name-python-3-language-python-name-python3">jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-vs-neural-embedding">Spectral vs Neural Embedding</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#module-8-embedding">Module 8: Embedding</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-to-learn-in-this-module">What to learn in this module</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#word2vec">word2vec</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-it-works">How it works</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#whats-special-about-word2vec">What’s special about word2vec?</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Sadamori Kojaku
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>