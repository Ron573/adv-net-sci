---
title: "Small-World Networks: Core Concepts"
filters:
    - marimo-team/marimo
---

## What to learn in this module

In this module, we will learn small-world experiments and conduct a small small-world experiment . We will learn:

- Small-world experiment by Milgram
- Different concepts of *distance*: path, walks, circuits, cycles, connectedness
- How to measure a *distance* between two nodes
- **Keywords**: small-world experiment, six degrees of separation, path, walks, circuits, cycles, connectedness, connected component, weakly connected component, strongly connected component.

## Small-world experiment

::: {.column-margin}
[Stanley Milgram](https://en.wikipedia.org/wiki/Stanley_Milgram) (1933-1984) was an American social psychologist best known for his controversial [obedience experiments](https://en.wikipedia.org/wiki/Milgram_experiment) at Yale University in the early 1960s. Beyond the obedience studies, Milgram conducted groundbreaking research on social networks, including the famous ["small world" experiment](https://en.wikipedia.org/wiki/Small-world_experiment) that revealed the surprisingly short chains connecting any two people in society.
:::

How far are two people in a social network? Milgram and his colleagues conducted a series of expriment to find out in the 1960s.

::: {#fig-milgram-small-world-experiment}

<img src="../figs/milgram-small-world-experiment.png" width="70%">

Milgram's small world experiment.

:::


The experiment went as follows:

1. Milgram first sent out packets to randomly selected people in Omaha, Nebraska, and Wichita, Kansas.
2. The recipient was asked to send the packet to the target person in Boston if they knew them. If not, they were to forward it to someone they knew on a first-name basis who might know the target.
3. The recipient continued to forward the packet to their acquaintances until it reached the target.

The results were surprising: out of the 160 letters sent, 64 successfully reached the target person by the chain of nearly six people, which was later called **six degrees of separation**.
The results imply that, despite the fact that there were hundreds of millions of people in the United States, their social network was significantly compact, with two random people being connected to each other in only a few steps.

::: {.column-margin}
The term "Six degrees of separation" is commonly associated with Milgram's experiment, but Milgram never used it. John Guare coined the term for his 1991 play and movie ["Six Degrees of Separation."](https://en.wikipedia.org/wiki/Six_Degrees_of_Separation_(film))
:::

The results were later confirmed independently.

-  Yahoo research replicate the Milgram's experiment by using emails. Started from more than 24,000 people, only 384 people reached the one of the 18 target person in 13 countries. Among the successful ones, the average length of the chain was about 4. When taken into account the broken chain, the average length was estimated between 5 and 7. [@goel2009social]

- Researchers in Facebook and University of Milan analyzed the social network n Facebook, which consisted of 721 million active users and 69 billion friendships. The average length of the shortest chain was found to be 4.74. [@backstrom2012four]

## Wikirace: Experiencing Small-World Networks

Let us feel how small a large network can be by playing the [Wikirace](https://wiki-race.com) game.

<div align="center">
  <img src="https://cdn.sparkfun.com/assets/home_page_posts/3/8/8/0/Wikirace.jpeg" alt="Wikirace" width="70%">
</div>

At the end of the module, we will measure the average path length in a social network. Before jumping on, let us arm with some coding techniques to handle the network in the next two sections.

## Why is small-world networks non-trivial?


::: {.column-margin}

<iframe width="250" height="150" src="https://www.youtube.com/embed/TcxZSmzPw8k?si=J7DZ-7gmBPPruTSV" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

:::

When we think about social networks, it's natural to imagine that most people are friends with others who are nearby—friends of friends, classmates, colleagues, or neighbors. These are **local connections**, and they tend to form tightly-knit groups where everyone knows each other. In network terms, this means there are many **triangles**: if Alice is friends with Bob, and Bob is friends with Carol, then Alice is also likely to be friends with Carol.

However, if a network only had these local, clustered connections, it would be difficult for information or influence to travel quickly across the entire network. You would have to go through many intermediaries to reach someone far away, resulting in a **large diameter** (the longest shortest path between any two nodes).

What makes **small-world networks** non-trivial and surprising is that, despite having lots of local clustering (many triangles), they also have a few **long-range connections**—edges that link distant parts of the network. These "shortcuts" dramatically reduce the average distance between nodes. As a result, even in a huge network, you can reach almost anyone in just a few steps. This combination of high clustering and short path lengths is what defines the small-world property.

In summary:

- **Local connections** create clustering (many triangles), but by themselves would make the network "large" in terms of path length.
- **Small-world networks** have both high clustering *and* short average path lengths, thanks to a few edges that connect distant parts of the network.
- This structure is non-trivial because it cannot be explained by local connections alone; the presence of long-range links is essential for the "small world" phenomenon.

## Quantifying Small-World Properties

::: {.column-margin}

<iframe width="250" height="150" src="https://www.youtube.com/embed/mgcNO58BLk4?si=9wjqYyDzlMB0z6DH" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

:::


Let us approach the small-world properties from mathematical angle. Two key characteristics of small-world networks are:

- **Short average path length**: You can reach distant parts of the network quickly.
- **High clustering**: Friends of friends are often friends.


### Short Average Path Length

::: {.column-margin}
A path is a walk without repeated nodes. The shortest paths are the paths with the smallest number of edges.
:::

Let's understand what **average path length** means. When we talk about how "far apart" two nodes are in a network, we mean the shortest number of edges you need to traverse to get from one node to the other. This is called the **distance** between nodes.

```{dot}
//| fig-width: 3
//| fig-height: 2.5
//| fig-cap: "Simple network example for understanding shortest paths"
//| label: fig-shortest-path
//| fig-align: center
graph G {
  layout=circo
  A [shape=circle, fillcolor="#f5cbcc", style="filled,bold", penwidth=2, ];
  B [shape=circle];
  C [shape=circle];
  D [shape=circle];
  A -- B;
  A -- C;
  B -- C;
  B -- D;
  C -- D;
}
```

In this simple network, let's find the distance between nodes A and D:

- Path 1: A $\rightarrow$ B $\rightarrow$ D (2 edges)
- Path 2: A $\rightarrow$ C $\rightarrow$ D (2 edges)
- Path 3: A $\rightarrow$ C $\rightarrow$ B $\rightarrow$ D (3 edges)

Even though there are multiple paths, the **shortest path length** (distance) from A to D is **2 edges**.

Building on this, let us calculate the *average* path length between two nodes. We have four nodes in the network, so there are 6 pairs of nodes. Let us enumerate them as follows:

| Pair    | Shortest Path                | Length |
|---------|------------------------------|--------|
| A - B   | A $\rightarrow$ B                        | 1      |
| A - C   | A $\rightarrow$ C                        | 1      |
| A - D   | A $\rightarrow$ B $\rightarrow$ D or A $\rightarrow$ C $\rightarrow$ D       | 2      |
| B - C   | B $\rightarrow$ C                        | 1      |
| B - D   | B $\rightarrow$ D                        | 1      |
| C - D   | C $\rightarrow$ D                        | 1      |


The **average path length** is simply the average of all these distances, which is $7 / 6 \simeq 1.16$.


### Clustering Coefficient

In social networks, your friends tend to know each other.
If you have a friend Alice, and Alice has friends Bob and Carol, local clustering asks: "Are Bob and Carol also friends with each other?" High local clustering means that your friends tend to know each other, creating dense local neighborhoods or cliques.

There are three ways to measure clustering: **local clustering**, **average local clustering**, and **global clustering**. The key difference is the focus of the measurement:

- **Local clustering** focuses on the clustering of the neighbors of a specific node
- **Average local clustering** focuses on the clustering of the neighbors of a node
- **Global clustering** focuses on the clustering of the entire network.

Let us explain each of them one by one.

#### Local Clustering

**Local clustering** asks: given all your friends, how many of triangles you and your friends form, relative to the maximum possible number of triangles?

The local clustering coefficient $C_i$ of a node $i$ is defined as:

$$
C_i = \dfrac{\text{\# of triangles involving } i \text{ and its neighbors}}{\text{\# of edges possibly exist in the neighborhood of } i}
$$

Or alternatively, using the adjacency matrix $A$ and the degree $k_i$ of node $i$,
$$
\begin{aligned}
C_i = \frac{\sum_{j}\sum_{\ell} A_{ij}A_{j\ell} A_{\ell i} }{k_i(k_i-1)}
\end{aligned}
$$

::: {.callout-note collapse="true" title="Note: Derivation of the local clustering coefficient"}
Numerator $A_{ij}A_{j\ell} A_{\ell i}$ is a binary indicator of whether three nodes $i$, $j$, and $\ell$ form a triangle; $A_{ij}A_{j\ell} A_{\ell i}=1$ if a cycle $i \rightarrow j \rightarrow \ell \rightarrow i$ exists, and $0$ otherwise.
By summing up all nodes, we have the number of triangles in the neighbors of $i$ given by $\sum_{j}\sum_{\ell} A_{ij}A_{j\ell} A_{\ell i} / 2$.
Note that we divide the sum by 2 because the same triangle forms two cycles, i.g., $i \rightarrow j \rightarrow \ell \rightarrow i$ and $i \rightarrow \ell \rightarrow j \rightarrow i$.

The number of possible triangles in the neighborhood of $i$ is given by $\binom{k_i}{2} = k_i(k_i-1)/2$.

Putting them together:

$$
C_i = \frac{\sum_{j}\sum_{\ell} A_{ij}A_{j\ell} A_{\ell i} }{k_i(k_i-1)}
$$
:::


For example, let us compute the local clustering coefficient of node A in the following network. There are two triangles in the neighborhood of A. The number of possible triangles is $5 \times 4 / 2 = 10$. Thus, the local clustering coefficient of A is $2 / 10 = 0.2$.

```{dot}
//| fig-width: 3
//| fig-height: 2.5
//| fig-cap: "A network of friends"
//| label: fig-shortest-path
//| fig-align: center
graph G {
  layout=circo
  A [shape=circle, fillcolor="#f5cbcc", style="filled,bold", penwidth=2, pos="0,0!"];
  B [shape=circle];
  C [shape=circle];
  D [shape=circle];
  E [shape=circle];
  F [shape=circle];

  A -- B;
  A -- C;
  A -- D;
  A -- E;
  A -- F;
  B -- F;
  C -- E;
}
```

#### Average Local Clustering

Local clustering focuses on the clustering of a node's neighborhood, while the global clustering focuses on the clustering of the entire network. One can adapt the local clustering for measuring the global clustering by taking the average of the local clustering coefficients of all nodes, i.e.,

$$
\overline {C} = \frac{1}{N} \sum_{i=1}^N C_i
$$

#### Global Clustering

Global clustering, also known as **transitivity**, measures the overall tendency for triangles to form throughout the entire network. It answers the question: "Across the whole network, how likely is it that two nodes connected to a common neighbor are also connected to each other?"

The global clustering coefficient $C$ is defined as:

$$
C = \frac{3 \times \text{number of triangles}}{\text{number of connected triplets}}
$$

where a **connected triplet** is a set of three nodes connected by at least two edges, forming either a closed triplet (triangle) or an open triplet (wedge) shown below.

```{dot}
//| fig-width: 5
//| fig-height: 2.5
//| fig-cap: "Closed triplet (left) and open triplet (right)"
//| fig-align: center
graph G {
  layout=neato;
  fontsize=16;

  node [fontsize=14];

  subgraph cluster_0 {
    label="Closed Triplet";
    fontsize=16;
    style=filled;
    color=lightgrey;
    node [shape=circle, fillcolor="#f5cbcc", style="filled,bold", penwidth=2];
    A1 [pos="-1.5,0!" shape=circle];
    B1 [pos="-2.5,-1!" shape=circle];
    C1 [pos="-0.5,-1!" shape=circle];
    A1 -- B1;
    B1 -- C1;
    C1 -- A1;
  }

  subgraph cluster_1 {
    label="Open Triplet";
    fontsize=16;
    style=filled;
    color=lightgrey;
    node [shape=circle, fillcolor="#d0e2f3", style="filled,bold", penwidth=2];
    A2 [pos="1.5,0!" ];
    B2 [pos="0.5,-1!" ];
    C2 [pos="2.5,-1!" ];
    A2 -- B2;
    B2 -- C2;
  }
}
```

In triplets, the order of the nodes matters. For example, $(A_1, B_1, C_1)$ and $(B_1, C_1, A_1)$ are two different triplets. A triangle pertains to three triplets, i.e., $(A_1, B_1, C_1)$, $(B_1, C_1, A_1)$, and $(C_1, A_1, B_1)$. This is why we multiple three to the number of triangles in the numerator.

::: {.callout-note collapse="true" title="Key difference between average local and global clustering"}

It is confusing to have two different global clustering measures, but the distinction becomes clearer if we think in terms of micro and macro perspectives:

- The global clustering coefficient $C$ (based on the total number of triangles and triplets in the network) is a **micro-level** measure. It looks at the prevalence of triangles relative to all possible connected triples in the entire network, essentially aggregating over all small, local patterns (triplets) to get a sense of how likely it is for any three connected nodes to form a closed triangle.

- The average local clustering coefficient $\overline{C}$ is a **macro-level** measure. It first computes the clustering coefficient for each individual node (how clustered each node's neighborhood is), and then averages these values across all nodes. This gives a sense of the overall tendency for nodes in the network to have tightly knit neighborhoods.

So the focal scope remains the same: the average local clustering focuses on a node's neighborhood, while the global clustering focuses on the entire network.
:::

### Small-world coefficient

Now let's define a coefficient to measure the small-world property. Recall that a small-world network has both **high clustering** and **short average path length**. A naive approach is to take the ratio between the average local clustering coefficient and the average path length:

$$
s_{\text{naive}} = \frac{\overline{C}}{\overline{L}}
$$

where $\overline{C}$ is the average local clustering coefficient and $\overline{L}$ is the average path length.

A high $s_{\text{naive}}$ value would seem to indicate a strong small-world property. However, this naive measure has a critical flaw: it can be high for trivial network structures. For example,
a fully-connected network has $\overline{L} = 1$ (minimum possible) and $\overline{C} = 1$ (maximum possible), giving $s_{\text{naive}} = 1$.
This leads us to normalize against **random networks** with the same basic properties.

To address this issue, Watts and Strogatz proposed normalizing by equivalent random networks. The **small-world index** (or small-world coefficient) is defined as:

$$
\sigma = \frac{\overline{C}/\overline{C}_{\text{random}}}{\overline{L}/\overline{L}_{\text{random}}} = \frac{\overline{C} \cdot \overline{L}_{\text{random}}}{\overline{L} \cdot \overline{C}_{\text{random}}}
$$

where: $\overline{C}_{\text{random}}$ and $\overline{L}_{\text{random}}$ are the average local clustering coefficient and the average path length of an equivalent random network. The "equivalent random network" typically refers to an Erdős–Rényi random graph, where edges are randomly connected with the same number of nodes and edges (or same average degree) as the original network (thus it represents a trivial random network of the same number of nodes and edges).

A high $\sigma$ value greater than 1 indicates a strong small-world property. If $\sigma$ is close to 1, the network is not small-world but comparable to a random network in terms of the small-world property.
If $\sigma$ is less than 1, the network is anti-small-world, i.e., it has a large average path length and low clustering compared to a random counterpart.

Now, we have a way to measure the small-world property of a network. It has been shown in many different studies that the small-world property is surprisingly common in real-world networks.

This leads to a question: what is the underlying mechanism? The Watts-Strogatz model provides a way to generate small-world networks, as we will see in the next section.


## Watts-Strogatz Model

::: {#fig-watts-strogatz-model}

![](https://imgur.com/pnEl4X1.png)

Watts-Strogatz model.

:::

::: {.column-margin}

Here is a nice blog post about the Watts-Strogatz model: [https://chih-ling-hsu.github.io/2020/05/15/watts-strogatz](https://chih-ling-hsu.github.io/2020/05/15/watts-strogatz).

:::

::: {.column-margin}
> "What I cannot create, I do not understand." - Richard Feynman

This quote captures the essence of why models like Watts-Strogatz are crucial: by building networks that exhibit small-world properties, we gain deeper insight into how these properties emerge in real systems.
:::

The **Watts-Strogatz model** provides a elegant way to generate networks that interpolate between regular lattices (high clustering, long paths) and random graphs (low clustering, short paths), capturing the small-world phenomenon.

### The Algorithm

The Watts-Strogatz model starts with a **ring lattice** and introduces randomness through edge **rewiring**:

**Step 1: Start with a Ring Lattice**
- Create a ring of $N$ nodes
- Connect each node to its $k$ nearest neighbors (k/2 on each side)
- This gives high clustering but long average path length

**Step 2: Rewire Edges with Probability p**
- For each edge in the lattice:
  - With probability $p$: remove the edge and reconnect one endpoint to a randomly chosen node
  - With probability $(1-p)$: keep the original edge
- Avoid self-loops and duplicate edges

**Step 3: Resulting Network Properties**
- $p = 0$: Regular ring lattice (high clustering, long paths)
- $p = 1$: Random graph (low clustering, short paths)
- $0 < p < 1$: Small-world network (high clustering, short paths)

```{dot}
//| fig-width: 6
//| fig-height: 2.5
//| fig-cap: "Watts-Strogatz model progression from regular lattice to random graph"
//| fig-align: center
graph G {
  layout=neato;
  fontsize=14;

  subgraph cluster_0 {
    label="p = 0 (Regular Lattice)";
    fontsize=12;
    style=filled;
    color=lightgrey;

    A1 [pos="-4,0!" shape=circle];
    B1 [pos="-3.5,0.8!" shape=circle];
    C1 [pos="-2.8,0.8!" shape=circle];
    D1 [pos="-2.3,0!" shape=circle];
    E1 [pos="-2.8,-0.8!" shape=circle];
    F1 [pos="-3.5,-0.8!" shape=circle];

    A1 -- B1; B1 -- C1; C1 -- D1; D1 -- E1; E1 -- F1; F1 -- A1;
    A1 -- C1; B1 -- D1; C1 -- E1; D1 -- F1; E1 -- A1; F1 -- B1;
  }

  subgraph cluster_1 {
    label="0 < p < 1 (Small World)";
    fontsize=12;
    style=filled;
    color=lightgrey;

    A2 [pos="0,0!" shape=circle];
    B2 [pos="0.5,0.8!" shape=circle];
    C2 [pos="1.2,0.8!" shape=circle];
    D2 [pos="1.7,0!" shape=circle];
    E2 [pos="1.2,-0.8!" shape=circle];
    F2 [pos="0.5,-0.8!" shape=circle];

    A2 -- B2; B2 -- C2; C2 -- D2; D2 -- E2; E2 -- F2; F2 -- A2;
    A2 -- C2; B2 -- D2; E2 -- A2; F2 -- B2;
    C2 -- F2 [color=red, penwidth=2]; // rewired edge
    D2 -- A2 [color=red, penwidth=2]; // rewired edge
  }

  subgraph cluster_2 {
    label="p = 1 (Random Graph)";
    fontsize=12;
    style=filled;
    color=lightgrey;

    A3 [pos="4,0!" shape=circle];
    B3 [pos="4.5,0.8!" shape=circle];
    C3 [pos="5.2,0.8!" shape=circle];
    D3 [pos="5.7,0!" shape=circle];
    E3 [pos="5.2,-0.8!" shape=circle];
    F3 [pos="4.5,-0.8!" shape=circle];

    A3 -- D3; B3 -- E3; C3 -- F3; D3 -- B3; E3 -- C3; F3 -- A3;
    A3 -- B3; C3 -- D3; E3 -- F3; A3 -- E3; B3 -- F3; C3 -- A3;
  }
}
```

### Key Insights

**The Magic of Small p Values:**
Even a small rewiring probability ($p \approx 0.01$) dramatically reduces average path length while maintaining high clustering. This happens because:

1. **Clustering preservation**: Most edges remain local (probability $1-p$), maintaining triangular relationships
2. **Shortcut creation**: A few random edges (probability $p$) act as "shortcuts" across the network
3. **Diameter collapse**: These shortcuts reduce the network diameter from $O(N)$ to $O(\log N)$

**Mathematical Properties:**
- **Clustering coefficient**: $C(p) \approx C(0) \cdot (1-p)^3$ for small $p$
- **Average path length**: $L(p)$ drops rapidly even for small $p$
- **Small-world regime**: Optimal $\sigma$ typically occurs around $p \approx 0.01$ to $0.1$

### Biological and Social Relevance

The Watts-Strogatz model captures essential features of real networks:

**Neural networks**: Neurons are primarily connected locally (clustering) but have some long-range connections (shortcuts) that enable rapid information transmission.

**Social networks**: People have local social groups (high clustering) but occasional distant connections (through travel, online interaction) that reduce social distances.

**Internet topology**: Routers are connected regionally for efficiency but have backbone connections that span continents.

The model's success lies in showing that small-world properties emerge naturally from the tension between local organization and random connectivity - a fundamental principle observed across many natural and social systems.

### Interactive Exploration

Explore the Watts-Strogatz model interactively by adjusting the rewiring probability and observing how network properties change:

```python {.marimo}
import marimo as mo
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from collections import deque
import random

# Create the rewiring probability slider
p_slider = mo.ui.slider(
    start=0.0,
    stop=1.0,
    step=0.01,
    value=0.1,
    show_value=True,
    label="Rewiring Probability (p)"
)

# Display the slider
mo.md(f"**Control the rewiring probability:** {p_slider}")
```

```python {.marimo}
def generate_watts_strogatz(N=20, k=4, p=0.1, seed=42):
    """Generate Watts-Strogatz network from scratch"""
    np.random.seed(seed)
    random.seed(seed)
    
    # Start with ring lattice - adjacency matrix
    adj_matrix = np.zeros((N, N), dtype=int)
    
    # Connect each node to k nearest neighbors (k/2 on each side)
    for i in range(N):
        for j in range(1, k//2 + 1):
            # Connect to neighbors on both sides, wrapping around
            neighbor_right = (i + j) % N
            neighbor_left = (i - j) % N
            adj_matrix[i][neighbor_right] = 1
            adj_matrix[i][neighbor_left] = 1
    
    # Make symmetric (undirected)
    adj_matrix = np.maximum(adj_matrix, adj_matrix.T)
    
    # Rewire edges with probability p
    edges_to_process = []
    for i in range(N):
        for j in range(i+1, N):
            if adj_matrix[i][j] == 1:
                edges_to_process.append((i, j))
    
    for i, j in edges_to_process:
        if np.random.random() < p:
            # Remove original edge
            adj_matrix[i][j] = 0
            adj_matrix[j][i] = 0
            
            # Find a new target for node i (avoid self-loops and duplicates)
            possible_targets = []
            for k in range(N):
                if k != i and adj_matrix[i][k] == 0:
                    possible_targets.append(k)
            
            if possible_targets:
                new_target = np.random.choice(possible_targets)
                adj_matrix[i][new_target] = 1
                adj_matrix[new_target][i] = 1
    
    return adj_matrix

def generate_random_graph(N, num_edges, seed=42):
    """Generate Erdős–Rényi random graph with same number of edges"""
    np.random.seed(seed)
    adj_matrix = np.zeros((N, N), dtype=int)
    
    # Get all possible edges
    possible_edges = []
    for i in range(N):
        for j in range(i+1, N):
            possible_edges.append((i, j))
    
    # Randomly select edges
    if len(possible_edges) >= num_edges:
        selected_edges = np.random.choice(len(possible_edges), size=num_edges, replace=False)
        for edge_idx in selected_edges:
            i, j = possible_edges[edge_idx]
            adj_matrix[i][j] = 1
            adj_matrix[j][i] = 1
    
    return adj_matrix

def bfs_shortest_paths(adj_matrix, start):
    """Compute shortest paths from start node using BFS"""
    N = len(adj_matrix)
    distances = [-1] * N
    distances[start] = 0
    queue = deque([start])
    
    while queue:
        node = queue.popleft()
        for neighbor in range(N):
            if adj_matrix[node][neighbor] == 1 and distances[neighbor] == -1:
                distances[neighbor] = distances[node] + 1
                queue.append(neighbor)
    
    return distances

def compute_average_path_length(adj_matrix):
    """Compute average shortest path length"""
    N = len(adj_matrix)
    total_distance = 0
    total_pairs = 0
    
    for i in range(N):
        distances = bfs_shortest_paths(adj_matrix, i)
        for j in range(i+1, N):
            if distances[j] != -1:  # Connected
                total_distance += distances[j]
                total_pairs += 1
    
    if total_pairs == 0:
        return float('inf')
    return total_distance / total_pairs

def compute_clustering_coefficient(adj_matrix):
    """Compute average local clustering coefficient"""
    N = len(adj_matrix)
    clustering_sum = 0
    valid_nodes = 0
    
    for i in range(N):
        # Find neighbors of node i
        neighbors = [j for j in range(N) if adj_matrix[i][j] == 1]
        
        if len(neighbors) < 2:
            continue
        
        # Count triangles involving node i
        triangles = 0
        possible_triangles = len(neighbors) * (len(neighbors) - 1) // 2
        
        for j in range(len(neighbors)):
            for k in range(j+1, len(neighbors)):
                if adj_matrix[neighbors[j]][neighbors[k]] == 1:
                    triangles += 1
        
        clustering_sum += triangles / possible_triangles if possible_triangles > 0 else 0
        valid_nodes += 1
    
    return clustering_sum / valid_nodes if valid_nodes > 0 else 0

def watts_strogatz_with_metrics(N=20, k=4, p=0.1):
    """Generate Watts-Strogatz network and compute metrics"""
    # Generate the network
    adj_matrix = generate_watts_strogatz(N, k, p, seed=42)
    
    # Count edges
    num_edges = np.sum(adj_matrix) // 2
    
    # Generate random network for comparison
    adj_random = generate_random_graph(N, num_edges, seed=42)
    
    # Compute metrics for original network
    try:
        C = compute_clustering_coefficient(adj_matrix)
        L = compute_average_path_length(adj_matrix)
    except:
        C = 0
        L = float('inf')
    
    # Compute metrics for random network
    try:
        C_random = compute_clustering_coefficient(adj_random)
        L_random = compute_average_path_length(adj_random)
    except:
        C_random = 0.001  # Small value to avoid division by zero
        L_random = 1
    
    # Compute small-world coefficient
    if C_random > 0 and L_random > 0 and L != float('inf'):
        sigma = (C / C_random) / (L / L_random)
    else:
        sigma = 0
    
    return adj_matrix, adj_random, C, L, C_random, L_random, sigma

def plot_network_and_metrics(p_value):
    """Create network visualization and metrics plots"""
    adj_matrix, adj_random, C, L, C_random, L_random, sigma = watts_strogatz_with_metrics(N=20, k=4, p=p_value)
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))
    
    N = len(adj_matrix)
    
    # Plot 1: Network visualization
    # Calculate node positions in a circle
    angles = np.linspace(0, 2*np.pi, N, endpoint=False)
    pos_x = np.cos(angles)
    pos_y = np.sin(angles)
    
    # Draw edges
    for i in range(N):
        for j in range(i+1, N):
            if adj_matrix[i][j] == 1:
                # Determine if this is an original or rewired edge
                ring_distance = min(abs(i-j), N-abs(i-j))
                edge_color = 'blue' if ring_distance <= 2 else 'red'  # k=4 means connect to 2 neighbors on each side
                
                ax1.plot([pos_x[i], pos_x[j]], [pos_y[i], pos_y[j]], 
                        color=edge_color, alpha=0.6, linewidth=1.5)
    
    # Draw nodes
    ax1.scatter(pos_x, pos_y, c='lightblue', s=300, edgecolors='black', zorder=5)
    
    # Add node labels
    for i in range(N):
        ax1.text(pos_x[i], pos_y[i], str(i), ha='center', va='center', fontsize=8, zorder=6)
    
    ax1.set_title(f'Watts-Strogatz Network (p = {p_value:.3f})')
    ax1.set_aspect('equal')
    ax1.axis('off')
    ax1.set_xlim(-1.3, 1.3)
    ax1.set_ylim(-1.3, 1.3)
    
    # Add legend
    blue_patch = patches.Patch(color='blue', label='Original edges')
    red_patch = patches.Patch(color='red', label='Rewired edges')
    ax1.legend(handles=[blue_patch, red_patch], loc='upper right')
    
    # Plot 2: Clustering coefficient comparison
    ax2.bar(['Network', 'Random'], [C, C_random],
            color=['skyblue', 'lightcoral'], alpha=0.7)
    ax2.set_ylabel('Clustering Coefficient')
    ax2.set_title('Clustering Coefficient Comparison')
    ax2.set_ylim(0, max(C, C_random, 0.1) * 1.2)
    
    # Add value labels
    ax2.text(0, C + max(C, C_random, 0.1) * 0.05, f'{C:.3f}', ha='center', va='bottom')
    ax2.text(1, C_random + max(C, C_random, 0.1) * 0.05, f'{C_random:.3f}', ha='center', va='bottom')
    
    # Plot 3: Average path length comparison
    if L != float('inf'):
        ax3.bar(['Network', 'Random'], [L, L_random],
                color=['skyblue', 'lightcoral'], alpha=0.7)
        ax3.text(0, L + max(L, L_random) * 0.05, f'{L:.3f}', ha='center', va='bottom')
        ax3.text(1, L_random + max(L, L_random) * 0.05, f'{L_random:.3f}', ha='center', va='bottom')
        ax3.set_ylim(0, max(L, L_random) * 1.2)
    else:
        ax3.bar(['Network', 'Random'], [10, L_random],
                color=['skyblue', 'lightcoral'], alpha=0.7)
        ax3.text(0, 10.5, '∞', ha='center', va='bottom')
        ax3.text(1, L_random + L_random * 0.05, f'{L_random:.3f}', ha='center', va='bottom')
        ax3.set_ylim(0, max(10, L_random * 1.2))
    
    ax3.set_ylabel('Average Path Length')
    ax3.set_title('Average Path Length Comparison')
    
    # Plot 4: Small-world coefficient
    ax4.bar(['σ (Small-world coefficient)'], [sigma], color='gold', alpha=0.7)
    ax4.axhline(y=1, color='red', linestyle='--', alpha=0.7, label='σ = 1 (Random)')
    ax4.set_ylabel('Small-world Coefficient (σ)')
    ax4.set_title('Small-world Property')
    ax4.text(0, sigma + max(sigma * 0.1, 0.1), f'{sigma:.2f}', ha='center', va='bottom', fontweight='bold')
    
    # Interpretation text
    if sigma > 1:
        interpretation = "Strong small-world"
        color = 'green'
    elif sigma > 0.5:
        interpretation = "Moderate small-world"
        color = 'orange'
    else:
        interpretation = "Random-like"
        color = 'red'
    
    y_pos = max(sigma * 0.8, 0.5)
    ax4.text(0, y_pos, interpretation, ha='center', va='center',
             bbox=dict(boxstyle='round', facecolor=color, alpha=0.3))
    
    ax4.legend()
    ax4.set_ylim(0, max(sigma * 1.3, 2))
    
    plt.tight_layout()
    return fig

# Generate the plot based on slider value
current_fig = plot_network_and_metrics(p_slider.value)
mo.mpl.interactive(current_fig)
```

```python {.marimo}
# Get current metrics for display
_, _, C, L, C_random, L_random, sigma = watts_strogatz_with_metrics(N=20, k=4, p=p_slider.value)

mo.md(f"""
### Key Observations

- **Network Structure**: Blue edges represent original ring lattice connections, red edges show rewired shortcuts
- **Clustering**: Measures local triangle density - starts high and decreases with rewiring
- **Path Length**: Average shortest path between nodes - drops rapidly even with small p values
- **Small-world Coefficient (σ)**: When σ > 1, the network exhibits small-world properties

**Current values**: C = {C:.3f}, L = {L:.3f}, σ = {sigma:.2f}

Try different values of p and observe how even small amounts of rewiring (p ≈ 0.01-0.1) can create the small-world effect!
""")
```



## Paths, Walks, and Network Connectivity

While we have already used the term **path**, let us make clear its definition, together with other related terms and concepts of network connectivity.

**Basic Definitions:**

- A **walk** is a sequence of nodes that are connected to form a continous route in a network. For instance, walk (0, 1, 2, 3) is a walk in the graph of the bridges of Konigsberg. But the sequence (0,2,3,1) is not a walk, because the node 0 is not directly connected to node 2.

- A **trail** is a walk with no repeated edge. For instance, walk (0, 1, 2, 3) is also a trail as it does not cross the same edge twice. But walk (0,2,3,1,3) is not a trail due to the repeated edge (1,3).

- A **path** is a walk without repeated node. For instance, walk (0,1,2,3) is a path. But walk (0, 1, 2, 1, 2, 3) is not a path due to the repeated node 1 and 2.

- When a walk starts and ends at the same node, it is called a **loop*. If the loop is a trail, it is called a **circuit**. If the loop is a path, it is called a **cycle**.

***Question***: Is a path always a trail, and is a trail always a path?

::: {#fig-numbered-koningsberg-graph2}

<img src= "../figs/labeled-koningsberg.jpg" width="30%">

Labeled Knigsberg graph

:::

**Shortest Paths:**

- **Shortest Path** is the path with the smallest number of edges (or nodes) between two nodes. A shortest path from node 0 to 2 is (0, 1, 2). Two nodes can have multiple shortest paths e.g., (0, 3, 2).
- **The shortest path length** is the number of edges in the shortest path, *not the number of nodes!* 👈👈

::: {.callout-note}
## Are there **shortest trails** and **shortest walks**?
Shortest trails and shortest walks are fundamentally equivalent to shortest paths. A shortest trail must visit each node only once (otherwise it would not be the shortest), and similarly, a shortest walk does not repeat nodes (otherwise it would not be the shortest), both forming a shortest path.
:::

## Network Connectivity

**Basic Connectivity Concepts:**

- A network is **connected** if there is a path between every pair of nodes.
- A network is **disconnected** if there is no path between some pairs of nodes.
- **A connected component** of a network is a set of nodes that are connected to each other.
- **The giant component** of a network is the largest connected component that contains a significant fraction of nodes in the network (in order of the number of nodes).

::: {#fig-connected-components}

<img src= "../figs/connected-component.jpg" width="50%">

connected components of a network. the nodes with the same color form a connected component.

:::

**Connectivity in Directed Networks:**

We call a network is *directed* if the edges have a direction. Example directed networks include the network of Web pages, the network of friendships on X, the network of citations on academic papers.

In a directed network, a walk must follow the edge directions. Paths, trails, and loops extend similarly to directed networks. But one thing to keep in mind: a walk may not be reversible, meaning there can be a walk from one node to another but not vice versa.

This leads to two different types of `connectedness` as follows:

- **Strong connectedness**: A directed network is said to be strongly connected if there is a path from every node to every other node.
- **Weak connectedness**: A directed network is said to be weakly connected if there is a path from every node to every other node on its *undirected* counterpart.

::: {#fig-connected-components-directed}

<img src= "../figs/connected-component-directed.jpg" width="50%">

connected components of a network. the nodes with the same color form a connected component.

:::

**Question**: Is a strongly-connected component always a weakly-connected component?

In the next section, we will learn how to compute the shortest paths and connected components of a network using a library [igraph](https://python.igraph.org/en/stable/).

## References

::: {#refs}
:::